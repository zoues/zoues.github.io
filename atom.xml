<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zouyee</title>
  
  <subtitle>life is short, enjoy it</subtitle>
  <link href="https://zoues.com/atom.xml" rel="self"/>
  
  <link href="https://zoues.com/"/>
  <updated>2024-01-26T23:17:17.760Z</updated>
  <id>https://zoues.com/</id>
  
  <author>
    <name>zouyee</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>揭开K8s适配CgroupV2内存虚高的迷局</title>
    <link href="https://zoues.com/posts/3f237e52/"/>
    <id>https://zoues.com/posts/3f237e52/</id>
    <published>2024-01-27T12:40:08.000Z</published>
    <updated>2024-01-26T23:17:17.760Z</updated>
    
    <content type="html"><![CDATA[<p>在Almalinux替换CentOS的过程中，我们通过kubectl top nodes命令观察到了两个相同规格的节点（只有cgroup版本不同）。在分别调度两个相同的Pod后，我们预期它们的内存使用量应该相近。然而，我们发现使用了cgroupv2的节点的内存使用量比使用了cgroupv1的节点多了约280Mi。</p><p>初步分析表明，可能是cAdvisor在统计cgroupv1和v2的内存使用量时存在逻辑上的不一致。</p><p>理论上，无论使用cgroupv1还是cgroupv2，两个相同配置的节点的内存使用量应该相近。实际上，在比较&#x2F;proc&#x2F;meminfo时，我们发现了总内存使用量近似的情况。那么问题出在哪里呢？</p><p>我们发现，这个问题只影响了节点级别的内存统计数据，而不影响Pod级别的统计数据。</p><p>问题的根本原因是cAdvisor调用了runc的接口，其计算root cgroup的内存数据方面存在差异。在cgroupv2中，root cgroup不存在memory.current这个文件，但在cgroupv1中root cgroup是存在memory.usage_in_bytes文件的。这导致了在统计cgroupv2内存使用量时出现了不一致的情况。</p><p>这个问题可能需要在cAdvisor或runc的逻辑中进行修复，以确保在cgroupv1和cgroupv2中的内存统计一致性。下面我们基于社区issue展开介绍。</p><p>v1.28.3 commit:a8a1abc25cad87333840cd7d54be2efaf31a3177</p><blockquote><p>NOTE: Containerd:1.6.21，K8s:1.28, Kernel:5.15.0<br>(同步以前的文章)</p></blockquote><hr><h2 id="技术背景"><a href="#技术背景" class="headerlink" title="技术背景"></a>技术背景</h2><p>在Kubernetes中，Google的cAdvisor项目被用于节点上容器资源和性能指标的收集。在kubelet server中，cAdvisor被集成用于监控该节点上kubepods（默认cgroup名称，systemd模式下会加上.slice后缀） cgroup下的所有容器。从1.29.0-alpha.2版本中可以看到，kubelet目前还是提供了以下两种配置选项（但是现在useLegacyCadvisorStats为false）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">if kubeDeps.useLegacyCadvisorStats &#123;</span><br><span class="line">klet.StatsProvider = stats.NewCadvisorStatsProvider(</span><br><span class="line">klet.cadvisor,</span><br><span class="line">klet.resourceAnalyzer,</span><br><span class="line">klet.podManager,</span><br><span class="line">klet.runtimeCache,</span><br><span class="line">klet.containerRuntime,</span><br><span class="line">klet.statusManager,</span><br><span class="line">hostStatsProvider)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">klet.StatsProvider = stats.NewCRIStatsProvider(</span><br><span class="line">klet.cadvisor,</span><br><span class="line">klet.resourceAnalyzer,</span><br><span class="line">klet.podManager,</span><br><span class="line">klet.runtimeCache,</span><br><span class="line">kubeDeps.RemoteRuntimeService,</span><br><span class="line">kubeDeps.RemoteImageService,</span><br><span class="line">hostStatsProvider,</span><br><span class="line">utilfeature.DefaultFeatureGate.Enabled(features.PodAndContainerStatsFromCRI))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>kubelet以Prometheus指标格式在<code>/stats/</code>暴露所有相关运行时指标，如下图所示，Kubelet内置了cadvisor服务</p><p>图片</p><p>从 Kubernetes 1.12 版本开始，kubelet 直接从 cAdvisor 暴露了多个接口。包括以下接口：</p><ul><li>cAdvisor 的 Prometheus 指标位于 <code>/metrics/cadvisor</code>。</li><li>cAdvisor v1 Json API 位于 <code>/stats/</code>、<code>/stats/container</code>、<code>/stats/&#123;podName&#125;/&#123;containerName&#125;</code> 和 <code>/stats/&#123;namespace&#125;/&#123;podName&#125;/&#123;uid&#125;/&#123;containerName&#125;</code>。</li><li>cAdvisor 的机器信息位于 &#x2F;spec。</li></ul><p>此外，kubelet还暴露了<code>summary API</code>，其中cAdvisor 是该接口指标来源之一。在社区的监控架构文档中描述了“核心”指标和“监控”指标的定义。这个文档中规定了一组核心指标及其用途，并且目标是通过拆分监控架构来实现以下两个目标：</p><ul><li><p>减小核心指标的统计收集性能影响，允许更频繁地收集这些指标。</p></li><li><p>使监控方案可替代且可扩展。</p></li></ul><p>因此移除cadvisor的接口，成了一项长期目标，目前进度如下(进度状态的标记略为滞后)：</p><ul><li><p>[1.13] 引入 Kubelet 的 pod-resources gRPC 端点；KEP: 支持设备监控社区#2454</p></li><li><p>[1.14] 引入 Kubelet 资源指标 API</p></li><li><p>[1.15] 通过添加和弃用 <code>--enable-cadvisor-json-endpoints</code> 标志，废弃“直接” cAdvisor API 端点</p></li><li><p>[1.18] 默认将 –enable-cadvisor-json-endpoints 标志设置为禁用</p></li><li><p>[1.21] 移除 <code>--enable-cadvisor-json-endpoints</code> 标志</p></li><li><p>[1.21] 将监控服务器过渡到 Kubelet 资源指标 API（需要3个版本的差异）</p></li><li><p>[TBD] 为 kubelet 监控端点提出外部替代方案</p></li><li><p>[TBD] 通过添加和废弃 <code>--enable-container-monitoring-endpoints</code> 标志，废弃摘要 API 和 cAdvisor Prometheus 端点</p></li><li><p>[TBD+2] 移除“直接”的 cAdvisor API 端点</p></li><li><p>[TBD+2] 默认将 –enable-container-monitoring-endpoints 标志设置为禁用</p></li><li><p>[TBD+4] 移除摘要 API、cAdvisor Prometheus 指标和移除 –enable-container-monitoring-endpoints 标志。</p></li></ul><p>当前版本的cadvisor接口已经做了部分废弃，例如<code>/spec及/stats/*</code>等<br><a href="https://pic.imgdb.cn/item/65b43ba0871b83018ac66a1f.png"></a></p><h2 id="寻根溯源"><a href="#寻根溯源" class="headerlink" title="寻根溯源"></a>寻根溯源</h2><p>kubelet 使用 cadvisor 来获取节点级别的统计信息（无论是使用 cri 还是通过cadvisor 来统计提供程序来获取 pod 的统计信息）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">kubernetes/pkg/kubelet/stats/provider.go</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// NewCRIStatsProvider returns a Provider that provides the node stats</span><br><span class="line">// from cAdvisor and the container stats from CRI.</span><br><span class="line">func NewCRIStatsProvider(</span><br><span class="line">cadvisor cadvisor.Interface,</span><br><span class="line">resourceAnalyzer stats.ResourceAnalyzer,</span><br><span class="line">podManager PodManager,</span><br><span class="line">runtimeCache kubecontainer.RuntimeCache,</span><br><span class="line">runtimeService internalapi.RuntimeService,</span><br><span class="line">imageService internalapi.ImageManagerService,</span><br><span class="line">hostStatsProvider HostStatsProvider,</span><br><span class="line">podAndContainerStatsFromCRI bool,</span><br><span class="line">) *Provider &#123;</span><br><span class="line">return newStatsProvider(cadvisor, podManager, runtimeCache, newCRIStatsProvider(cadvisor, resourceAnalyzer,</span><br><span class="line">runtimeService, imageService, hostStatsProvider, podAndContainerStatsFromCRI))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// NewCadvisorStatsProvider returns a containerStatsProvider that provides both</span><br><span class="line">// the node and the container stats from cAdvisor.</span><br><span class="line">func NewCadvisorStatsProvider(</span><br><span class="line">cadvisor cadvisor.Interface,</span><br><span class="line">resourceAnalyzer stats.ResourceAnalyzer,</span><br><span class="line">podManager PodManager,</span><br><span class="line">runtimeCache kubecontainer.RuntimeCache,</span><br><span class="line">imageService kubecontainer.ImageService,</span><br><span class="line">statusProvider status.PodStatusProvider,</span><br><span class="line">hostStatsProvider HostStatsProvider,</span><br><span class="line">) *Provider &#123;</span><br><span class="line">return newStatsProvider(cadvisor, podManager, runtimeCache, newCadvisorStatsProvider(cadvisor, resourceAnalyzer, imageService, statusProvider, hostStatsProvider))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以通过下述两种方式获取节点的内存使用情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl top node</span><br><span class="line">kubectl get --raw /api/v1/nodes/foo/proxy/stats/summary | jq -C .node.memory</span><br></pre></td></tr></table></figure><p>结果显示cgroupv2节点的内存使用量比相同节点配置但使用 cgroupv1的高一些。kubectl top node 获取节点信息的逻辑在：<a href="https://github.com/kubernetes-sigs/metrics-server/blob/master/pkg/storage/node.go#L40">https://github.com/kubernetes-sigs/metrics-server/blob/master/pkg/storage/node.go#L40</a></p><p>kubelet使用 cadvisor 来获取 cgroup 统计信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubernetes/pkg/kubelet/server/stats/summary.go</span><br><span class="line"></span><br><span class="line">rootStats, err := sp.provider.GetCgroupCPUAndMemoryStats(&quot;/&quot;, false)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return nil, fmt.Errorf(&quot;failed to get root cgroup stats: %v&quot;, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里GetCgroupCPUAndMemoryStats调用以下cadvisor逻辑</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubernetes/pkg/kubelet/stats/helper.go</span><br><span class="line"></span><br><span class="line">infoMap, err := cadvisor.ContainerInfoV2(containerName, cadvisorapiv2.RequestOptions&#123;</span><br><span class="line">IdType:    cadvisorapiv2.TypeName,</span><br><span class="line">Count:     2, // 2 samples are needed to compute &quot;instantaneous&quot; CPU</span><br><span class="line">Recursive: false,</span><br><span class="line">MaxAge:    maxAge,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>cadvisor 基于 cgroup v1&#x2F;v2 获取不同 cgroup manager接口实现，然后调用GetStats()获取监控信息。</p><p>这些实现在计算root cgroup 的内存使用方面存在差异。</p><ul><li><p>v1 使用来自 memory.usage_in_bytes 的内存使用情况：<a href="https://github.com/opencontainers/runc/blob/92c71e725fc6421b6375ff128936a23c340e2d16/libcontainer/cgroups/fs/memory.go#L204-L224">https://github.com/opencontainers/runc/blob/92c71e725fc6421b6375ff128936a23c340e2d16/libcontainer/cgroups/fs/memory.go#L204-L224</a></p></li><li><p>v2 使用 &#x2F;proc&#x2F;meminfo 并计算使用情况为总内存 - 空闲内存：<a href="https://github.com/opencontainers/runc/blob/92c71e725fc6421b6375ff128936a23c340e2d16/libcontainer/cgroups/fs2/memory.go#L217">https://github.com/opencontainers/runc/blob/92c71e725fc6421b6375ff128936a23c340e2d16/libcontainer/cgroups/fs2/memory.go#L217</a></p></li></ul><p>usage_in_bytes 大致等于 RSS + Cache。workingset是 usage - 非活动文件。</p><p>在 cadvisor 中，在workingset中排除了非活动文件：<a href="https://github.com/google/cadvisor/blob/8164b38067246b36c773204f154604e2a1c962dc/container/libcontainer/handler.go#L835-L844">https://github.com/google/cadvisor/blob/8164b38067246b36c773204f154604e2a1c962dc/container/libcontainer/handler.go#L835-L844</a>“</p><p>因此可以判断在cgroupv2计算内存使用使用了total-free，这里面包含了inactive_anon，而内核以及cgroupv1计算内存使用量时不会计入 inactive_anon：<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/mm/memcontrol.c#n3720">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/mm/memcontrol.c#n3720</a></p><p>通过下面的测试中，inactive_anon 解释数据看到了差异。</p><p>下述分别为cgroupv1及cgroupv2的两个集群</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~ # kubectl top node</span><br><span class="line">NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class="line">node1   98m          2%     1512Mi          12%</span><br><span class="line">node2   99m          2%     1454Mi          11%</span><br><span class="line">node3   94m          2%     1448Mi          11%</span><br></pre></td></tr></table></figure><p>其中cgroupv1节点的root cgroup内存使用如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">~ # cat /sys/fs/cgroup/memory/memory.usage_in_bytes</span><br><span class="line">6236864512</span><br><span class="line">~ # cat /sys/fs/cgroup/memory/memory.stat</span><br><span class="line">cache 44662784</span><br><span class="line">rss 3260416</span><br><span class="line">rss_huge 2097152</span><br><span class="line">shmem 65536</span><br><span class="line">mapped_file 11083776</span><br><span class="line">dirty 135168</span><br><span class="line">writeback 0</span><br><span class="line">pgpgin 114774</span><br><span class="line">pgpgout 103506</span><br><span class="line">pgfault 165891</span><br><span class="line">pgmajfault 99</span><br><span class="line">inactive_anon 135168</span><br><span class="line">active_anon 3645440</span><br><span class="line">inactive_file 5406720</span><br><span class="line">active_file 39333888</span><br><span class="line">unevictable 0</span><br><span class="line">hierarchical_memory_limit 9223372036854771712</span><br><span class="line">total_cache 5471584256</span><br><span class="line">total_rss 767148032</span><br><span class="line">total_rss_huge 559939584</span><br><span class="line">total_shmem 1921024</span><br><span class="line">total_mapped_file 605687808</span><br><span class="line">total_dirty 270336</span><br><span class="line">total_writeback 0</span><br><span class="line">total_pgpgin 51679194</span><br><span class="line">total_pgpgout 50291069</span><br><span class="line">total_pgfault 97383769</span><br><span class="line">total_pgmajfault 5610</span><br><span class="line">total_inactive_anon 1081344</span><br><span class="line">total_active_anon 772235264</span><br><span class="line">total_inactive_file 4648124416</span><br><span class="line">total_active_file 820551680</span><br><span class="line">total_unevictable 0</span><br></pre></td></tr></table></figure><p>meminfo文件如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">~ # cat /proc/meminfo</span><br><span class="line">MemTotal:       16393244 kB</span><br><span class="line">MemFree:         9744148 kB</span><br><span class="line">MemAvailable:   15020900 kB</span><br><span class="line">Buffers:          132344 kB</span><br><span class="line">Cached:          5207356 kB</span><br><span class="line">SwapCached:            0 kB</span><br><span class="line">Active:          1557252 kB</span><br><span class="line">Inactive:        4526668 kB</span><br><span class="line">Active(anon):     745916 kB</span><br><span class="line">Inactive(anon):      792 kB</span><br><span class="line">Active(file):     811336 kB</span><br><span class="line">Inactive(file):  4525876 kB</span><br><span class="line">Unevictable:           0 kB</span><br><span class="line">Mlocked:               0 kB</span><br><span class="line">SwapTotal:             0 kB</span><br><span class="line">SwapFree:              0 kB</span><br><span class="line">Dirty:               636 kB</span><br><span class="line">Writeback:             0 kB</span><br><span class="line">AnonPages:        618992 kB</span><br><span class="line">Mapped:           624384 kB</span><br><span class="line">Shmem:              2496 kB</span><br><span class="line">KReclaimable:     285824 kB</span><br><span class="line">Slab:             423600 kB</span><br><span class="line">SReclaimable:     285824 kB</span><br><span class="line">SUnreclaim:       137776 kB</span><br><span class="line">KernelStack:        8400 kB</span><br><span class="line">PageTables:         9060 kB</span><br><span class="line">NFS_Unstable:          0 kB</span><br><span class="line">Bounce:                0 kB</span><br><span class="line">WritebackTmp:          0 kB</span><br><span class="line">CommitLimit:     8196620 kB</span><br><span class="line">Committed_AS:    2800016 kB</span><br><span class="line">VmallocTotal:   34359738367 kB</span><br><span class="line">VmallocUsed:       40992 kB</span><br><span class="line">VmallocChunk:          0 kB</span><br><span class="line">Percpu:             4432 kB</span><br><span class="line">HardwareCorrupted:     0 kB</span><br><span class="line">AnonHugePages:    270336 kB</span><br><span class="line">ShmemHugePages:        0 kB</span><br><span class="line">ShmemPmdMapped:        0 kB</span><br><span class="line">FileHugePages:         0 kB</span><br><span class="line">FilePmdMapped:         0 kB</span><br><span class="line">CmaTotal:              0 kB</span><br><span class="line">CmaFree:               0 kB</span><br><span class="line">HugePages_Total:       0</span><br><span class="line">HugePages_Free:        0</span><br><span class="line">HugePages_Rsvd:        0</span><br><span class="line">HugePages_Surp:        0</span><br><span class="line">Hugepagesize:       2048 kB</span><br><span class="line">Hugetlb:               0 kB</span><br><span class="line">DirectMap4k:      302344 kB</span><br><span class="line">DirectMap2M:     3891200 kB</span><br><span class="line">DirectMap1G:    14680064 kB</span><br></pre></td></tr></table></figure><p>当前的计算</p><p>memory.current - memory.stat.total_inactive_file &#x3D; 6236864512 - 4648124416 &#x3D; 1515 Mi -&gt; kubelet 报告的结果</p><p>cgroupv2 集群</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~ # kubectl top node</span><br><span class="line">NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class="line">node1   113m         2%     2196Mi          17%</span><br><span class="line">node2   112m         2%     2171Mi          17%</span><br><span class="line">node3   113m         2%     2180Mi          17%</span><br></pre></td></tr></table></figure><p>其中一节点的meminfo文件如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">MemTotal:       16374584 kB</span><br><span class="line">MemFree:         9505980 kB</span><br><span class="line">MemAvailable:   14912544 kB</span><br><span class="line">Buffers:          155164 kB</span><br><span class="line">Cached:          5335576 kB</span><br><span class="line">SwapCached:            0 kB</span><br><span class="line">Active:           872420 kB</span><br><span class="line">Inactive:        5399340 kB</span><br><span class="line">Active(anon):       2568 kB</span><br><span class="line">Inactive(anon):   791340 kB</span><br><span class="line">Active(file):     869852 kB</span><br><span class="line">Inactive(file):  4608000 kB</span><br><span class="line">Unevictable:       30740 kB</span><br><span class="line">Mlocked:           27668 kB</span><br><span class="line">SwapTotal:             0 kB</span><br><span class="line">SwapFree:              0 kB</span><br><span class="line">Dirty:               148 kB</span><br><span class="line">Writeback:             0 kB</span><br><span class="line">AnonPages:        716552 kB</span><br><span class="line">Mapped:           608424 kB</span><br><span class="line">Shmem:              6320 kB</span><br><span class="line">KReclaimable:     274360 kB</span><br><span class="line">Slab:             355976 kB</span><br><span class="line">SReclaimable:     274360 kB</span><br><span class="line">SUnreclaim:        81616 kB</span><br><span class="line">KernelStack:        8064 kB</span><br><span class="line">PageTables:         7692 kB</span><br><span class="line">NFS_Unstable:          0 kB</span><br><span class="line">Bounce:                0 kB</span><br><span class="line">WritebackTmp:          0 kB</span><br><span class="line">CommitLimit:     8187292 kB</span><br><span class="line">Committed_AS:    2605012 kB</span><br><span class="line">VmallocTotal:   34359738367 kB</span><br><span class="line">VmallocUsed:       48092 kB</span><br><span class="line">VmallocChunk:          0 kB</span><br><span class="line">Percpu:             3472 kB</span><br><span class="line">HardwareCorrupted:     0 kB</span><br><span class="line">AnonHugePages:    409600 kB</span><br><span class="line">ShmemHugePages:        0 kB</span><br><span class="line">ShmemPmdMapped:        0 kB</span><br><span class="line">FileHugePages:         0 kB</span><br><span class="line">FilePmdMapped:         0 kB</span><br><span class="line">HugePages_Total:       0</span><br><span class="line">HugePages_Free:        0</span><br><span class="line">HugePages_Rsvd:        0</span><br><span class="line">HugePages_Surp:        0</span><br><span class="line">Hugepagesize:       2048 kB</span><br><span class="line">Hugetlb:               0 kB</span><br><span class="line">DirectMap4k:      271624 kB</span><br><span class="line">DirectMap2M:     8116224 kB</span><br><span class="line">DirectMap1G:    10485760 kB</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">usage = total - free = 16374584 - 9505980</span><br><span class="line"></span><br><span class="line">workingset = 总内存 - 空闲内存 - 非活动文件 = 16374584 - 9505980 - 4608000 = 2207 Mi（kubelet 报告的结果）</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>如上所述，在Linux kernel及runc cgroupv1计算内存使用为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mem_cgroup_usage =NR_FILE_PAGES + NR_ANON_MAPPED + nr_swap_pages (如果swap启用的话)</span><br><span class="line"></span><br><span class="line">// - rss (NR_ANON_MAPPED)</span><br><span class="line">// - cache (NR_FILE_PAGES)</span><br></pre></td></tr></table></figure><p>但是runc在cgroupv2计算使用了total-free，因此在相似负载下，同一台机器上v1和v2版本的节点级别报告确实会相差约250-750Mi，为了让cgroup v2的内存使用计算更接近 cgroupv1，  cgroup v2调整计算内存使用量方式为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stats.MemoryStats.Usage.Usage = stats.MemoryStats.Stats[&quot;anon&quot;] + stats.MemoryStats.Stats[&quot;file&quot;]</span><br></pre></td></tr></table></figure><p>当然，我们同时还需要处理cadvisor的woringset的处理逻辑</p><p>由于笔者时间、视野、认知有限，本文难免出现错误、疏漏等问题，期待各位读者朋友、业界专家指正交流，上述排障信息已修改为社区内容。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>1.<a href="https://github.com/torvalds/linux/blob/06c2afb862f9da8dc5efa4b6076a0e48c3fbaaa5/mm/memcontrol.c#L3673-L3680">https://github.com/torvalds/linux/blob/06c2afb862f9da8dc5efa4b6076a0e48c3fbaaa5/mm/memcontrol.c#L3673-L3680</a><br>2.<a href="https://github.com/kubernetes/kubernetes/issues/68522">https://github.com/kubernetes/kubernetes/issues/68522</a><br>3.<a href="https://kubernetes.io/docs/reference/instrumentation/cri-pod-container-metrics/">https://kubernetes.io/docs/reference/instrumentation/cri-pod-container-metrics/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在Almalinux替换CentOS的过程中，我们通过kubectl top nodes命令观察到了两个相同规格的节点（只有cgroup版本不同）。在分别调度两个相同的Pod后，我们预期它们的内存使用量应该相近。然而，我们发现使用了cgroupv2的节点的内存使用量比使用了</summary>
      
    
    
    
    <category term="云原生面试案例50篇" scheme="https://zoues.com/categories/%E4%BA%91%E5%8E%9F%E7%94%9F%E9%9D%A2%E8%AF%95%E6%A1%88%E4%BE%8B50%E7%AF%87/"/>
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Rust vs. Zig：究竟谁更胜一筹？性能、安全性等全面对决！</title>
    <link href="https://zoues.com/posts/423bdf96/"/>
    <id>https://zoues.com/posts/423bdf96/</id>
    <published>2024-01-21T12:23:48.000Z</published>
    <updated>2024-01-21T12:43:12.377Z</updated>
    
    <content type="html"><![CDATA[<p>Rust和Zig，这两种语言都旨在编写高效、性能优异的代码，然而它们在实现这一目标时采用了不同的方式。</p><p>值得注意的是，Rust和Zig根植于截然不同的理念，这可能影响开发者选择时的取舍。为了更深入地了解它们在相互比较中的表现，我们将进一步探讨它们各自的特点。</p><h2 id="什么是Rust？"><a href="#什么是Rust？" class="headerlink" title="什么是Rust？"></a>什么是Rust？</h2><p>Rust是一种以效率、性能和内存安全著称的通用型编程语言。它引入了一种新的编程方式，使开发者仍然能够使用面向对象以及函数式编程。</p><p>使用Rust进行编码需要一种不同往常的思维方式，这部分主要围绕着语言规则中的所有权和借用展开。</p><p>虽然这种思维方式能够让开发者更容易编写出安全高效的代码，但与C和C++等语言相比，特别是对于新手来说，充满挑战性。</p><p>Rust消除了C和C++跨平台的限制，允许将代码编译为目标系统运行的可执行文件。这意味着可以在不做重大修改的情况下将代码编译为多系统版本。</p><p>让我们看一个Rust版的Hello world：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fn main() &#123;</span><br><span class="line">    let text: &amp;str = &quot;World&quot;;</span><br><span class="line">    println!(&quot;Hello, &#123;&#125;!&quot;, text);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似于其他编译型编程语言，在Rust中，每个可执行程序同样也都从main函数开始。如果运行上述示例，将在你的终端上输出“Hello, World!”。</p><h3 id="Rust优势与短板"><a href="#Rust优势与短板" class="headerlink" title="Rust优势与短板"></a>Rust优势与短板</h3><p>在Rust中，一些特性对开发者是有益的，而另一些则让开发变得更具挑战性。在这一章节，我们将分别介绍一下Rust的优势与劣势。</p><p>Rust的一些<strong>优势</strong>包括以下几点：</p><ul><li><p>并发和并行：Rust内置对并行编程的支持，以及安全高效的多线程特性</p></li><li><p>性能：由于Rust代码不需要运行时，同时它不需要额外的垃圾回收器功耗，从而可以使用更少的资源并提高性能，</p></li><li><p>内存安全且无垃圾回收：由于所有权和借用等规则，Rust在没有垃圾回收器的情况下管理内存，从而实现更高效和可预测的性能</p></li><li><p>跨平台兼容性：Rust支持跨平台开发，意味着可以在多个系统上编译代码而不需要太多的修改代码</p></li><li><p>强大的生态系统：Rust拥有强大的工具和库生态系统。它的包管理器Cargo显著简化了依赖管理和与外部库集成的难度</p></li></ul><p>Rust的一些<strong>劣势</strong>包括以下几点：</p><ul><li><p>学习曲线：Rust的语法对新开发者可能有些棘手。其语法融合了函数式和系统编程，受所有权和借用规则的影响很大。此外，新开发者还必须学习所有权系统、生命周期和借用规则等概念，需要付出一定的努力 ，下图是流传甚广的一张学习曲线图(来源于极客邦)</p><p><img src="https://pic.imgdb.cn/item/65ad10c7871b83018ac90c50.png" alt="Rust 编程第一课，实战驱动，快速上手 Rust"></p></li><li><p>编译耗时：Rust的安全需求导致较长的编译时间。Rust会彻底检查你的代码以防止运行时可能出现的问题，这意味着它的编译时间会比大多数语言更长</p></li><li><p>有限的资源：尽管Cargo是一个有用的包管理器，提供了许多可用的工具和库，但从整体来看，Rust的生态系统相较大多数语言来说都不够成熟。在一些专业领域，Rust的资源可能较少，迫使开发者更多地从零开始编写代码</p></li><li><p>繁琐的开发过程：由于强调安全和准确性，使用严格的规则和明确性，开发者通常在Rust中需要编写更多的代码，虽然可能会有高质量的输出，但往往会使开发过程变得更长，对小项目影响显著</p></li><li><p>互操作性：将Rust代码整合到其他语言编写的代码中可能有些困难。</p></li></ul><p>虽然Rust有其劣势，但它仍然是开发者的热门选择。在2023年Stack Overflow开发者调查中，Rust荣获最受喜爱的语言的桂冠，超过80%的受访者表示明年仍然想要使用它。</p><h3 id="Rust的常见使用场景"><a href="#Rust的常见使用场景" class="headerlink" title="Rust的常见使用场景"></a>Rust的常见使用场景</h3><p>既然你已经了解了Rust的功能，让我们看看它已经在哪些场景落地。</p><ul><li><p>在系统编程中，Rust对于构建操作系统、数据库系统、设备驱动程序和嵌入式系统等场景非常有用。</p></li><li><p>前后端Web开发者也使用Rust，与像Rocket或Actix这样的流行框架一起进行后端开发，以及使用WebAssembly或Tauri进行前端开发。</p></li></ul><p>Rust还被用于网络服务，如网络协议、代理、负载均衡器、VPN软件等。</p><p>一些Rust的更专业用例包括：</p><ul><li>游戏开发，使用像Amethyst和Bevy这样的游戏引擎</li><li>在区块链和加密货币领域，用于开发智能合约和项目中的区块链网络，如Solana 在物联网（IoT）中，用于编程微控制器和传感器等设备</li></ul><h2 id="什么是Zig？"><a href="#什么是Zig？" class="headerlink" title="什么是Zig？"></a>什么是Zig？</h2><p>虽然Zig更类似于传统的编程语言，如C和C++，但它像Rust一样注重内存安全和效率。然而，与Rust不同的是，Zig与现有的C和C++代码整合良好，无需像FFI这样的外部机制来简化互操作性。</p><p>与Rust、C和C++一样，Zig不使用垃圾收集器。为了实现类似Rust的内存安全性，Zig提供了促进内存安全的机制，例如：</p><ul><li>严格的编译时检查</li><li>用于处理潜在空值的可选类型</li><li>带有Error类型的明确错误处理</li><li>内置分配器的增强内存分配</li></ul><p>这些机制不会像Rust中那样严重影响编码习惯。让我们看一个Zig中的Hello world例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zigCopy codeconst std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;Hello, world&quot;, .&#123;&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对开发者来说，许多编程语言背后都有一种理念和设计哲学。例如，Rust注重内存安全性、效率、无垃圾收集和性能。</p><p>那么Zig呢？它的哲学包括：</p><ul><li>与C和C++代码轻松整合</li><li>生成不依赖系统依赖项的独立二进制文件</li><li>轻松的跨平台开发</li><li>快速的编译时间</li></ul><p>接下来，我们将看一看Zig的优势和劣势，之后再看它的用例。</p><h3 id="Zig的优势与短板"><a href="#Zig的优势与短板" class="headerlink" title="Zig的优势与短板"></a>Zig的优势与短板</h3><p>与我们在Rust中所做的一样，让我们从优势开始，然后再看劣势。</p><p>Zig为开发者提供的一些好处包括：</p><ul><li><p>控制和低级能力：Zig非常适合系统编程和需要直接管理系统资源的情场景</p></li><li><p>安全功能：内置分配器等功能使开发者能够轻松防止错误，提高代码可靠性，并减少错误和漏洞</p></li><li><p>性能优化：Zig是一个为高效执行和性能调优而优化代码的工具。它提供手动内存管理、编译时检查以及直接访问CPU指令的功能，以实现更高性能的应用程序</p></li><li><p>简单和可读性：Zig具有与C类似的简单语法和语言设计。这使得阅读、编写和维护代码变得简单</p></li><li><p>最小的外部依赖：Zig最小化了构建和运行程序所需的外部依赖，简化了开发，增强了可移植性，并减轻了跨平台依赖管理的负担</p></li><li><p>元编程能力：Zig的编译时元编程通过减少样板代码的需求和启用代码优化来提高代码的灵活性和生产力</p></li></ul><p>Zig的一些劣势包括：</p><ul><li>有限的生态系统：因为它仍处于早期阶段，Zig语言的生态系统比成熟语言更小</li><li>学习曲线：对于不熟悉低级编程概念的开发者来说，理解Zig可能需要一些时间 （相较Rust来说，所需的时间很短）</li><li>成熟度和工具：Zig是一种新语言，还有改进的空间。但请注意，仍然有一个强大而活跃的社区支持它</li><li>互操作性挑战：Zig提供了用于兼容性的C接口，但与其他语言集成可能需要额外的工作，比如管理数据转换和语言之间的通信</li><li>文档可用性：Zig是一种相对较新的语言，因此文档有限，社区正在努力提高文档的可用性</li></ul><h3 id="Zig的常见使用场景"><a href="#Zig的常见使用场景" class="headerlink" title="Zig的常见使用场景"></a>Zig的常见使用场景</h3><p>让我们深入一些Zig的实际用例，看看它在实际场景中是如何落地的！</p><p>开发者可以在系统编程中使用Zig来构建操作系统、设备驱动程序和嵌入式系统。其还在命令行工具中也有很多应用场景，可用于创建高效和快速的命令行界面，构建系统脚本，或优化现有工具的性能。</p><p>在编译器和语言开发中，Zig以其元编程能力和对简易性的追求而闻名。比较著名的开源项目是Bun，其是一个使用Zig开发的JavaScript运行时。</p><p>与Rust一样，Zig也有一些更为专业的使用场景：</p><ul><li>游戏开发，因支持高性能游戏引擎、能够实时模拟</li><li>在嵌入式系统和物联网中，用于编程微控制器、传感器和其他资源受限设备</li><li>在密码应用中，用于实现加密算法、数字签名、安全通信协议和其他安全敏感组件</li></ul><h2 id="Rust-vs-Zig-相似之处与差异"><a href="#Rust-vs-Zig-相似之处与差异" class="headerlink" title="Rust vs. Zig: 相似之处与差异"></a>Rust vs. Zig: 相似之处与差异</h2><p>前面我们已经分别看过Rust和Zig，现在是时候将它们放在一起进行比较了。比较不同的编程语言总是很有趣，特别是当它们有着相似的目标时。</p><p>让我们从它们的共同之处开始：</p><ul><li>内存安全性：Rust和Zig都优先考虑内存安全性，并通过严格的编译器检查、静态类型和适用于每种语言的特殊规则来防止常见的编程错误。</li><li>低级控制：两者都提供对系统资源更多的控制，使它们非常适合低级任务和系统编程。</li><li>性能优化：这两种编程语言都以高度优化的代码而闻名，具有手动内存管理、直接CPU访问和编译时评估的特性。</li><li>社区和可用性：Rust和Zig都是开源项目，拥有积极的社区、文档和工具支持。</li><li>无未定义行为：这两种编程语言都有严格的编译器检查和其他功能，可以防止未定义的行为。通过在编译时捕获问题，提高了程序的稳定性和安全性。</li></ul><p>与此同时，您可以使用下面的比较了解Rust和Zig之间的差异：</p><table><thead><tr><th>特征</th><th>Rust 使用其严格的所有权和借用规则来确保开发者编写的任何代码都是安全的。</th><th>Zig 使用跟踪和控制内存分配和释放的机制来防止开发者编写的任何代码都是不安全的。</th></tr></thead><tbody><tr><td>语法</td><td>Rust 通过显式注解强调所有权和生命周期，可能导致代码更长。</td><td>Zig 遵循类似于C的语法。</td></tr><tr><td>生态系统</td><td>Rust 提供了强大的生态系统，包括库、工具和社区支持。</td><td>Zig 是一个较年轻的语言，生态系统相对较小。</td></tr><tr><td>互操作性</td><td>Rust 具有良好的FFI兼容性。它在从C调用Rust函数方面表现良好，但从Rust调用C函数可能会有难度。</td><td>Zig 具有更出色的FFI。它在从C调用Zig函数和从C调用Zig函数方面表现良好。</td></tr><tr><td>错误处理</td><td>Rust 使用Result和Option类型进行显式错误处理。</td><td>Zig 使用错误类型、错误联合和延迟语句进行错误处理。</td></tr><tr><td>包管理器</td><td>Rust 使用Cargo包管理器处理包和依赖关系。</td><td>Zig 使用其内置的包管理器处理包和依赖关系。</td></tr></tbody></table><p>除了它们的相似之处和差异之外，我们还可以通过性能、流行度以及它们的程序员薪酬来比较Rust和Zig。让我们更仔细地看一看。</p><h3 id="Rust-vs-Zig-性能"><a href="#Rust-vs-Zig-性能" class="headerlink" title="Rust vs. Zig: 性能"></a>Rust vs. Zig: 性能</h3><p>客观来看，在Rust和Zig之间，并没有绝对性能更好的语言。Rust在特定应用中可能会胜过Zig，而Zig在其他方面可能会超越Rust。</p><p>让我们通过从编程语言和编译器基准测试中进行比较，仔细研究每种语言的性能：</p><p><img src="https://pic.imgdb.cn/item/65ad10df871b83018ac973e8.png" alt="Screenshot Taken From Programming Languages And Compiler Benchmark Project Showing Rust Vs Zig Performance For Two Example Programs"></p><p>这个基准测试项目包含用多种编程语言编写，并同时运行的程序。以表格形式呈现它们的运行结果，可以看到每种编程语言在任务中的表现到底如何。</p><p>在上面的图片中，我们使用Rust和Zig编写的mandelbrot和nbody程序，从性能<strong>由好到差</strong>进行排列。</p><p>你会注意到在某些情况下，Zig的性能优于Rust，而在其他情况下，Rust的性能优于Zig。两者都是高性能的语言，因此在项目中选择任一选项都应该能够满足你的需求。</p><h3 id="Rust-vs-Zig：流行度"><a href="#Rust-vs-Zig：流行度" class="headerlink" title="Rust vs. Zig：流行度"></a>Rust vs. Zig：流行度</h3><p>在选择要学习的编程语言时，流行度可能是一个重要因素。选择一种流行的语言不仅增加了你找到资源和支持的机会，还意味着你更有可能找到合作的开发者。</p><p>StackOverflow最新的开发者调查提供了一些有趣的观察视角。正如前面提到的，Rust是今年最受钦佩的语言，有84.66％的受访者表示他们明年想再次使用它，而Zig只有71.33％。</p><p>Rust在受欢迎语言列表中排名第14位，而Zig在总共列出的51种语言中排名第41位。</p><p>可能是因为它仍处于早期阶段，因此Zig在这两种情况下才获得较低的流行度。无论如何，考虑你选择工作的语言的流行度是至关重要的。</p><h3 id="Rust-vs-Zig：薪酬"><a href="#Rust-vs-Zig：薪酬" class="headerlink" title="Rust vs. Zig：薪酬"></a>Rust vs. Zig：薪酬</h3><p>StackOverflow的开发者调查还包含了受访者报告的最高薪酬的信息。如果你对进入软件开发市场感兴趣，这张图表可能对你很有帮助。</p><p>有趣的是，尽管Zig是一个新的选择，但实际上是今年最高薪酬的语言，而Rust在列表中排名第14位。如果你出于专业原因想要学习Rust或Zig，这些信息可能会有所帮助：</p><p><img src="https://pic.imgdb.cn/item/65ad10f2871b83018ac9cd1e.png" alt="Red Bar Chart With Dark Grey Background And White Labels Comparing Reported Pay For Developers By Language Ordered From Highest Pay To Lowest Pay"></p><p>尽管这张图表非常有帮助，但它只提供了局部的一些信息。当确定一个开发者的薪酬时，还有其他因素需要考虑，比如他们的经验水平和他们所在公司。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>关于Rust和Zig，很难说哪一个是明显的赢家。每种语言都有其优点和缺点。在深入使用任何一种语言之前，进行研究是至关重要的。这就是为什么我希望这篇文章能帮助你找到正确的选择。</p><p><a href="https://blog.logrocket.com/comparing-rust-vs-zig-performance-safety-more/">https://blog.logrocket.com/comparing-rust-vs-zig-performance-safety-more/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Rust和Zig，这两种语言都旨在编写高效、性能优异的代码，然而它们在实现这一目标时采用了不同的方式。&lt;/p&gt;
&lt;p&gt;值得注意的是，Rust和Zig根植于截然不同的理念，这可能影响开发者选择时的取舍。为了更深入地了解它们在相互比较中的表现，我们将进一步探讨它们各自的特点。&lt;</summary>
      
    
    
    
    
    <category term="zig" scheme="https://zoues.com/tags/zig/"/>
    
  </entry>
  
  <entry>
    <title>Optimizing the construction of the VM ecosystem with KubeVirt</title>
    <link href="https://zoues.com/posts/a78d5062/"/>
    <id>https://zoues.com/posts/a78d5062/</id>
    <published>2024-01-20T05:40:08.000Z</published>
    <updated>2024-01-21T02:32:23.551Z</updated>
    
    <content type="html"><![CDATA[<p>Two months ago, we were thrilled to share insights in the article “Best Practices for Migrating VM Clusters to KubeVirt 1.0.” As previously mentioned, we have selected AlmaLinux and Kubernetes 1.28 as the foundation for virtualization, employing cgroup v2 for resource isolation. Before moving to the production phase, we encountered additional challenges, particularly related to Kubernetes, containerd, and specific issues within KubeVirt. Therefore, in this second article, our goal is to share practical experiences and insights gained before the deployment of KubeVirt into a production environment.</p><h3 id="Latest-Developments"><a href="#Latest-Developments" class="headerlink" title="Latest Developments"></a>Latest Developments</h3><p>KubeVirt containerizes the trusted virtualization layer of QEMU and libvirt, enabling the management of VMs as standard Kubernetes resources. This approach offers users a more flexible, scalable, and contemporary solution for virtual machine management. As the project progresses, we’ve identified specific misconceptions, configuration errors, and opportunities to enhance KubeVirt functionality, especially in the context of utilizing Kubernetes 1.28 and containerd. The details are outlined below:</p><h4 id="kubernetes"><a href="#kubernetes" class="headerlink" title="kubernetes"></a>kubernetes</h4><ul><li>kubelet ready-only port</li></ul><p>To address security concerns, we have taken measures to mitigate potential malicious attacks on pods and containers. Specifically, we have discontinued the default opening of the insecure read-only port 10255 for the kubelet in K8s clusters running Kubernetes 1.26 or later. Instead, the authentication port 10250 is now opened and utilized by the kubelet.</p><ul><li>service account token expiration</li></ul><p>To enhance data security, Kubernetes 1.21 defaults to enabling the BoundServiceAccountTokenVolume feature. This feature specifies the validity period of service account tokens, automatically renews them before expiration, and invalidates tokens after associated pods are deleted. If using client-go version 11.0.0 or later, or 0.15.0 or later, the kubelet automatically reloads service account tokens from disks to facilitate token renewal.</p><ul><li>securing controller-manager and scheduler metrics</li></ul><p>Secure serving on port 10257 to kube-controller-manager (configurable via –secure-port) is now enabled. Delegated authentication and authorization are to be configured using the same flags as for aggregated API servers. Without configuration, the secure port will only allow access to &#x2F;healthz. (#64149, @sttts) Courtesy of SIG API Machinery, SIG Auth, SIG Cloud Provider, SIG Scheduling, and SIG Testing</p><p>Added secure port 10259 to the kube-scheduler (enabled by default) and deprecate old insecure port 10251. Without further flags self-signed certs are created on startup in memory. (#69663, @sttts)</p><h4 id="containerd"><a href="#containerd" class="headerlink" title="containerd"></a>containerd</h4><ul><li>private registry</li></ul><p>Modify your config.toml file (usually located at &#x2F;etc&#x2F;containerd&#x2F;config.toml) as shown below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">version = 2</span><br><span class="line"></span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class="line">config_path = &quot;/etc/containerd/certs.d&quot;</span><br></pre></td></tr></table></figure><p>In containerd registry configuration, a registry host namespace refers to the path of the hosts.toml file specified by the registry host name or IP address, along with an optional port identifier. When submitting a pull request for an image, the typical format is as follows:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pull [registry_host_name|IP address][:port][/v2][/org_path]&lt;image_name&gt;[:tag|@DIGEST]</span><br></pre></td></tr></table></figure><p>The registry host namespace part is <code>[registry_host_name|IP address][:port]</code>. For example, the directory structure for docker.io looks like this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plaintextCopy code$ tree /etc/containerd/certs.d</span><br><span class="line">/etc/containerd/certs.d</span><br><span class="line">└── docker.io</span><br><span class="line">└── hosts.toml</span><br></pre></td></tr></table></figure><p>Alternatively, you can use the _default registry host namespace as a fallback if no other namespace matches.</p><ul><li>systemd cgroup</li></ul><p>While containerd and Kubernetes default to using the legacy cgroupfs driver for managing cgroups, it is recommended to utilize the systemd driver on systemd-based hosts to adhere to the “single-writer” rule of cgroups.</p><p>To configure containerd to use the systemd driver, add the following option in <code>/etc/containerd/config.toml</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">version = 2</span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">SystemdCgroup = true</span><br></pre></td></tr></table></figure><p>Additionally, apart from configuring containerd, you need to set the KubeletConfiguration to use the “systemd” cgroup driver. The KubeletConfiguration is typically found at <code>/var/lib/kubelet/config.yaml</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">cgroupDriver: &quot;systemd&quot;</span><br></pre></td></tr></table></figure><ul><li>[community issue]containerd startup hangs when &#x2F;etc is ready-only</li></ul><p>We observed that, following the update from containerd v1.6.21 to v1.6.22, the systemd service failed to start successfully. Upon closer inspection during debugging, it was revealed that containerd did not fully initialize (lacking the “containerd successfully booted in …” message) and did not send the sd notification READY&#x3D;1 event.</p><ul><li>migration docker to containerd</li></ul><p>you have to configure the KubeletConfiguration to use the “containerd” endpoint. The KubeletConfiguration is typically located at &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kind: KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">containerRuntimeEndpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br></pre></td></tr></table></figure><p>Because <code>/var/lib/docker</code> is mounted on a separate disk, switching to containerd requires navigating to the root directory of containerd.</p><h3 id="kubevirt"><a href="#kubevirt" class="headerlink" title="kubevirt"></a>kubevirt</h3><ul><li>containerDisk data persistent<br>The containerDisk feature provides the ability to store and distribute VM disks in the container image registry. containerDisks can be assigned to VMs in the disks section of the VirtualMachineInstance spec.containerDisks are ephemeral storage devices that can be assigned to any number of active VirtualMachineInstances.We can persist data locally through incremental backups.</li><li>hostdisk support qcow2 format</li><li>hostdisk support hostpath capacity expansion</li></ul><h3 id="Storage-Solution"><a href="#Storage-Solution" class="headerlink" title="Storage Solution"></a>Storage Solution</h3><h4 id="VM-Image-storage-Soultion"><a href="#VM-Image-storage-Soultion" class="headerlink" title="VM Image storage Soultion"></a>VM Image storage Soultion</h4><p>In KubeVirt, the original virtual machine image file is incorporated into the &#x2F;disk path of the Docker base image and subsequently pushed to the image repository for utilization in virtual machine creatio.</p><p>Example: we could Inject a local VirtualMachineInstance disk into a container image</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; END &gt; Dockerfile</span><br><span class="line">FROM scratch</span><br><span class="line">ADD --chown=107:107 almalinux.qcow2 /disk/</span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">docker build -t kubevirt/alamlinux:latest .</span><br></pre></td></tr></table></figure><p>When initiating a virtual machine, a Virtual Machine Instance (VMI) Custom Resource Definition (CRD) is created, capturing the specified virtual machine image’s name. Subsequent to VMI creation, the virt-controller generates a corresponding virt-launcher pod for the VMI. This pod comprises threee containers: compute container hosting the compute process for virt-launcher, named container-disk, responsible for managing the storage of the virtual machine image and guest-console-log container. The imageName of the container-disk container corresponds to the virtual machine image name recorded in the VMI. Once the virt-launcher pod is created, kubelet retrieves the container-disk image and initiates the container-disk container. During startup, the container-disk consistently monitors the disk_0.sock file under the -copy-path, with the sock file mapped to the path &#x2F;var&#x2F;run&#x2F;kubevirt&#x2F;container-disk&#x2F;{vmi-uuid}&#x2F; on the host machine through hostPath.</p><p>To facilitate the retrieval of necessary information during virtual machine creation, the virt-handler pod utilizes HostPid, enabling visibility of the host machine’s pid and mount details within the virt-handler container. During the virtual machine creation process, virt-handler identifies the pid of the container-disk process by referencing the disk_0.sock file of the VMI. It proceeds to determine the disk number of the container-disk container’s root disk using &#x2F;proc&#x2F;{pid}&#x2F;mountInfo. Subsequently, by cross-referencing the disk number of the container-disk root disk with the mount information of the host machine , it pinpoints the physical location of the container-disk root disk. Finally, it constructs the path for the virtual machine image file (&#x2F;disk&#x2F;disk.qcow2), retrieves the actual storage location (sourceFile) of the original virtual machine image on the host machine, and mounts the sourceFile to the targetFile for subsequent use as a backingFile during virtual machine creation.</p><h4 id="Host-Disk-Storage"><a href="#Host-Disk-Storage" class="headerlink" title="Host Disk Storage"></a>Host Disk Storage</h4><p>A hostDisk volume type provides the ability to create or use a disk image located somewhere on a node. It works similar to a hostPath in Kubernetes and provides two usage types:</p><p>DiskOrCreate if a disk image does not exist at a given location then create one<br>Disk a disk image must exist at a given location<br>need to enable the HostDisk feature gate.</p><p>Currently, hostdisk feature has some limitations. The expansion of hostdisk is only supported in the manner of using Persistent Volume Claims (PVC), and the disk format is limited to raw files.</p><p>Details regarding the above will be elaborated in the Feature Expansion section.</p><h3 id="Feature-Expansion"><a href="#Feature-Expansion" class="headerlink" title="Feature Expansion"></a>Feature Expansion</h3><h4 id="Support-VM-static-expansion"><a href="#Support-VM-static-expansion" class="headerlink" title="Support VM static expansion"></a>Support VM static expansion</h4><p>The CPU&#x2F;Mem is also provided with a synchronous interface when the CPU&#x2F;Mem disk is stopped and expanded. The CPU hotplug feature was introduced in KubeVirt v1. 0, making it possible to configure the VM workload to allow for adding or removing virtual CPUs while the VM is running,While the current version supports online expansion, we still opt for static expansion, primarily due to the temporary nature of VMs. The challenge here is that when resources are insufficient, the VM will not start.</p><h4 id="hostdisk-support-qcow2-and-online-expand"><a href="#hostdisk-support-qcow2-and-online-expand" class="headerlink" title="hostdisk support qcow2 and online expand"></a>hostdisk support qcow2 and online expand</h4><p>The current hostdisk has some limitations. The expansion of hostdisk is only supported in the manner of using Persistent Volume Claims (PVC), and the disk is limited to raw format,To implement this feature, we made minor adjustments to all components.</p><h4 id="cold-migration"><a href="#cold-migration" class="headerlink" title="cold migration"></a>cold migration</h4><p>We refrain from employing live migration capabilities due to their complexity and several limitations in our specific scenario. Instead, with data locally persisted and VMs scheduled in a fixed manner, we utilize cold migration through the rsync command.</p><h4 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h4><p>In addition to the enhanced features mentioned earlier, we have integrated support for both static and dynamic addition or removal of host disks for virtual machines, password reset capabilities, pass-through of physical machine disks, and addressed various user requirements to deliver a more versatile and comprehensive usage experience.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>KubeVirt simplifies running virtual machines on Kubernetes, making it as easy as managing containers. It provides a cloud-native approach to managing virtual machines. KubeVirt addresses the challenge of unifying the management of virtual machines and containers, effectively harnessing the strengths of both. However, there is still a long way to go in practice.</p><p><a href="https://github.com/k8snetworkplumbingwg/multus-cni/issues/1132">https://github.com/k8snetworkplumbingwg/multus-cni/issues/1132</a></p><p><a href="https://segmentfault.com/a/1190000040926384/en">https://segmentfault.com/a/1190000040926384/en</a></p><p><a href="https://www.alibabacloud.com/help/en/ack/product-overview/solution-to-serviceaccount-token-expiration-after-upgrading-122-version">https://www.alibabacloud.com/help/en/ack/product-overview/solution-to-serviceaccount-token-expiration-after-upgrading-122-version</a></p><p><a href="https://github.com/containerd/containerd/issues/9139">https://github.com/containerd/containerd/issues/9139</a></p><p><a href="https://github.com/containerd/containerd/blob/main/docs/cri/config.md">https://github.com/containerd/containerd/blob/main/docs/cri/config.md</a></p><p><a href="https://www.cncf.io/blog/2023/09/22/best-practices-for-transitioning-vm-clusters-to-kubevirt-1-0/https://kubevirt.io/user-guide/virtualmachines/disksand_volumes/#hostdisk">https://www.cncf.io/blog/2023/09/22/best-practices-for-transitioning-vm-clusters-to-kubevirt-1-0/https://kubevirt.io/user-guide/virtualmachines/disksand_volumes/#hostdisk</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Two months ago, we were thrilled to share insights in the article “Best Practices for Migrating VM Clusters to KubeVirt 1.0.” As previous</summary>
      
    
    
    
    <category term="kubevirt" scheme="https://zoues.com/categories/kubevirt/"/>
    
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
    <category term="cncf" scheme="https://zoues.com/tags/cncf/"/>
    
    <category term="kubevirt" scheme="https://zoues.com/tags/kubevirt/"/>
    
  </entry>
  
  <entry>
    <title>Best practices for transitioning VM clusters to KubeVirt 1.0</title>
    <link href="https://zoues.com/posts/912f3650/"/>
    <id>https://zoues.com/posts/912f3650/</id>
    <published>2024-01-20T05:40:08.000Z</published>
    <updated>2024-01-21T02:27:17.870Z</updated>
    
    <content type="html"><![CDATA[<p>The KubeVirt community is thrilled to announce the highly-anticipated release of KubeVirt v1.0! This momentous release signifies the remarkable achievements and widespread adoption within the community, marking a significant milestone for all stakeholders involved. This project became part of CNCF as a sandbox project in September 2019 and attained incubation status in April 2022. KubeVirt has evolved into a production-ready virtual machine management project that seamlessly operates as a native Kubernetes API. We have also chosen KubeVirt as our ultimate solution for virtual machine orchestration. Currently, we are utilizing AlmaLinux as the virtualization foundation and cgroup v2 as the resource isolation mechanism. Throughout the process of implementing KubeVirt, we encountered certain challenges. Therefore, we aim to share some of the practical experiences and insights we’ve gained from working with KubeVirt in this article.</p><h3 id="Why-KubeVirt"><a href="#Why-KubeVirt" class="headerlink" title="Why KubeVirt?"></a>Why KubeVirt?</h3><p>While OpenStack has seen widespread adoption, its architecture is relatively complex. By utilizing KubeVirt, virtual machine management is streamlined, offering an improved integration experience. With KubeVirt’s inclusion in the CNCF sandbox project and its integration with the CNCF ecosystem, Kubernetes API has been extended with custom resource definitions (CRDs) to enable native VM operation within Kubernetes.</p><p>KubeVirt containerizes the trusted virtualization layer of QEMU and libvirt, allowing VMs to be handled just like any other Kubernetes resource. This approach provides users with a more flexible, scalable, and modern virtual machine management solution, offering the following key advantages:</p><ul><li>Simplified Architecture and Management: Compared to OpenStack, KubeVirt offers a simplified architecture and management requirements. OpenStack can be unwieldy and costly to maintain, while KubeVirt leverages Kubernetes for the automated lifecycle management of VMs. It eliminates separate processes for VMs and containers, facilitating the integration of workflows for both virtualization and containerization. This simplifies the underlying infrastructure stack and reduces management costs.</li><li>Modern, Scalable, Kubernetes-Based Solution: KubeVirt is a modern, scalable, Kubernetes-based virtual machine management solution. By standardizing automated testing and deployment of all applications using Kubernetes, and unifying metadata within Kubernetes, it reduces the risk of deployment errors and enables faster iteration. This minimizes the operational workload for DevOps teams and accelerates day-to-day operations.</li><li>Tight Integration with the Kubernetes Ecosystem: KubeVirt seamlessly integrates with the Kubernetes ecosystem, offering improved scalability and performance. When VMs are migrated to Kubernetes, it can lead to cost reductions for software and application use and minimize performance overhead at the virtualization layer.</li><li>Ideal for Lightweight, Flexible, and Modern VM Management: KubeVirt is well-suited for scenarios requiring lightweight, flexible, and modern virtual machine management. Users can run their virtual workloads alongside container workloads, managing them in the same manner. They can also leverage familiar cloud-native tools such as Tekton, Istio, ArgoCD, and more, which are already favored by cloud-native users.</li></ul><h3 id="What‘s-new-in-kubeVirt-1-0-？"><a href="#What‘s-new-in-kubeVirt-1-0-？" class="headerlink" title="What‘s new in kubeVirt 1.0 ？"></a>What‘s new in kubeVirt 1.0 ？</h3><p>In POC phase, two RPM-based packages and six container images were used, providing an extension for virtual machine management within Kubernetes:</p><ol><li>kubevirt-virtctl: This package can be installed on any machine with administrator access to the cluster. It contains the virtctl tool, which simplifies virtual machine management using kubectl. While kubectl can be used for this purpose, managing VMs can be complex due to their stateful nature. The virtctl tool abstracts this complexity, enabling operations like starting, stopping, pausing, unpausing, and migrating VMs. It also provides access to the virtual machine’s serial console and graphics server.</li><li>kubevirt-manifests: This package contains manifests for installing KubeVirt. Key files include kubevirt-cr.yaml, representing the KubeVirt Custom Resource definition, and kubevirt-operator.yaml, which deploys the KubeVirt operator responsible for managing the KubeVirt service within the cluster.<br>The container images are as follows:</li></ol><ul><li>virt-api: Provides a Kubernetes API extension for virtual machine resources.</li><li>virt-controller: Watches for new or updated objects created via virt-api and ensures object states match the requested state.</li><li>virt-handler: A DaemonSet and node component that keeps cluster-level virtual machine objects in sync with libvirtd domains running in virt-launcher. It can also perform node-centric operations like configuring networking and storage.</li><li>virt-launcher: A node component that runs libvirt and QEMU to provide the virtual machine environment.</li><li>virt-operator: Implements the Kubernetes operator pattern for managing the KubeVirt application.</li><li>libguestfs-tools: Provides utilities for accessing and modifying VM disk images.<br>The v1.0 release signifies significant growth for the KubeVirt community, progressing from an idea to a production-ready Virtual Machine Management solution over the past six years. This release emphasizes maintaining APIs while expanding the project. The release cadence has shifted to align with Kubernetes practices, enabling better stability, compatibility, and support.</li></ul><p>The project has embraced Kubernetes community practices, including SIGs for test and review responsibilities, a SIG release repo for release-related tasks, and regular SIG meetings covering areas like scale, performance, and storage.</p><p>Notable features in v1.0 include memory over-commit support, persistent vTPM for easier BitLocker usage on Windows, initial CPU Hotplug support, hot plug, and hot unplug (in alpha), and further developments in API stabilization and SR-IOV interface support.</p><p>The focus is on aligning KubeVirt with Kubernetes and fostering community collaboration to enhance virtual machine management within the Kubernetes ecosystem.</p><h3 id="What-issues-in-kubeVirt-1-0？"><a href="#What-issues-in-kubeVirt-1-0？" class="headerlink" title="What issues in kubeVirt 1.0？"></a>What issues in kubeVirt 1.0？</h3><h4 id="CgroupV2-support"><a href="#CgroupV2-support" class="headerlink" title="CgroupV2 support"></a>CgroupV2 support</h4><p>When using cgroup v2, starting a VM with a non-hotpluggable volume can be problematic because cgroup v2 doesn’t provide information about the currently allowed devices for a container. KubeVirt addresses this issue by tracking device rules internally using a global variable:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/kubevirt/7/pkg/virt-handler/cgroup/cgroup_v2_manager.go#L10</span><br><span class="line"></span><br><span class="line">var rulesPerPid = make(map[string][]*devices.Rule)</span><br></pre></td></tr></table></figure><p>However, this approach has some drawbacks:</p><p>The variable won’t survive a crash or restart of the virt-handler pod, resulting in data loss.<br>The state is stored in a dynamic structure (a map), and stale data is not removed, causing memory consumption to continuously increase.<br>A potential solution is to store the state in a file, for example, <code>/var/run/kubevirt-private/devices.list</code>. This file should be updated each time a device is added or removed. Additionally, it should be removed when the corresponding VM is destroyed, or periodic cleanup can be performed. The file can follow the same data format as devices.list on cgroup v1 hosts, allowing the same code to parse the current state for both v1 and v2.</p><p>However, managing the file introduces the challenge of performing transactions, i.e., applying actual device rules and writing the state to the file atomically.</p><p>You can find more details and discussions about this issue in GitHub issue #7710.</p><h4 id="Cilium-Support"><a href="#Cilium-Support" class="headerlink" title="Cilium Support"></a>Cilium Support</h4><ul><li>cilium multi-homing<br>In Kubernetes, each pod typically has only one network interface (aside from a loopback interface). Cilium-native multi-homing aims to enable the attachment of additional network interfaces to pods. This functionality is similar to what the Multus CNI offers, which allows the attachment of multiple network interfaces to pods. However, Cilium-native multi-homing distinguishes itself by relying exclusively on the Cilium CNI as the sole CNI installed.</li></ul><p>This feature should provide robust support for all existing Cilium datapath capabilities, including network policies, observability, datapath acceleration, and service discovery. Furthermore, it aims to offer a straightforward developer experience that aligns with the simplicity and usability that Cilium already provides today.</p><ul><li>multus<br>When utilizing Cilium version 1.14.0 alongside multus-cni, there seems to be an issue where the secondary interface does not become visible. Here’s a list of files you can find under the &#x2F;etc&#x2F;cni directory after installing multus in a Cilium 1.14 environment:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l</span><br><span class="line">/etc/cni/net.d/05-cilium.conflist</span><br><span class="line">/etc/cni/net.d/00-multus.conf.cilium_bak</span><br><span class="line">/etc/cni/net.d/100-crio-bridge.conflist.cilium_bak</span><br><span class="line">/etc/cni/net.d/200-loopback.conflist.cilium_bak</span><br><span class="line">/etc/cni/net.d/multus.d/multus.kubeconfig</span><br></pre></td></tr></table></figure>The issue with multus installation in Cilium 1.14 has been resolved by setting cni.exclusive to false.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Make Cilium take ownership over the `/etc/cni/net.d` directory on the</span><br><span class="line"># node, renaming all non-Cilium CNI configurations to `*.cilium_bak`.</span><br><span class="line"># This ensures no Pods can be scheduled using other CNI plugins during Cilium</span><br><span class="line"># agent downtime.</span><br><span class="line">exclusive: false</span><br></pre></td></tr></table></figure></li></ul><h4 id="Harbor-limit"><a href="#Harbor-limit" class="headerlink" title="Harbor limit"></a>Harbor limit</h4><p>We encountered an issue when attempting to push a container with a single layer size which contain win.qcow2 image exceeding 10.25GB to our Harbor instance hosted on an EC2 instance. Our Harbor version is v2.1.2, and we are using S3 as the storage backend.</p><p>Our system has successfully handled containers with total sizes exceeding 15GB in the past. However, this specific container with a single layer size of 13.5GB repeatedly fails to push. On the client side, we receive limited feedback:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Sep 10 22:29:19 backend-ci dockerd[934]:</span><br><span class="line">time=&quot;2023-09-10T22:29:19.628869277+02:00&quot; level=error msg=&quot;Upload failed, retrying: blob upload unknown&quot;</span><br><span class="line">Although the push activity completes successfully, the client-side error only appears afterward. In the registry.log, we’ve noticed the following error:</span><br><span class="line"></span><br><span class="line">registry[885]: time=&quot;2023-09-10T08:47:25.330317861Z&quot; level=error msg=&quot;upload resumed at wrong offest: 10485760000 != 12341008872&quot;</span><br></pre></td></tr></table></figure><p>We would greatly appreciate any insights or advice on this matter. Perhaps others have encountered similar issues with very large layers, especially when using S3 as a storage backend, where pushing layers larger than 10GB is not supported. We’ve also come across potential fixes proposed in this GitHub pull request:</p><p><a href="https://github.com/goharbor/harbor/pull/16322">https://github.com/goharbor/harbor/pull/16322</a></p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>KubeVirt simplifies running virtual machines on Kubernetes, making it as easy as managing containers. It provides a cloud-native approach to managing virtual machines. KubeVirt addresses the challenge of unifying the management of virtual machines and containers, effectively harnessing the strengths of both. However, there is still a long way to go in practice. Nevertheless, the release of version 1.0 is significant for the community and users. We look forward to the widespread adoption of KubeVirt and its full support for cgroupv2.</p><ul><li><p><a href="https://documentation.suse.com/container/kubevirt/html/SLE-kubevirt/index.html">https://documentation.suse.com/container/kubevirt/html/SLE-kubevirt/index.html</a></p></li><li><p><a href="https://kubevirt.io/2023/KubeVirt-v1-has-landed.html">https://kubevirt.io/2023/KubeVirt-v1-has-landed.html</a></p></li><li><p>CFP: Cilium-native multi-homing · Issue #20129</p></li><li><p><a href="https://github.com/goharbor/harbor/issues/15719">https://github.com/goharbor/harbor/issues/15719</a></p></li><li><p><a href="https://github.com/kubevirt/kubevirt/issues/398">https://github.com/kubevirt/kubevirt/issues/398</a></p></li><li><p><a href="https://github.com/k8snetworkplumbingwg/multus-cni/issues/1132">https://github.com/k8snetworkplumbingwg/multus-cni/issues/1132</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The KubeVirt community is thrilled to announce the highly-anticipated release of KubeVirt v1.0! This momentous release signifies the rema</summary>
      
    
    
    
    <category term="kubevirt" scheme="https://zoues.com/categories/kubevirt/"/>
    
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
    <category term="cncf" scheme="https://zoues.com/tags/cncf/"/>
    
    <category term="kubevirt" scheme="https://zoues.com/tags/kubevirt/"/>
    
  </entry>
  
  <entry>
    <title>Embracing Cgroup V2:Best Practices for Migrating Kubernetes Clusters to AlmaLinux</title>
    <link href="https://zoues.com/posts/58fc8d19/"/>
    <id>https://zoues.com/posts/58fc8d19/</id>
    <published>2024-01-20T05:40:08.000Z</published>
    <updated>2024-01-21T02:29:47.248Z</updated>
    
    <content type="html"><![CDATA[<p>With the announcement of CentOS discontinuation by the CentOS community , along with the set dates for service termination, we have put the switch to a new container operating system on our agenda. Based on factors such as migration cost, smoothness of transition, and maintenance difficulty, we have chosen AlmaLinux from the RHEL series as an alternative solution.</p><p>NOTE: AlmaLinux is just one of the replacement options available within the RHEL ecosystem. Our choice is based on our specific production needs and does not necessarily apply to everyone.</p><p>AlmaLinux 9 defaults to using cgroup v2, and this configuration affects some underlying components. Therefore, certain adaptations and compatibility work need to be done. This article presents the best practices for migrating Kubernetes cluster nodes from CentOS to AlmaLinux which involves removing dockershim and utilizing cgroup v2 for node resource management.</p><h2 id="Why-Cgroup-v2"><a href="#Why-Cgroup-v2" class="headerlink" title="Why Cgroup v2?"></a>Why Cgroup v2?</h2><p>Effective resource management is a critical aspect of Kubernetes. This involves managing the finite resources in your nodes, such as CPU, memory, and storage.</p><p><em>cgroups</em> are a Linux kernel capability that establish resource management functionality like limiting CPU usage or setting memory limits for running processes.</p><p>When you use the resource management capabilities in Kubernetes, such as configuring requests and limits for Pods and containers, Kubernetes uses cgroups to enforce your resource requests and limits.</p><p>The Linux kernel offers two versions of cgroups: cgroup v1 and v2.</p><p>Here is our comparison between the two versions based on our research:</p><table><thead><tr><th></th><th>cgroup v1</th><th>cgroup v2</th></tr></thead><tbody><tr><td>Maintainability</td><td>deprecate and systemd community intend to remove cgroup v1 support from systemd release after the end of 2023</td><td>Many recent releases of Linux distributions have switched over to cgroup v2 by default</td></tr><tr><td>Compatibility</td><td>support</td><td>1. Components such as kubelet need to be adapted for cgroup v2 2. Business applications require JDK version upgrades, which can be achieved by replacing the base image</td></tr><tr><td>hierarchy</td><td>multiple hierarchies，it wasn’t useful and complicated in practice</td><td>single unified hierarchy</td></tr><tr><td>resource allocation management</td><td>basic</td><td>more powerful、dynamic and enhanced resource allocation management，such as the following： • Unified accounting for different types of memory allocations (network and kernel memory, etc) • Accounting for non-immediate resource changes such as page cache write backs • Safer sub-tree delegation to containers</td></tr><tr><td>Performance</td><td>support for multiple hierarchies came at a steep cost</td><td>better</td></tr><tr><td>Scalability</td><td>it seemed to provide a high level of flexibility,  but it wasn’t useful in practice</td><td>provide a high level of flexibility ，new features like PSI</td></tr><tr><td>Security</td><td>the known CVEs, such as cve-2022-0492、cve-2021-4154</td><td>support rootless container</td></tr></tbody></table><p>cgroup v2 has been in development in the Linux Kernel since 2016 and in recent years has matured across the container ecosystem. With Kubernetes 1.25, cgroup v2 support has graduated to general availability.</p><h2 id="What-issues-were-encountered？"><a href="#What-issues-were-encountered？" class="headerlink" title="What issues were encountered？"></a>What issues were encountered？</h2><h3 id="Java-applications"><a href="#Java-applications" class="headerlink" title="Java applications"></a>Java applications</h3><p><a href="https://bugs.openjdk.org/browse/JDK-8146115">JDK-8146115</a> added Hotspot runtime support for JVMs running in Docker containers. At the time Docker used cgroups v1 and, hence, runtime support only includes cgroup v1 controllers.</p><p>JDK-8230305 extended functionality of <a href="https://bugs.openjdk.org/browse/JDK-8146115">JDK-8146115</a> to also detect cgroups v2. That is iff cgroups v2 unified hierarchy is available only, use the cgroups v2 backend. Otherwise fall back to existing cgroups v1 container support.</p><p>require version：jdk8u372, 11.0.16, 15 and later</p><h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h3><p>Currently,  the version of Kubernetes in production is 1.19 and enabling cgroup v2 support for kubelet is proving to be challenging. While a comprehensive upgrade of Kubernetes is being researched and prepared, we are currently focusing on implementing cgroup v2 support specifically for kubelet. This approach allows for a shorter implementation time while laying the foundation for the subsequent comprehensive upgrade.</p><p>To enable cgroup v2 support, several adjustments need to be made to various components:</p><ol><li>Kernel Version: We are currently using kernel version 5.15, which meets the minimum requirement for cgroup v2 (4.14). However, it is recommended to use kernel version 5.2 or newer due to the lack of freezer support in older versions.</li><li>Systemd and Runc: It is highly recommended to run runc with the systemd cgroup driver (<code>runc --systemd-cgroup</code>), although it is not mandatory. To ensure compatibility, it is recommended to use systemd version 244 or later, as older versions do not support delegation of the <code>cpuset</code> controller.</li><li>Kubelet : The vendor for kubelet needs to upgrade the runc version. Currently, the latest fully supported version of runc for cgroup v2 is rc93. To minimize changes, we have chosen rc94 and modified the kubelet code to internally maintain runc rc94. This allows us to merge the necessary cgroup v2-related pull requests. However, in rc95, there are significant changes to the cgroup.Manager interface, which does not align with the principle of minimal changes.</li></ol><p>metrics-server retrieves resource usage information of nodes and pods using kubelet summary and other interfaces. This data is crucial for Horizontal Pod Autoscaling (HPA) based on resource scaling. To eliminate dockershim, the kubelet should utilize the systemd cgroup driver and configure the runtime accordingly.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock</span><br></pre></td></tr></table></figure><ol start="4"><li>Containerd : starting from version 1.4, containerd supports cgroup v2. We have successfully validated the removal of dockershim and conducted thorough testing of business operations in the testing environment. With the successful testing, we will proceed with the production rollout. Similar to kubelet, containerd also requires the systemd cgroup driver. Use the following configuration for the systemd cgroup driver:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.runc]</span><br><span class="line">  ...</span><br><span class="line">  [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.runc.options]</span><br><span class="line">    SystemdCgroup = <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>The configuration of the sandbox image and registry can be customized based on specific requirements.</p><h3 id="Systemd-with-cilium"><a href="#Systemd-with-cilium" class="headerlink" title="Systemd with cilium"></a>Systemd with cilium</h3><p>SystemD versions greater than 245 automatically set the rp_filter value to 1 for all network interfaces. This conflicts with Cilium, which requires rp_filter to be 0 on its interfaces, leading to a disruption in out-of-node IPv4 traffic.</p><p>Therefore, it is crucial to exercise caution before upgrading SystemD, as demonstrated by the failure experienced by Datadog, which served as a significant warning.</p><p>on March 8, 2023, at 06:00 UTC, a security update to systemd was automatically applied to several VMs, which caused a latent adverse interaction in the network stack (on Ubuntu 22.04 via systemd v249) to manifest upon systemd-networkd restarting.Namely, <code>systemd-networkd</code> forcibly deleted the routes managed by the Container Network Interface (CNI) plugin (Cilium) we use for communication between containers. This caused the affected nodes to go offline.</p><p>Additionally, when container runtimes are configured with cgroup v2, the Cilium agent pod is deployed in a separate cgroup namespace. For example, Docker container runtime with cgroupv2 support defaults to private cgroup namespace mode. Due to cgroup namespaces, the Cilium pod’s cgroup filesystem points to a virtualized hierarchy instead of the host cgroup root. Consequently, BPF programs are attached to the nested cgroup root, rendering socket load balancing ineffective for other pods. To address this limitation, work is being done in the Cilium project  to revisit assumptions made around cgroup hierarchies and enable socket load balancing in different environments.</p><p>Don’t worry, these issues have already been fixed by the community.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>During the testing process of Cgroup V2 and removing dockershim in our testing environment, we conducted extensive adaptation and stability tests. Our long-term analysis revealed that the benefits of adopting this technology roadmap far outweigh the initial investment. As part of our plan, we intend to promote the adoption of Cgroup V2-based machines in production. This will involve a meticulous testing and validation process, followed by a gradual rollout in production environments. We will start with offline applications such as logging and big data applications.</p><p>The Cloud Native Computing Foundation’s flagship conference gathers adopters and technologists from leading open source and cloud native communities in Shanghai, China from 26-28 September, 2023.  We are considering submitting a proposal for a presentation at KubeCon 2023, where we will have the opportunity to share the latest developments and insights with the conference attendees.</p><p><a href="https://bugs.openjdk.org/browse/JDK-8230305">https://bugs.openjdk.org/browse/JDK-8230305</a></p><p><a href="https://kubernetes.io/blog/2022/08/31/cgroupv2-ga-1-25/">https://kubernetes.io/blog/2022/08/31/cgroupv2-ga-1-25/</a></p><p><a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html">https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html</a></p><p><a href="https://github.com/cilium/cilium/issues/10645">https://github.com/cilium/cilium/issues/10645</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;With the announcement of CentOS discontinuation by the CentOS community , along with the set dates for service termination, we have put t</summary>
      
    
    
    
    <category term="cgroupv2" scheme="https://zoues.com/categories/cgroupv2/"/>
    
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
    <category term="cncf" scheme="https://zoues.com/tags/cncf/"/>
    
    <category term="almalinux" scheme="https://zoues.com/tags/almalinux/"/>
    
  </entry>
  
  <entry>
    <title>Ziglang简明教程</title>
    <link href="https://zoues.com/posts/5941d835/"/>
    <id>https://zoues.com/posts/5941d835/</id>
    <published>2024-01-14T05:40:08.000Z</published>
    <updated>2024-01-21T02:30:15.984Z</updated>
    
    <content type="html"><![CDATA[<p>这份zig简明教程适合已经有编程基础知识的同学快速了解zig语言，同时也适合没有编程经验但是懂得善用搜索引擎的同学,该文章详细介绍Zig编程语言各种概念，主要包括基础知识、函数、结构体、枚举、数组、切片、控制结构、错误处理、指针、元编程和堆管理等内容。</p><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>命令 <code>zig run my_code.zig</code> 将编译并立即运行你的 Zig 程序。每个单元格都包含一个 Zig 程序，你可以尝试运行它们（其中一些包含编译时错误，你可以注释掉后再尝试）。</p><p>首先需要声明一个 <code>main()</code> 函数来运行代码。</p><p>下面的代码什么都不会做，只是简单的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// comments look like this and go to the end of the line</span><br><span class="line">pub fn main() void &#123;&#125;</span><br></pre></td></tr></table></figure><p>可以使用 内置函数<code>@import</code> 导入标准库，并将命名空间赋值给一个 <code>const</code> 值。Zig 中的几乎所有东西都必须明确地被赋予标识符。你也可以通过这种方式导入其他 Zig 文件，类似地，你可以使用 <code>@cImport</code> 导入 C 文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;hello world!\n&quot;, .&#123;&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：后续会在结构部分部分解释 <code>print</code> 语句中的第二个参数。</p><p>一般用<code>var</code> 来声明变量，同时在大多数情况下，需要带上声明变量类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var x: i32 = 47; // declares &quot;x&quot; of type i32 to be 47.</span><br><span class="line">    std.debug.print(&quot;x: &#123;&#125;\n&quot;, .&#123;x&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>const</code> 声明一个变量的值是不可变的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pub fn main() void &#123;</span><br><span class="line">    const x: i32 = 47;</span><br><span class="line">    x = 42; // error: cannot assign to constant</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Zig 非常严苛，不允许你从外部作用域屏蔽标识符，以防止混淆：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">const x: i32 = 47;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var x: i32 = 42;  // error: redefinition of &#x27;x&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>全局作用域的常量默认为编译时的 “comptime” 值，如果省略了类型，它们就是编译时类型，并且可以在运行时转换为运行时类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">const x: i32 = 47;</span><br><span class="line">const y = -47;  // comptime integer.</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var a: i32 = y; // comptime constant coerced into correct type</span><br><span class="line">    var b: i64 = y; // comptime constant coerced into correct type</span><br><span class="line">    var c: u32 = y; // error: cannot cast negative value -47 to unsigned integer</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果希望在后面设置它，也可以明确选择将其保留为未定义。如果你在调试模式下意外使用它引发错误，Zig 将使用 0XAA 字节填充一个虚拟值，以帮助检测错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">  var x: i32 = undefined;</span><br><span class="line">  std.debug.print(&quot;undefined: &#123;&#125;\n&quot;, .&#123;x&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在某些情况下，如果 Zig 可以推断出类型信息，才允许你省略类型信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var x: i32 = 47;</span><br><span class="line">    var y: i32 = 47;</span><br><span class="line">    var z = x + y; // declares z and sets it to 94.</span><br><span class="line">    std.debug.print(&quot;z: &#123;&#125;\n&quot;, .&#123;z&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是需要注意，整数字面值是编译时类型，所以下面的示例是行不通的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pub fn main() void &#123;</span><br><span class="line">    var x = 47; // error: variable of type &#x27;comptime_int&#x27; must be const or comptime</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>函数可以带参数和返回值，使用<code>fn</code>关键字声明。<code>pub</code>关键字表示函数可以从当前作用域导出，使其它地方可以调用。下面示例是一个不返回任何值的函数（foo）。<code>pub</code>关键字表示该函数可以从当前作用域导出，这就是为什么<code>main</code>函数必须是<code>pub</code>的。你可以像大多数编程语言中一样调用函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo() void &#123;</span><br><span class="line">    std.debug.print(&quot;foo!\n&quot;, .&#123;&#125;);</span><br><span class="line"></span><br><span class="line">    //optional:</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    foo();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面示例是一个返回整数值的函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo() i32 &#123;</span><br><span class="line">    return 47;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var result = foo();</span><br><span class="line">    std.debug.print(&quot;foo: &#123;&#125;\n&quot;, .&#123;result&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Zig不允许你忽略函数的返回值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fn foo() i32 &#123;</span><br><span class="line">    return 47;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    foo(); // error: expression value is ignored</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是你可以将其赋值给丢弃变量 <code>_</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fn foo() i32 &#123;</span><br><span class="line">    return 47;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">  _ = foo();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以声明函数时带上参数的类型，这样函数调用时可以传入参数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo(x: i32) void &#123;</span><br><span class="line">    std.debug.print(&quot;foo param: &#123;&#125;\n&quot;, .&#123;x&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    foo(47);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>结构体通过使用<code>const</code>关键字分配一个名称来声明，它们的赋值顺序可以是任意的，并且可以使用常规的点语法进行解引用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">const Vec2 = struct &#123;</span><br><span class="line">    x: f64,</span><br><span class="line">    y: f64</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var v = Vec2&#123;.y = 1.0, .x = 2.0&#125;;</span><br><span class="line">    std.debug.print(&quot;v: &#123;&#125;\n&quot;, .&#123;v&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结构体可以有默认值；结构体也可以是匿名的，并且可以强制转换为另一个结构体，只要所有的值都能确定：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">const Vec3 = struct&#123;</span><br><span class="line">    x: f64 = 0.0,</span><br><span class="line">    y: f64,</span><br><span class="line">    z: f64</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var v: Vec3 = .&#123;.y = 0.1, .z = 0.2&#125;;  // ok</span><br><span class="line">    var w: Vec3 = .&#123;.y = 0.1&#125;; // error: missing field: &#x27;z&#x27;</span><br><span class="line">    std.debug.print(&quot;v: &#123;&#125;\n&quot;, .&#123;v&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以将函数放入结构体中，使其像面向对象编程中的对象一样工作。这里有一个语法糖，如果你定义的函数的第一个参数为对象的指针，我们称之为”面向对象编程”，类似于Python带self参数的函数。一般约定是通过将变量命名为self来表示。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">const LikeAnObject = struct&#123;</span><br><span class="line">    value: i32,</span><br><span class="line"></span><br><span class="line">    fn print(self: *LikeAnObject) void &#123;</span><br><span class="line">        std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;self.value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var obj = LikeAnObject&#123;.value = 47&#125;;</span><br><span class="line">    obj.print();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们一直传递给<code>std.debug.print</code>的第二个参数是一个元组，它是一个带有数字字段的匿名结构体。在编译时，<code>std.debug.print</code>会找出元组中参数的类型，并生成一个针对你提供的参数字符串的版本，这就是为何Zig知道如何将打印的内容变得漂亮的原因。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;&#123;&#125;\n&quot;, .&#123;1, 2&#125;); #  error: Unused arguments</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h3><p>枚举通过使用<code>const</code>关键字将枚举组以类型方式来声明。</p><p>注意：在某些情况下，可以简化枚举的名称。 其可以将枚举的值设置为整数，但它不会自动强制转换，你必须使用<code>@enumToInt</code>或<code>@intToEnum</code>来进行转换。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">const EnumType = enum&#123;</span><br><span class="line">    EnumOne,</span><br><span class="line">    EnumTwo,</span><br><span class="line">    EnumThree = 3</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;One: &#123;&#125;\n&quot;, .&#123;EnumType.EnumOne&#125;);</span><br><span class="line">    std.debug.print(&quot;Two?: &#123;&#125;\n&quot;, .&#123;EnumType.EnumTwo == .EnumTwo&#125;);</span><br><span class="line">    std.debug.print(&quot;Three?: &#123;&#125;\n&quot;, .&#123;@enumToInt(EnumType.EnumThree) == 3&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数组和切片"><a href="#数组和切片" class="headerlink" title="数组和切片"></a>数组和切片</h3><p>Zig有数组概念，它们是具有在编译时已知长度的连续内存。你可以通过在前面声明类型并提供值列表来初始化它们，同时可以通过数组的<code>len</code>字段访问它们的长度。</p><p>注意：Zig中的数组也是从零开始索引的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var array: [3]u32 = [3]u32&#123;47, 47, 47&#125;;</span><br><span class="line"></span><br><span class="line">    // also valid:</span><br><span class="line">    // var array = [_]u32&#123;47, 47, 47&#125;;</span><br><span class="line"></span><br><span class="line">    var invalid = array[4]; // error: index 4 outside array of size 3.</span><br><span class="line">    std.debug.print(&quot;array[0]: &#123;&#125;\n&quot;, .&#123;array[0]&#125;);</span><br><span class="line">    std.debug.print(&quot;length: &#123;&#125;\n&quot;, .&#123;array.len&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跟golang类似，Zig也有切片（slices），它们的长度在运行时已知。你可以使用切片操作从数组或其他切片构造切片。与数组类似，切片有一个<code>len</code>字段，告诉它的长度。</p><p>注意：切片操作中的间隔参数是开口的（不包含在内）。 尝试访问超出切片范围的元素会引发运行时panic。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var array: [3]u32 = [_]u32&#123;47, 47, 47&#125;;</span><br><span class="line">    var slice: []u32 = array[0..2];</span><br><span class="line"></span><br><span class="line">    // also valid:</span><br><span class="line">    // var slice = array[0..2];</span><br><span class="line"></span><br><span class="line">    var invalid = slice[3]; // panic: index out of bounds</span><br><span class="line"></span><br><span class="line">    std.debug.print(&quot;slice[0]: &#123;&#125;\n&quot;, .&#123;slice[0]&#125;);</span><br><span class="line">    std.debug.print(&quot;length: &#123;&#125;\n&quot;, .&#123;slice.len&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>字符串文字是以null结尾的utf-8编码的const u8字节数组。Unicode字符只允许在字符串文字和注释中使用。</p><p>注意：长度不包括null终止符（官方称为”sentinel termination”）。 访问null终止符是安全的。 索引是按字节而不是Unicode字符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line">const string = &quot;hello 世界&quot;;</span><br><span class="line">const world = &quot;world&quot;;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var slice: []const u8 = string[0..5];</span><br><span class="line"></span><br><span class="line">    std.debug.print(&quot;string &#123;&#125;\n&quot;, .&#123;string&#125;);</span><br><span class="line">    std.debug.print(&quot;length &#123;&#125;\n&quot;, .&#123;world.len&#125;);</span><br><span class="line">    std.debug.print(&quot;null &#123;&#125;\n&quot;, .&#123;world[5]&#125;);</span><br><span class="line">    std.debug.print(&quot;slice &#123;&#125;\n&quot;, .&#123;slice&#125;);</span><br><span class="line">    std.debug.print(&quot;huh? &#123;&#125;\n&quot;, .&#123;string[0..7]&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>const数组可以强制转换为const切片。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo() []const u8 &#123;  // note function returns a slice</span><br><span class="line">    return &quot;foo&quot;;      // but this is a const array.</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;foo: &#123;&#125;\n&quot;, .&#123;foo()&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h3><p>Zig提供了与其他语言类似的if语句、switch语句、for循环和while循环。示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo(v: i32) []const u8 &#123;</span><br><span class="line">    if (v &lt; 0) &#123;</span><br><span class="line">        return &quot;negative&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        return &quot;non-negative&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;positive &#123;&#125;\n&quot;, .&#123;foo(47)&#125;);</span><br><span class="line">    std.debug.print(&quot;negative &#123;&#125;\n&quot;, .&#123;foo(-47)&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>switch方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo(v: i32) []const u8 &#123;</span><br><span class="line">    switch (v) &#123;</span><br><span class="line">        0 =&gt; return &quot;zero&quot;,</span><br><span class="line">        else =&gt; return &quot;nonzero&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    std.debug.print(&quot;47 &#123;&#125;\n&quot;, .&#123;foo(47)&#125;);</span><br><span class="line">    std.debug.print(&quot;0 &#123;&#125;\n&quot;, .&#123;foo(0)&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>for-loop</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var array = [_]i32&#123;47, 48, 49&#125;;</span><br><span class="line"></span><br><span class="line">    for (array) | value | &#123;</span><br><span class="line">        std.debug.print(&quot;array &#123;&#125;\n&quot;, .&#123;value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    for (array) | value, index | &#123;</span><br><span class="line">        std.debug.print(&quot;array &#123;&#125;:&#123;&#125;\n&quot;, .&#123;index, value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    var slice = array[0..2];</span><br><span class="line"></span><br><span class="line">    for (slice) | value | &#123;</span><br><span class="line">        std.debug.print(&quot;slice &#123;&#125;\n&quot;, .&#123;value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    for (slice) | value, index | &#123;</span><br><span class="line">        std.debug.print(&quot;slice &#123;&#125;:&#123;&#125;\n&quot;, .&#123;index, value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>while loop</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var array = [_]i32&#123;47, 48, 49&#125;;</span><br><span class="line">    var index: u32 = 0;</span><br><span class="line"></span><br><span class="line">    while (index &lt; 2) &#123;</span><br><span class="line">        std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;array[index]&#125;);</span><br><span class="line">        index += 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>错误是特殊的联合类型，你可以在函数前面加上 ! 来表示该函数可能返回错误。你可以通过简单地将错误作为正常返回值返回来抛出错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">const MyError = error&#123;</span><br><span class="line">    GenericError,</span><br><span class="line">    OtherError</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn main() !void &#123;</span><br><span class="line">    return MyError.GenericError;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fn wrap_foo(v: i32) void &#123;</span><br><span class="line">    if (foo(v)) |value| &#123;</span><br><span class="line">        std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;value&#125;);</span><br><span class="line">    &#125; else |err| &#123;</span><br><span class="line">        std.debug.print(&quot;error: &#123;&#125;\n&quot;, .&#123;err&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果你编写一个可能出错的函数，当它返回时你必须决定如何处理错误。两个常见的选择是 <code>try</code> 和 <code>catch</code>。<code>try</code> 方式很摆烂，它只是简单地将错误转发为函数的错误。而 <code>catch</code> 需要处理错误。</p><p><code>try</code> 其实就是 <code>catch | err | &#123;return err&#125;</code> 的语法糖。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line">const MyError = error&#123;</span><br><span class="line">    GenericError</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">fn foo(v: i32) !i32 &#123;</span><br><span class="line">    if (v == 42) return MyError.GenericError;</span><br><span class="line">    return v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() !void &#123;</span><br><span class="line">    // catch traps and handles errors bubbling up</span><br><span class="line">    _ = foo(42) catch |err| &#123;</span><br><span class="line">        std.debug.print(&quot;error: &#123;&#125;\n&quot;, .&#123;err&#125;);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    // try won&#x27;t get activated here.</span><br><span class="line">    std.debug.print(&quot;foo: &#123;&#125;\n&quot;, .&#123;try foo(47)&#125;);</span><br><span class="line"></span><br><span class="line">    // this will ultimately cause main to print an error trace and return nonzero</span><br><span class="line">    _ = try foo(42);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们也可以使用 <code>if</code> 来检查错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line">const MyError = error&#123;</span><br><span class="line">    GenericError</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">fn foo(v: i32) !i32 &#123;</span><br><span class="line">    if (v == 42) return MyError.GenericError;</span><br><span class="line">    return v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// note that it is safe for wrap_foo to not have an error ! because</span><br><span class="line">// we handle ALL cases and don&#x27;t return errors.</span><br><span class="line">fn wrap_foo(v: i32) void &#123;    </span><br><span class="line">    if (foo(v)) | value | &#123;</span><br><span class="line">        std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;value&#125;);</span><br><span class="line">    &#125; else | err | &#123;</span><br><span class="line">        std.debug.print(&quot;error: &#123;&#125;\n&quot;, .&#123;err&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    wrap_foo(42);</span><br><span class="line">    wrap_foo(47);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h3><p>Zig使用<code>*</code>表示指针类型，可以通过<code>.*</code>语法访问指针指向的值。示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn printer(value: *i32) void &#123;</span><br><span class="line">    std.debug.print(&quot;pointer: &#123;&#125;\n&quot;, .&#123;value&#125;);</span><br><span class="line">    std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;value.*&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var value: i32 = 47;</span><br><span class="line">    printer(&amp;value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：在Zig中，指针需要正确对齐到它所指向的值的对齐方式。 对于结构体，类似于Java，您可以解引用指针并一次获取字段，使用 . 运算符。需要注意的是，这仅适用于一层间接引用，因此如果您有指向指针的指针，您必须首先解引用外部指针。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">const MyStruct = struct &#123;</span><br><span class="line">    value: i32</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">pub fn printer(s: *MyStruct) void &#123;</span><br><span class="line">    std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;s.value&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var value = MyStruct&#123;.value = 47&#125;;</span><br><span class="line">    printer(&amp;value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Zig允许任何类型（不仅仅是指针）可为空，但请注意它们是基本类型和特殊值 null 的联合体。要访问未包装的可选类型，请使用 .? 字段：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var value: i32 = 47;</span><br><span class="line">    var vptr: ?*i32 = &amp;value;</span><br><span class="line">    var throwaway1: ?*i32 = null;</span><br><span class="line">    var throwaway2: *i32 = null; // error: expected type &#x27;*i32&#x27;, found &#x27;(null)&#x27;</span><br><span class="line"></span><br><span class="line">    std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;vptr.*&#125;); // error: attempt to dereference non-pointer type</span><br><span class="line">    std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;vptr.?.*&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：当我们使用来自C ABI函数的指针时，它们会自动转换为可为空指针。 获得未包装的可选指针的另一种方法是使用 if 语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn nullChoice(value: ?*i32) void &#123;</span><br><span class="line">    if (value) | v | &#123;</span><br><span class="line">        std.debug.print(&quot;value: &#123;&#125;\n&quot;, .&#123;v.*&#125;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        std.debug.print(&quot;null!\n&quot;, .&#123;&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var value: i32 = 47;</span><br><span class="line">    var vptr1: ?*i32 = &amp;value;</span><br><span class="line">    var vptr2: ?*i32 = null;</span><br><span class="line"></span><br><span class="line">    nullChoice(vptr1);</span><br><span class="line">    nullChoice(vptr2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="元编程"><a href="#元编程" class="headerlink" title="元编程"></a>元编程</h3><p>Zig的元编程受几个基本概念驱动：</p><ul><li><p>类型在编译时是有效的值。</p></li><li><p>大多数运行时代码在编译时也能工作。</p></li><li><p>结构体字段的评估是编译时的鸭子类型（duck-typed）。</p></li><li><p>Zig标准库提供了执行编译时反射的工具。</p><p>下面是元编程的一个示例：</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn foo(x : anytype) @TypeOf(x) &#123;</span><br><span class="line">    // note that this if statement happens at compile-time, not runtime.</span><br><span class="line">    if (@TypeOf(x) == i64) &#123;</span><br><span class="line">        return x + 2;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return 2 * x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var x: i64 = 47;</span><br><span class="line">    var y: i32 =  47;</span><br><span class="line"></span><br><span class="line">    std.debug.print(&quot;i64-foo: &#123;&#125;\n&quot;, .&#123;foo(x)&#125;);</span><br><span class="line">    std.debug.print(&quot;i32-foo: &#123;&#125;\n&quot;, .&#123;foo(y)&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是泛型类型的一个示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn Vec2Of(comptime T: type) type &#123;</span><br><span class="line">    return struct&#123;</span><br><span class="line">        x: T,</span><br><span class="line">        y: T</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">const V2i64 = Vec2Of(i64);</span><br><span class="line">const V2f64 = Vec2Of(f64);</span><br><span class="line"></span><br><span class="line">pub fn main() void &#123;</span><br><span class="line">    var vi = V2i64&#123;.x = 47, .y = 47&#125;;</span><br><span class="line">    var vf = V2f64&#123;.x = 47.0, .y = 47.0&#125;;</span><br><span class="line">    </span><br><span class="line">    std.debug.print(&quot;i64 vector: &#123;&#125;\n&quot;, .&#123;vi&#125;);</span><br><span class="line">    std.debug.print(&quot;f64 vector: &#123;&#125;\n&quot;, .&#123;vf&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过这些概念，我们可以构建非常强大的泛型类型！</p><h3 id="堆管理"><a href="#堆管理" class="headerlink" title="堆管理"></a>堆管理</h3><p>Zig为我们提供了与堆交互的多种方式，通常要求您明确选择使用哪种方式。它们都遵循下述相同的模式：</p><ol><li>创建一个分配器工厂结构体。</li><li>检索由分配器工厂创建的<code>std.mem.Allocator</code>结构体。</li><li>使用<code>alloc/free</code>和<code>create/destroy</code>函数来操作堆。</li><li>（可选）销毁分配器工厂。</li></ol><p>这么处理的目的是：</p><ul><li>为了阻止您过度使用堆。</li><li>这使得调用堆的任何东西（基本上是可失败的操作）都是显式的。</li><li>您可以仔细调整权衡，并使用标准数据结构而无需重写标准库。</li><li>您可以在测试中运行非常安全的分配器，并在发布&#x2F;生产环境中切换到不同的分配器。</li></ul><p>好的，但是你也可以偷点懒。你是不是想一直使用jemalloc？ 只需选择一个全局分配器，并在所有地方使用它（请注意，某些分配器是线程安全的，而某些则不是）。</p><p>在这个示例中，我们将使用<code>std.heap.GeneralPurposeAllocator</code>工厂创建一个具有多种特性（包括泄漏检测）的分配器，并看看它是如何组合在一起的。</p><p>最后一件事，这里使用了<code>defer</code>关键字，它非常类似于Go语言中的<code>defer</code>关键字！还有一个<code>errdefer</code>关键字，如果需要了解更多信息，请查阅Zig文档。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">// factory type</span><br><span class="line">const Gpa = std.heap.GeneralPurposeAllocator(.&#123;&#125;);</span><br><span class="line"></span><br><span class="line">pub fn main() !void &#123;</span><br><span class="line">    // instantiates the factory</span><br><span class="line">    var gpa = Gpa&#123;&#125;;</span><br><span class="line">    </span><br><span class="line">    // retrieves the created allocator.</span><br><span class="line">    var galloc = &amp;gpa.allocator;</span><br><span class="line">    </span><br><span class="line">    // scopes the lifetime of the allocator to this function and</span><br><span class="line">    // performs cleanup; </span><br><span class="line">    defer _ = gpa.deinit();</span><br><span class="line"></span><br><span class="line">    var slice = try galloc.alloc(i32, 2);</span><br><span class="line">    // uncomment to remove memory leak warning</span><br><span class="line">    // defer galloc.free(slice);</span><br><span class="line">    </span><br><span class="line">    var single = try galloc.create(i32);</span><br><span class="line">    // defer gallo.destroy(single);</span><br><span class="line"></span><br><span class="line">    slice[0] = 47;</span><br><span class="line">    slice[1] = 48;</span><br><span class="line">    single.* = 49;</span><br><span class="line"></span><br><span class="line">    std.debug.print(&quot;slice: [&#123;&#125;, &#123;&#125;]\n&quot;, .&#123;slice[0], slice[1]&#125;);</span><br><span class="line">    std.debug.print(&quot;single: &#123;&#125;\n&quot;, .&#123;single.*&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>现在我们已经掌握了相当大的Zig基础知识。没有覆盖的一些（非常重要的）内容包括：</p><ul><li>测试（Zig使得编写测试非常容易）</li><li>标准库</li><li>内存模型（Zig在分配器方面没有倾向性）</li><li>异步编程（Zig 的异步特性在编译器中出现了性能退化，在 0.11 版本的 Zig 中已经不存在了，并且在 Zig 0.12 版本中也可能不会出现。）</li><li>交叉编译</li><li><code>build.zig</code> 文件</li></ul><p>如果想要了解更多细节，请查阅最新的文档：</p><ul><li><a href="https://ziglang.org/documentation/master/">https://ziglang.org/documentation/master/</a></li><li><a href="https://gist.github.com/ityonemo/769532c2017ed9143f3571e5ac104e50">https://gist.github.com/ityonemo/769532c2017ed9143f3571e5ac104e50</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这份zig简明教程适合已经有编程基础知识的同学快速了解zig语言，同时也适合没有编程经验但是懂得善用搜索引擎的同学,该文章详细介绍Zig编程语言各种概念，主要包括基础知识、函数、结构体、枚举、数组、切片、控制结构、错误处理、指针、元编程和堆管理等内容。&lt;/p&gt;
&lt;h3 id</summary>
      
    
    
    
    <category term="Ziglang简明教程" scheme="https://zoues.com/categories/Ziglang%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/"/>
    
    
    <category term="zig" scheme="https://zoues.com/tags/zig/"/>
    
  </entry>
  
  <entry>
    <title>OpenAI关于Kubernetes集群近万节点的生产实践</title>
    <link href="https://zoues.com/posts/1df3dc63/"/>
    <id>https://zoues.com/posts/1df3dc63/</id>
    <published>2021-01-28T00:40:08.000Z</published>
    <updated>2024-01-20T12:01:27.441Z</updated>
    
    <content type="html"><![CDATA[<p>OpenAI已经将Kubernetes集群规模扩展至7500个节点，为大型神经网络模型（如GPT-3，CLIP和DALL·E）及小型实验性研究提供了可扩展的基础架构。 很少将单个Kubernetes集群扩展到如此规模，为此进行了一些必要的改进，但好处是单一的基础架构使我们的机器学习研究团队可以在不修改代码的前提下，快速扩展以缩短实验时间、加速研发进度。</p><hr><p>作者：Benjamin Chess、Eric Sigler</p><p>译者：zouyee</p><p>原文：<a href="https://openai.com/blog/scaling-kubernetes-to-7500-nodes/">https://openai.com/blog/scaling-kubernetes-to-7500-nodes/</a></p><p><img src="https://s3.ax1x.com/2021/01/28/yS7JHA.png"></p><p>自上一篇有关扩展到2500个节点的文章以来，我们一直在不断扩展基础架构以满足研究人员的需求，并在此过程中学习了许多其他相关知识。 该篇文章总结了相关经验，以便Kubernetes社区中的其他人可以从中受益，接下来介绍，需要解决的问题。</p><h4 id="一、工作负载"><a href="#一、工作负载" class="headerlink" title="一、工作负载"></a>一、工作负载</h4><p>首先需要说明的是，针对工作负载，我们在Kubernetes集群上运行的应用程序和硬件与其他公司中的场景完全不同。我们面临的问题和相应的解决方案可能与读者所处的实际场景不是太一致。</p><p>大型的机器学习作业可以访问多个节点，及每个节点上的所有硬件资源，因此运行效率最高。允许GPU使用NVLink进行交叉通信，或者GPU使用GPUDirect与NIC通信。因此，对于我们的许多工作负载，单个pod占据了整个节点，因此调度不涉及任何NUMA，CPU或PCIE资源抢占。当前的集群具有完整的双向带宽互通，因此无需考虑任何网络拓扑。因此，调度程序的压力相对较低。</p><p>因为一个新的任务可能包含数百个Pod调度的需求，kube-scheduler存在毛刺现象。</p><p><img src="https://s3.ax1x.com/2021/01/28/yS7GBd.png"></p><p>最大的job是运行MPI（并行计算），job中的所有Pod都工作在同一个MPI通信器中。任何Pod的消亡，都会导致整个job暂停，并重新启动。job定期备份相关信息（即checkpoint），在重新启动时从最近的备份信息处恢复。</p><p>我们不完全依赖Kubernetes进行负载平衡。我们的七层流量很少，因为不需要进行A &#x2F; B测试，蓝绿升级或金丝雀发布等。 Pod通过SSH与其他Pod的MPI直接通信(这部分貌似有点疑问)，而不是<code>service endpoint</code>。服务发现功能相对有限，因为我们只执行一次查找，即在工作启动时（pod刚参与MPI时）。</p><p>大多数job都与Blob类型存储进行交互，通常直接向Blob传输一些数据集的分片，或将其缓存到本地盘。我们也使用了一些PersistentVolumes，但是blob类型存储具有更好的伸缩性，并且不需要挂载、卸载操作。</p><p>超级计算团队努力致力于提供生产级别的计算基础架构，当前在该集群上运行的应用寿命较短，开发人员正在快速迭代中。任何时候都有可能出现新的应用场景，这需要我们对趋势进行预判，并做出适当折衷的设想。</p><hr><h4 id="二、网络"><a href="#二、网络" class="headerlink" title="二、网络"></a>二、网络</h4><p>随着集群中节点和Pod数量的增加，我们发现<code>Flannel</code>难以满足需求。转而使用主机pod网络技术进行Azure VMSSes和相关CNI插件的IP配置。这使我们能够在Pod上获得主机级别的网络吞吐量。</p><p>我们改用基于别名的IP寻址的另一个原因是，在我们最大的集群上，我们可能随时有大约200,000个IP地址正在使用。在测试基于路由的Pod网络时，我们发现路由数量存在明显的限制。</p><p>改造SDN或路由引擎虽然麻烦，但它会使我们的网络设置变得简单。无需任何其他适配器即可添加VPN或隧道。同时我们不必担心数据包分片，因为网络的某些部分的MTU较低。网络策略和流量监控非常简单；数据包的来源和目的地没有任何歧义。</p><p>我们在主机上使用iptables来跟踪每个命名空间和pod的网络资源使用情况。这使研究人员可以可视化其网络使用。由于我们的许多实验都具有独特的外部和Pod内部通信模式，因此对于调查可能出现瓶颈的位置很有用。</p><p>iptables mangle规则可用于标记任意符合特定条件的数据包。如下是我们用来检测流量是内部流量还是外部流量的规则。 FORWARD规则涵盖来自Pod的流量，以及来自主机的INPUT和OUTPUT流量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iptables -t mangle -A INPUT ! -s 10.0.0.0/8 -m comment --comment &quot;iptables-exporter openai traffic=internet-in&quot;</span><br><span class="line">iptables -t mangle -A FORWARD ! -s 10.0.0.0/8 -m comment --comment &quot;iptables-exporter openai traffic=internet-in&quot;</span><br><span class="line">iptables -t mangle -A OUTPUT ! -d 10.0.0.0/8 -m comment --comment &quot;iptables-exporter openai traffic=internet-out&quot;</span><br><span class="line">iptables -t mangle -A FORWARD ! -d 10.0.0.0/8 -m comment --comment &quot;iptables-exporter openai traffic=internet-out&quot;</span><br></pre></td></tr></table></figure><p>一旦标记，iptables将启动计数器以跟踪与此规则匹配的字节和数据包。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">% iptables -t mangle -L -v</span><br><span class="line">Chain FORWARD (policy ACCEPT 50M packets, 334G bytes)</span><br><span class="line"> pkts bytes target     prot opt in     out     source               destination</span><br><span class="line">....</span><br><span class="line">1253K  555M            all  --  any    any     anywhere            !10.0.0.0/8           /* iptables-exporter openai traffic=internet-out */</span><br><span class="line">1161K 7937M            all  --  any    any    !10.0.0.0/8           anywhere             /* iptables-exporter openai traffic=internet-in */</span><br></pre></td></tr></table></figure><p>我们使用基于Prometheus的<code>iptables-exporter</code>的方案，然后将其接入到我们的监控系统。 </p><p><img src="https://s3.ax1x.com/2021/01/28/yS7tAI.png"></p><p>我们网络模型的一个特别的地方是，我们向研究人员公开了节点，容器和服务网络CIDR范围。 我们有一个辐射状网络模型，并使用本机节点和Pod CIDR范围来路由该流量。 研究人员连接到中枢节点，从那里可以访问任何单个集群。 但是集群本身无法相互通信。 这样可以确保集群间相互隔离，且没有跨集群的依存关系以破坏隔离（译者表示…）。</p><p>我们使用主机<code> NAT</code>来转换服务网络CIDR，以处理来自集群外部的流量。 这种设置使我们的研究人员在选择实验方式和选择哪种网络配置上具有极大的灵活性。</p><hr><h5 id="三、API-Server"><a href="#三、API-Server" class="headerlink" title="三、API Server"></a>三、API Server</h5><p>Kubernetes的API Server和etcd集群是集群健康运行的关键组件，因此我们特别注意这些系统上的压力。 我们使用kube-prometheus项目提供的Grafana以及其他内部仪表板。 我们发现针对API Server的HTTP（如429、5xx等状态）告警还是很有效的。</p><p><img src="https://s3.ax1x.com/2021/01/28/yS78nH.png"></p><p>尽管大多数人在k8s集群内运行API Server，但我们选择在集群外运行。 etcd和API Server服务都在它们自己的专用节点上运行。 我们最大的集群运行了5个API  Server和5个etcd节点，以分散负载并最大程度地降低影响（如果其中一台发生故障）。 自从我们在上一篇文章中将Kubernetes Events写入到其他etcd集群以来，我们在etcd方面没有遇到任何麻烦。 API Server是无状态的，通常很容易在自愈实例组或规模集中运行。 我们尚未尝试建立etcd集群的任何自愈等自动化功能。</p><p>API  Server会占用相当大的内存，并且会随着集群中节点的数量线性上升。 对于具有7500个节点的集群，我们观察到每个API Server最多使用了70GB。</p><p><img src="https://s3.ax1x.com/2021/01/28/yS71je.png"></p><p>API Server上的另一大压力是API上的WATCH能力，例如<code>kubelet</code>和<code> node-exporter</code>。 当从集群中添加或删除节点时，将触发此WATCH。 并且由于通常每个节点本身都通过<code>kube-proxy</code>监视<code>kubelet</code>服务（译者：可通过本地LB优化，并分配固定几个Master），因此这些响应所需的带宽为节点的二次方，有时甚至达到1GB &#x2F; s或更高。 在Kubernetes 1.17中的EndpointSlices特性带来巨大的优化，使此负载降低了1000倍。</p><p><img src="https://s3.ax1x.com/2021/01/28/yS7NNt.png"></p><p>通常，我们密切关注任何随集群大小扩展的API Server请求。 我们尝试避免让任何DaemonSet与API Server进行交互。 在确实需求更改所有节点的监控组件时，引入中间缓存服务（例如Datadog Cluster Agent）似乎成了一种避免集群范围瓶颈的最佳实践。</p><p>随着集群数量的增长，我们对集群的自动伸缩操作逐步减少。 有时自动伸缩超标时，我们就会遇到麻烦。 当新节点加入集群时，就会产生许多请求，并且一次添加数百个节点可能会使API Server服务过载。</p><hr><h5 id="四、监控"><a href="#四、监控" class="headerlink" title="四、监控"></a>四、监控</h5><p>我们使用Prometheus收集指标，并使用Grafana配置图形界面，管理仪表板和警报。我们从部署<code>kube-prometheus</code>项目开始，该项目收集各种指标，并提供良好的仪表板以完成可视化。随着时间的推移，我们添加了许多自己特有的仪表板，指标和警报。</p><p>随着节点日益增多，我们发现Prometheus收集的大量指标毫无用处。尽管kube-prometheus公开了许多有用的数据，但其中有部分我们从未使用过。我们使用Prometheus接口<code>删除</code>其中的某些指标。</p><p>一段时间以来，我们一直在努力解决一个问题，即Prometheus会消耗越来越多的内存，直到最终OOM。即使在设置了超大内存容量之后，这种情况似乎仍会发生（译者：该问题应该是发生在旧版本）。更糟糕的是，当它崩溃时，启动后需要花费很多时间进行恢复。</p><p>最终，我们找到了这些OOM的来源，是Grafana和Prometheus之间的交互，其中Grafana调用Prometheus接口<code>/api/v1/series</code>查询。<code> /api/v1/series</code>接口获取所有监控指标，这将带来内存的持续增长。我们改进了Prometheus，使其在Context中包含此超时控制。</p><p>虽然Prometheus崩溃的频率降低了很多，但在确实需要重新启动它的时候，WAL恢复仍然是一个问题。在Prometheus收集新指标和为查询提供服务之前，通常需要花费很长时间来恢复所有WAL日志。在Robust Perception的帮助下，我们发现通过配置GOMAXPROCS &#x3D; 24进行优化。 Prometheus会在WAL重放期间尝试使用所有内核，而对于具有大量内核的服务器来说，抢占会削减性能。</p><hr><h5 id="五、健康检查"><a href="#五、健康检查" class="headerlink" title="五、健康检查"></a>五、健康检查</h5><p>对于规模如此大的集群，当然需要依靠自动化来检测和删除集群中行为异常的节点。 随之逐步深入，我们已经建立了一套完善的健康检查系统。</p><h5 id="a-被动检查"><a href="#a-被动检查" class="headerlink" title="a. 被动检查"></a>a. 被动检查</h5><p>（译者：可以将之称为性能监控）某些运行状况检查是被动的，始终在所有节点上运行。它们监视基本的系统资源，例如网络可达性，磁盘损坏或磁盘已满或GPU错误等。 GPU会出现多种不同的问题，但一个比较常见的错误是<code>无法纠正的ECC错误</code>。 Nvidia的数据中心GPU管理器（DCGM）工具使查询此错误和许多其他<code>Xid</code>错误变得容易了许多。我们跟踪这些错误的一种方法是通过<code>dcgm-exporter</code>将指标抓取到我们的监控系统Prometheus中。其为DCGM_FI_DEV_XID_ERRORS指标。此外，NVML设备查询API公开了有关GPU的运行状况和操作的详细信息。</p><p>一旦我们检测到错误，通常可以通过重置GPU或系统来修复它们。</p><p>健康检查的另一种形式是跟踪来自上游云提供商的维护事件。大多数云提供商都提供了一种方法来了解当前虚拟机是否由于即将发生的维护事件而导致的中断。如安装升级补丁、替换硬件等。</p><p>这些被动运行的监控运行在所有节点上。如果健康检查开始失败，该节点将自动建立报警，对于更严重的健康检查故障，我们还将尝试驱逐容器，该操组由Pod本身决定，可以通过Pod Disruption Budget进行配置，以决定是否允许这种驱逐。</p><h5 id="b-GPU动态测试"><a href="#b-GPU动态测试" class="headerlink" title="b. GPU动态测试"></a>b. GPU动态测试</h5><p>不幸的是，并非所有GPU问题都表现为通过DCGM可见的错误代码。我们已经建立了自己的测试库，这些测试库可以利用GPU来捕获其他问题，并确保硬件和驱动程序的运行情况符合预期。这些测试无法在后台运行，它们需要在几秒钟或几分钟内独占GPU。</p><p>所有节点都以<code>preflight</code>污点和标签加入集群。此污点会阻止在节点上调度常规Pod。将DaemonSet配置为在带有此标签的节点上运行预检测试Pod。成功完成测试后，测试本身将去除<code>preflight</code>污点和标签，然后该节点即可用于常规用途。</p><p>随后，我们将在节点的生命周期内定期运行这些测试。我们以CronJob方式运行，使其可以在群集中的任何可用节点上运行。</p><hr><h5 id="五、资源配额及用量"><a href="#五、资源配额及用量" class="headerlink" title="五、资源配额及用量"></a>五、资源配额及用量</h5><p>随着我们集群规模的不断扩大，然而研究人员开始发现自己难以获得分配的所有容量。 传统的调度系统具有许多不同的能力以确保团队之间公平地运行任务，而Kubernetes则没有。我们从这些调度系统中获得了灵感，并以Kubernetes原生的方式构建了一些功能。</p><p><em><strong>污点</strong></em></p><p>我们在每个集群中都有一个服务，即<code>team-resource-manager</code>，它具有多种功能。 它的数据源是ConfigMap，它为在给定集群中具有容量的所有研究团队指定元组（节点选择器，要应用的团队标签，分配数量）。 它使用openai.com&#x2F;team&#x3D;teamname:NoSchedule调整适当数量的节点。</p><p><code>team-resource-manager</code>还配置一个<code>admission webhook</code>(译者：即准入服务插件)服务，以便在提交每个作业时，根据提交者的团队成员身份应用相应的容忍度。 通过使用污点，我们可以灵活地约束Kubernetes Pod Scheduler，例如允许对优先级较低的Pod允许<code>任意</code>容忍，这允许团队在无需强力协调的情况下资源共享。</p><p><em><strong>CPU &amp; GPU balloons</strong></em></p><p>除了使用cluster-autoscaler动态扩展虚拟机集群外，我们还使用它来管理（删除和重新添加）集群中不正常的节点。为此，我们将激情的<code>最小</code>设置为零，并将集群的<code>最大</code>设置为可用容量。但是，如果cluster-autoscaler看到空闲节点，则将尝试缩小到仅所需的容量。由于多种原因（VM启动延迟，预分配的成本，上述API Server的影响），这种空闲扩展并不理想。</p><p>因此，我们为CPU和GPU主机引入了balloons Deployment。该Deployment包含一个具有<code>最大值</code>数量的低优先级容器配置。这些Pod占用了节点内的资源，因此自cluster-autoscaler不会将其视为空闲。但是，由于它们的优先级较低，因此调度程序可以立即将其逐出，以便为实际工作腾出空间。 （我们选择使用Deployment而不是DaemonSet，以避免将DaemonSet视为节点上的空闲工作负载。）</p><p>需要注意的一件事是，我们使用容器抗亲和力来确保容器在节点上均匀分布。自Kubernetes 1.18起已更正了该算法的性能问题。</p><hr><h5 id="六、成组调度-Gang-scheduling"><a href="#六、成组调度-Gang-scheduling" class="headerlink" title="六、成组调度(Gang scheduling)"></a>六、成组调度(Gang scheduling)</h5><p>我们的实验通常涉及一个或多个StatefulSet，每个StatefulSet都在训练工作的不同部分进行。对于优化器，研究人员需要在进行任何训练之前调度完StatefulSet的所有pod（因为我们经常在优化器成员之间使用MPI进行协作，并且MPI对组成员身份更改很敏感）。</p><p>但是，默认情况下，Kubernetes并不一定要优先执行一个StatefulSet的请求。例如，如果两个实验作业各自请求集群容量的100％，但Kubernetes可能只调度每个实验Pod的一半，从而导致调度僵局，这两个实验作业都无法完成。</p><p>我们尝试了实现自定义调度程序，但是遇到了一些极端情况，这些情况导致与常规Pod的调度方式发生冲突。 Kubernetes 1.18引入了Kubernetes framwork plugin架构，这使得在本地添加此类功能变得更加容易。我们最近引入Coscheduling插件解决此问题。</p><hr><h5 id="七、结论"><a href="#七、结论" class="headerlink" title="七、结论"></a>七、结论</h5><p>在扩展Kubernetes集群时，仍有许多问题需要解决。 其中一些包括：</p><p>a. 监控指标</p><p>就我们的规模而言，Prometheus的内置TSDB存储引擎的压缩速度很慢，并且每次重新启动时都需要花费很长的时间来恢复WAL（Write-Ahead-Log），这给我们带来了很大的麻烦。 我们正在迁移到其他与Prometheus兼容的存储和查询引擎。 期待将来有关它如何发展的博客文章！</p><p>b. Pod网络流量整形</p><p>当我们扩展群集时，每个Pod都会被计算为具有一定数量的Internet带宽，那么所有Pod总体流量将非常惊人，因而需要引入流量整形技术，防止网络风暴、流量泛滥等问题。</p><p>我们发现Kubernetes是满足我们研究需求的异常灵活的平台。 它具有扩展能力，可以满足我们要求的最苛刻的工作负载。 尽管还有很多地方需要改进，但OpenAI的超级计算团队将继续探索Kubernetes如何扩展。 </p><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li>[scaling-kubernetes-to-7500-nodes](<a href="https://openai.com/blog/scaling-kubernetes-to-7500-nodes/%EF%BC%89">https://openai.com/blog/scaling-kubernetes-to-7500-nodes/）</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;OpenAI已经将Kubernetes集群规模扩展至7500个节点，为大型神经网络模型（如GPT-3，CLIP和DALL·E）及小型实验性研究提供了可扩展的基础架构。 很少将单个Kubernetes集群扩展到如此规模，为此进行了一些必要的改进，但好处是单一的基础架构使我们的</summary>
      
    
    
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes废弃PodSecurityPolicy后续</title>
    <link href="https://zoues.com/posts/aa6cf752/"/>
    <id>https://zoues.com/posts/aa6cf752/</id>
    <published>2021-01-21T00:40:08.000Z</published>
    <updated>2024-01-20T12:01:27.443Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes社区将在1.21版本中弃用PSP，并将1.25版本中移除该API。目前CNCF生态圈类似项目：Kyverno与Open Policy Agen(OPA).</p><p>PodSecurityPolicy是集群级别的Pod安全策略，其对Pod的操作进行细粒度的授权。在Kubernetes架构中以Admission Controller（准入控制，类似NamespaceLifecycle、ResourceQuota等），通俗来讲就是一种写入前检查插件</p><hr><h4 id="一、PSP困境"><a href="#一、PSP困境" class="headerlink" title="一、PSP困境"></a>一、PSP困境</h4><p>当前PodSecurityPolicy特性存在以下问题：</p><ol><li>授权模型存在缺陷</li><li>功能易开难关</li><li>API接口缺乏一致性及扩展性,如MustRunAsNonRoot、AllowPrivilegeEscalation此类配置</li><li>无法处理动态注入的side-car（如knative）</li><li>在CI&#x2F;CD场景难以落地</li></ol><hr><h4 id="二、备选方案"><a href="#二、备选方案" class="headerlink" title="二、备选方案"></a>二、备选方案</h4><h5 id="Kyverno简介"><a href="#Kyverno简介" class="headerlink" title="Kyverno简介"></a>Kyverno简介</h5><p>Kyverno是为Kubernetes设计的策略引擎（CNCF sandbox项目）。其具备以下功能：</p><ul><li><p>相关策略类似Kubernetes对象，上手容易</p></li><li><p>配置管理便利</p></li><li><p>为Kubernetes资源的策略进行声明式验证，更改和生成资源配置。</p></li><li><p>在Kubernetes集群中作为动态准入控制器运行。</p></li><li><p>可以使用资源种类，名称和标签选择器来匹配资源。名称中支持通配符等</p></li></ul><p>当前采纳该方案的开源项目：fluxcd v2等</p><h5 id="OPA简介"><a href="#OPA简介" class="headerlink" title="OPA简介"></a>OPA简介</h5><p>Open Policy Agent（即OPA, CNCF孵化项目）, 为策略决策需求提供了一个统一的框架。它将策略决策从软件业务逻辑中解耦剥离，将策略定义、决策过程抽象为通用模型，实现了一个通用策略引擎，</p><p>其可用于微服务、Kubernetes、 CI&#x2F;CD、API网关等应用场景。</p><p>OPA可以通过sidecar、外部服务或是依赖库的方式与已有的软件系统进行集成。OPA 可以接受任何类型的结构化数据，决策流程如下图所示：</p><p><img src="https://s3.ax1x.com/2021/01/20/sRWx7d.png"></p><p>OPA通过数据输入和策略来进行决策，决策过程和数据无关。例如：</p><ul><li>判断某用户可以访问哪些资源</li><li>允许哪些子网对外访问</li><li>工作负载可以部署在哪个集群</li><li>可以使用哪些镜像</li><li>容器可以使用哪些系统功能</li><li>什么时间可以访问等</li></ul><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li>[deprecate PSP](<a href="https://github.com/kubernetes/kubernetes/pull/9717%EF%BC%89">https://github.com/kubernetes/kubernetes/pull/9717）</a></li><li><a href="https://docs.google.com/document/d/1VKqjUlpU888OYtIrBwidL43FOLhbmOD5tesYwmjzO4E/edit#">PodSecurityPolicy Options</a></li><li><a href="https://servicesblog.redhat.com/2019/10/16/open-policy-agent-part-i-the-introduction/">redhat关于OPA系列</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Kubernetes社区将在1.21版本中弃用PSP，并将1.25版本中移除该API。目前CNCF生态圈类似项目：Kyverno与Open Policy Agen(OPA).&lt;/p&gt;
&lt;p&gt;PodSecurityPolicy是集群级别的Pod安全策略，其对Pod的操作进行细</summary>
      
    
    
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes调度由浅入深：框架</title>
    <link href="https://zoues.com/posts/27bb006d/"/>
    <id>https://zoues.com/posts/27bb006d/</id>
    <published>2021-01-19T13:40:08.000Z</published>
    <updated>2024-01-20T12:01:27.437Z</updated>
    
    <content type="html"><![CDATA[<p>今天zouyee先带各位盘点CNCF上周的一些有趣的事情：</p><ol><li><p>Kubernetes社区GB代表选举结束 Paris Pittman当选</p></li><li><p>CNCF孵化项目OPA进入毕业流程</p></li><li><p>上周<code>helm</code>项目发布v3.5.0功能性版本</p></li><li><p>CoreDNS项目通过Docker镜像仓库放开拉取限制的申请</p></li></ol><p>书接上文《Kubernetes调度系统由浅入深系列：初探》，今天zouyee为大家带来《kuberneter调度由浅入深：框架》，该系列对应版本为<code>1.20.+</code>.</p><hr><h4 id="一、前文回顾"><a href="#一、前文回顾" class="headerlink" title="一、前文回顾"></a>一、前文回顾</h4><p>在《Kubernetes调度系统由浅入深系列：初探》中，给出整体的交互图，来构建Pod调度的直观感受，我们拓展了一下交互图，如下所示。</p><p>注：该交互图非专业UML，还请谅解。</p><p><img src="https://s3.ax1x.com/2021/01/19/sgNXVJ.png" alt="图1 交互流程图"></p><p>上述以创建一个Pod为例，简要介绍调度流程：</p><ol><li><p>用户通过命令行创建Pod(选择直接创建Pod而不是其他workload，是为了省略kube-controller-manager)</p></li><li><p>kube-apiserver经过对象校验、admission、quota等准入操作，写入etcd</p></li><li><p>kube-apiserver将结果返回给用户</p></li><li><p>同时kube-scheduler一直监听节点、Pod事件等（流程1）</p></li><li><p><strong>kube-scheduler将spec.nodeName的pod加入到调度队列中，调度系统选择pod，进入调度周期（本文介绍内容）（流程2-3）</strong></p></li><li><p>kube-scheduler将pod与得分最高的节点进行binding操作（流程4）</p></li><li><p>kube-apiserver将binding信息写入etcd</p></li><li><p>kubelet监听分配给自己的Pod，调用CRI接口进行Pod创建（该部分内容后续出系列，进行介绍）</p></li><li><p>kubelet创建Pod后，更新Pod状态等信息，并向kube-apiserver上报</p></li><li><p>kube-apiserver写入数据</p></li></ol><h5 id="二、框架背景"><a href="#二、框架背景" class="headerlink" title="二、框架背景"></a>二、框架背景</h5><p>​Kubernetes 随着功能的增多，代码与逻辑也日益复杂。代码体量及复杂度的提升必然带来维护成本的增加，隐形的增加错误定位和修复的难度。旧版本的Kubernetes调度程序（<strong>1.16前</strong>）提供了webhooks进行扩展。但有以下缺陷：</p><ul><li><p>用户可以扩展的点比较有限，位置比较固定，无法支持灵活的扩展与调配，例如只能在执行完默认的 Filter 策略后才能调用。</p></li><li><p>调用扩展接口使用 HTTP 请求，其受到网络影响，性能远低于本地的函数调用。同时每次调用都需要将 Pod 和 Node 的信息进行 序列化与反序列化 操作，会进一步降低性能。</p></li><li><p>Pod当前的相关信息，无法及时传递（利用调度Cache）。</p></li></ul><p>为了解决上述问题，使调度系统代码精简、扩展性更好，社区从<code> Kubernetes 1.16</code> 版本开始, 引入了一种新的调度框架- Scheduling Framework 。</p><p>Scheduling Framework 在原有调度流程的基础之上, 定义了丰富的扩展点接口，开发者可以通过实现扩展点所定义的接口来实现插件，将插件注册到扩展点。Scheduling Framework 在执行调度流程时，运行到相应的扩展点时，执行用户注册的插件，生成当前阶段的结果。通过这种方式来将用户的调度逻辑集成到 Scheduling Framework 中。Scheduling Framework明确了以下目标：</p><ul><li>扩展性：调度更具扩展性</li><li>维护性：将调度器的一些特性移到插件中</li><li>功能性<ul><li>框架提供扩展</li><li>提供一种机制来接收插件结果并根据接收到的结果继续或终止</li><li>提供一种机制处理错误与插件通信</li></ul></li></ul><h5 id="三、框架原理"><a href="#三、框架原理" class="headerlink" title="三、框架原理"></a>三、框架原理</h5><p>​Framework 的调度流程是分为两个阶段：</p><ul><li>调度阶段是同步执行的，同一个周期内只有一个 scheduling cycle，线程安全</li><li>绑定阶段(gouroutine)是异步执行的，同一个周期内可能会有多个 binding cycle在运行，线程不安全</li></ul><p>在介绍Framework 的调度流程之前，先介绍上图的调度流程，即schedulerOne的处理逻辑：</p><p><strong>a. 调度阶段</strong></p><pre><code> 1. **过滤**操作即findNodesThatFitPod函数 - 执行PreFilterPlugins - 执行FilterPlugins - 执行扩展 Filter - 若出现FitError，执行PostFilter 2. **评分**操作即prioritizeNodes函数     - 执行PreScorePlugins     - 执行ScorePlugins     - 执行扩展Prioritize 3. 挑选节点即select函数（符合条件节点，按照评分排序及采样选择） 4. 节点预分配即assume（只是预先分配，可收回） 5. 相关调度数据缓存即RunReservePlugins，从该节点开始，后续阶段发生错误，需要调用UnReserve，进行回滚（类似事务） 6.  执行准入操作即RunPermitPlugins</code></pre><p><strong>b. 绑定阶段</strong></p><pre><code>1. 执行WaitOnPermit，失败时调用RunReservePluginsUnreserve 2. 执行预绑定即RunPreBindPlugins，失败时调用RunReservePluginsUnreserve 3. 执行扩展bingding即extendersBinding，失败时调用RunReservePluginsUnreserve 4. 执行绑定收尾工作即RunPostBindPlugins</code></pre><h5 id="扩展点介绍"><a href="#扩展点介绍" class="headerlink" title="扩展点介绍"></a>扩展点介绍</h5><p>上述涉及到的各类Plugins（图中紫色部分），针对下图，各位应该看了很多篇了，需要注意的是Unreserve的时机，各插件功能说明如下：</p><p><code>pkg/scheduler/framework/interface.go</code></p><p><img src="https://s3.ax1x.com/2021/01/19/sg2Jns.png"></p><table><thead><tr><th>扩展点</th><th>用途说明</th></tr></thead><tbody><tr><td>QueueSort</td><td>用来支持自定义 Pod 的排序。如果指定 QueueSort 的排序算法，在调度队列里面就会按照指定的排序算法来进行排序，只能enable一个</td></tr><tr><td>Prefilter</td><td>对 Pod 信息的预处理，比如 Pod 的缓存等</td></tr><tr><td>Filter</td><td>对应旧式的Predicate ，过滤不满足要求的节点</td></tr><tr><td>PostFilter</td><td>用于处理当 Pod 在 Filter 阶段失败后的操作，例如抢占等行为</td></tr><tr><td>PreScore</td><td>用于在 Score 之前进行一些信息生成，也可以在此处生成一些日志或者监控信息</td></tr><tr><td>Score</td><td>对应旧式的Priority，根据 扩展点定义的评分策略挑选出最优的节点(打分与归一化处理)</td></tr><tr><td>Reserver</td><td>调度阶段的最后一个插件, 防止调度成功后资源的竞争, 确保集群的资源信息的准确性</td></tr><tr><td>Permit</td><td>主要提供了Pod绑定的拦截功能，根据条件对pod进行allow、reject或者wait。</td></tr><tr><td>PreBind</td><td>在真正 bind node 之前，执行一些操作</td></tr><tr><td>Bind</td><td>一个 Pod 只会被一个 BindPlugin 处理，创建Bind对象</td></tr><tr><td>PostBind</td><td>bind 成功之后执行的逻辑</td></tr><tr><td>Unreserve</td><td>在 Permit 到 Bind 这几个阶段只要报错就回滚数据至初始状态，类似事务。</td></tr><tr><td></td><td></td></tr></tbody></table><h5 id="四、使用场景"><a href="#四、使用场景" class="headerlink" title="四、使用场景"></a>四、使用场景</h5><p>​下述为一些关于如何使用调度框架来解决常见调度场景的示例。</p><ol><li><p>联合调度</p><p>类似<code>kube-batch</code>，允许调度以一定数量的Pod为整体的任务。其能够将一个训练任务的多个worker当做一个整体进行调度，只有当任务所有worker的资源都满足，才会将容器在节点上启动。</p></li><li><p>集群资源的动态绑定</p><p> Volume topology-aware调度可以通过filter和prebind方式实现。</p></li><li><p>调度拓展</p><p>该框架允许自定义插件，以main函数封装scheduler方式运行。</p></li></ol><p>关于框架部分，该文就介绍到此处，接下里将进入源码阶段，后续内容为调度配置及第三方调度集成的相关内容，敬请关注。</p><h5 id="五、参考资料"><a href="#五、参考资料" class="headerlink" title="五、参考资料"></a>五、参考资料</h5><pre><code>1. https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/ 2. https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/ 3. https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/624-scheduling-framework/README.md</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天zouyee先带各位盘点CNCF上周的一些有趣的事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Kubernetes社区GB代表选举结束 Paris Pittman当选&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CNCF孵化项目OPA进入毕业流程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;上周</summary>
      
    
    
    
    <category term="Kubernetes GO" scheme="https://zoues.com/categories/Kubernetes-GO/"/>
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>一文搞懂Kubernetes网络策略</title>
    <link href="https://zoues.com/posts/d6be75a2/"/>
    <id>https://zoues.com/posts/d6be75a2/</id>
    <published>2021-01-13T04:40:08.000Z</published>
    <updated>2024-01-20T12:01:27.471Z</updated>
    
    <content type="html"><![CDATA[<p>从CNCF基金会的成立，到Kubernetes社区蓬勃发展，历经6载，17年异军突起，在mesos、swarm等项目角逐中，拔得头筹，继而一统容器编排,其成功的关键原因可概括为以下几点：</p><ul><li>项目领导者们的坚守与远见</li><li>社区的良好的运作与社区文化</li><li>社区与企业落地的正反馈</li></ul><p>今天zouyee为大家带来《一文搞懂Kubernetes网络策略》，其中《kuberneter调度由浅入深：框架》正在编写中，敬请期待，当前涉及版本均为<code>1.20.+</code>。</p><hr><h4 id="一、Network-Policy简介"><a href="#一、Network-Policy简介" class="headerlink" title="一、Network Policy简介"></a>一、Network Policy简介</h4><p>​随着微服务架构的日渐盛行，Serverless框架的逐步落地，应用上云后带来了模块间网络调用需求的大规模增长，Kubernetes 自 1.3 引入了 Network Policy，其提供以应用为中心， 基于策略的网络控制，用于隔离应用以减少攻击面。</p><p>​Pod之间能否通信可通过如下三种组合进行确认：</p><ol><li>其他被允许的 Pods（例如：Pod 无法限制对自身的访问）</li><li>被允许访问的namespace</li><li>IP  CIDR（例如：与 Pod 运行所在节点的通信总是被允许的）</li></ol><p>在定义基于 Pod 或namespace的 NetworkPolicy 时，可以使用<code>标签选择器</code>来设定哪些流量可以进入或离开 Pod。同时，当创建基于 IP 的 NetworkPolicy 时，可以基于 IP CIDR 来定义策略。</p><p>以下结构体示意图辅助理解，后面章节有具体说明：</p><p><img src="https://s3.ax1x.com/2021/01/12/sYphbq.png"></p><h5 id="版本变迁"><a href="#版本变迁" class="headerlink" title="版本变迁"></a>版本变迁</h5><table><thead><tr><th>Kubernetes 版本</th><th>Networking API 版本</th><th>说明</th></tr></thead><tbody><tr><td>v1.5-v1.6</td><td>extensions&#x2F;v1beta1</td><td>需要在kube-apiserver开启 <code>extensions/v1beta1/networkpolicies</code></td></tr><tr><td>v1.7</td><td>networking.k8s.io&#x2F;v1</td><td></td></tr><tr><td>v1.8</td><td>networking.k8s.io&#x2F;v1</td><td>新增 <strong>Egress</strong> 和 <strong>IPBlock</strong> 的支持</td></tr></tbody></table><h4 id="二、简要介绍"><a href="#二、简要介绍" class="headerlink" title="二、简要介绍"></a>二、简要介绍</h4><p>默认情况下，Pod 是非隔离的，它们接受任何流量。</p><p>Pod 在被某 NetworkPolicy 选中时进入隔离状态。 一旦名字空间中有 NetworkPolicy 选择了特定的 Pod，该 Pod 会拒绝该 NetworkPolicy 所不允许的连接。 （名字空间下其他未被 NetworkPolicy 所选择的 Pod 会继续接受所有的流量）</p><p><em><strong>网络策略不会冲突</strong></em>。 如果任何一个或多个策略选择了一个 Pod, 则该 Pod 受限于这些策略的 入站（Ingress）&#x2F;出站（Egress）规则的并集。</p><p>⚠️在使用 Network Policy 时，网络插件需要支持 Network Policy，如 Calico、Romana、Weave Net 和 Trireme 等，其中Engress为 出口流量，Ingress为 入口流量。</p><h5 id="2-1-结构体说明"><a href="#2-1-结构体说明" class="headerlink" title="2.1 结构体说明"></a>2.1 结构体说明</h5><p><code>staging/src/k8s.io/api/networking/v1/types.go</code></p><p>下面是 NetworkPolicy 的一个示例，如需完整说明，可参看结构定义文档:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">network-policy-sample</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">role:</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">        <span class="attr">except:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">172.17</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">namespaceSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">project:</span> <span class="string">myproject</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">role:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">  <span class="attr">egress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">to:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">5978</span></span><br></pre></td></tr></table></figure><p><strong>必需字段</strong>：与所有其他的 Kubernetes 对象一样，NetworkPolicy 需要 <code>apiVersion</code>、 <code>kind</code> 和 <code>metadata</code> 字段。</p><p><strong>spec</strong>：NetworkPolicy <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status">规约</a>中包含了在名字空间中定义特定网络策略所需的所有信息。</p><p><strong>podSelector</strong>：每个 NetworkPolicy 都包括一个 <code>podSelector</code>，它选择适用该该策略的 Pod。示例中的策略选择带有 “role&#x3D;db” 标签的 Pod。 若<code>podSelector</code>为空的，则选择名字空间下所有 Pod。</p><p><strong>policyTypes</strong>: 每个 NetworkPolicy 都包含一个 <code>policyTypes</code> 列表，其中包含 <code>Ingress</code> 或 <code>Egress</code> 或（两者亦可）。<code>policyTypes</code> 字段表示给定的策略是应用于 所选 Pod 的入口流量还是来出口流量（两者亦可）。 如果 NetworkPolicy 未指定 <code>policyTypes</code> 则默认情况下始终设置 <code>Ingress</code>； 如果 NetworkPolicy 有任何出口规则的话则设置 <code>Egress</code>。</p><p><strong>ingress</strong>: 每个 NetworkPolicy 可包含一个 <code>ingress</code> 规则的白名单列表。 每个规则都允许同时匹配 <code>from</code> 和 <code>ports</code> 部分的流量。示例策略中包含一条 简单的规则： 它匹配某个特定端口，第一个通过 <code>ipBlock</code> 指定，第二个通过 <code>namespaceSelector</code> 指定，第三个通过 <code>podSelector</code> 指定。</p><p><strong>egress</strong>: 每个 NetworkPolicy 可包含一个 <code>egress</code> 规则的白名单列表。 每个规则都允许匹配 <code>to</code> 和 <code>port</code> 部分的流量。该示例策略包含一条规则， 该规则指定端口上的流量匹配到 <code>10.0.0.0/24</code> 中的任何目的地。</p><p>该网络策略总结如下:</p><ol><li>隔离 <code>default</code>名字空间下 <code>role=db</code> 的 Pod 。</li><li>出口限制:允许符合以下条件的 Pod 连接到 <code>default</code>名字空间下标签为 <code>role=db</code>的所有 Pod 的 6379 TCP 端口：<ul><li><code>default</code>名字空间下带有 <code>role=frontend</code> 标签的所有 Pod</li><li>带有 <code>project=myproject</code> 标签的所有名字空间中的 Pod</li><li>IP 地址范围为<code> 172.17.0.0–172.17.0.255</code> 和 <code>172.17.2.0–172.17.255.255 </code>（即除了 172.17.1.0&#x2F;24 之外的所有 172.17.0.0&#x2F;16）</li></ul></li><li>入口限制：允许从带有 <code>role=db</code>标签的名字空间下的任何 Pod 到 CIDR 10.0.0.0&#x2F;24 下 5978 TCP 端口。</li></ol><h5 id="2-2-简单示例"><a href="#2-2-简单示例" class="headerlink" title="2.2 简单示例"></a>2.2 简单示例</h5><p>以 calico 为例看一下 Network Policy 的具体用法。</p><ol><li>配置 kubelet 使用 CNI 网络插件(默认已经配置，无需更改)</li></ol><p><code>kubelet --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin ...</code></p><ol start="2"><li>安装 calio 网络插件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 注意修改 CIDR，需要跟 k8s pod-network-cidr 一致，默认为 192.168.0.0/16</span><br><span class="line"># 当前选择的是小于50节点的安装方式，具体安装可查看</span><br><span class="line"># https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises</span><br><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br></pre></td></tr></table></figure><ol start="3"><li>部署应用</li></ol><p>部署 nginx 服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create deployment nginx --image=nginx</span><br><span class="line">deployment &quot;nginx&quot; created</span><br><span class="line">$ kubectl expose deployment nginx --port=80</span><br><span class="line">service &quot;nginx&quot; exposed</span><br></pre></td></tr></table></figure><p>测试网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc,pod</span><br><span class="line">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/kubernetes   ClusterIP   10.233.0.1      &lt;none&gt;        443/TCP   186d</span><br><span class="line">service/nginx        ClusterIP   10.233.27.142   &lt;none&gt;        80/TCP    2s</span><br><span class="line"></span><br><span class="line">NAME                            READY   STATUS              RESTARTS   AGE</span><br><span class="line">pod/nginx-f89759699-kfmbj       1/1     Running   0          62s</span><br><span class="line"></span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">/ # wget --spider --timeout=1 nginx</span><br><span class="line">Connecting to nginx (10.233.27.142:80)</span><br><span class="line">remote file exists</span><br><span class="line">/ #</span><br></pre></td></tr></table></figure><p>4）测试网络策略</p><p>如果只让那些拥有标签 <code>access: true</code> 的 Pod 访问 <code>nginx</code> 服务， 那么可以创建一个如下所示的 NetworkPolicy 对象：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">$ cat nginx-policy.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: access-nginx</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          access: &quot;true&quot;</span><br><span class="line"></span><br><span class="line">$ kubectl create -f nginx-policy.yaml</span><br><span class="line">networkpolicy &quot;access-nginx&quot; created</span><br><span class="line"></span><br><span class="line"># 不带 access=true 标签的 Pod 还是无法访问 nginx 服务</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">/ # wget --spider --timeout=1 nginx</span><br><span class="line">Connecting to nginx (10.233.27.142:80)</span><br><span class="line">wget: download timed out</span><br><span class="line">/ #</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 而带有 access=true 标签的 Pod 可以访问 nginx 服务</span><br><span class="line">$ kubectl run busybox --rm -ti --labels=&quot;access=true&quot; --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">/ # wget --spider --timeout=1 nginx</span><br><span class="line">Connecting to nginx (10.233.27.142:80)</span><br><span class="line">/ #</span><br></pre></td></tr></table></figure><h5 id="三、应用场景"><a href="#三、应用场景" class="headerlink" title="三、应用场景"></a>三、应用场景</h5><h5 id="3-1-一般场景"><a href="#3-1-一般场景" class="headerlink" title="3.1 一般场景"></a>3.1 一般场景</h5><h5 id="a-禁止访问指定服务"><a href="#a-禁止访问指定服务" class="headerlink" title="a. 禁止访问指定服务"></a>a. 禁止访问指定服务</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run web --image=nginx --labels app=web --expose --port 80</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 未有策略限制时，可以访问</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- http://web</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br></pre></td></tr></table></figure><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># cat web-deny-all.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-deny-all</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress: []</span><br><span class="line">  </span><br><span class="line">$ kubectl apply -f web-deny-all.yaml</span><br><span class="line">networkpolicy &quot;web-deny-all&quot; created</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web</span><br><span class="line">wget: download timed out</span><br></pre></td></tr></table></figure><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022447799137.jpg" alt="img"></p><h5 id="b-限制访问指定服务"><a href="#b-限制访问指定服务" class="headerlink" title="b. 限制访问指定服务"></a>b. 限制访问指定服务</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run apiserver --image=nginx --labels app=bookstore,role=api --expose --port 80</span><br></pre></td></tr></table></figure><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022448622429.jpg" alt="img"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># cat api-allow.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: api-allow</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: bookstore</span><br><span class="line">      role: api</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">      - podSelector:</span><br><span class="line">          matchLabels:</span><br><span class="line">            app: bookstore</span><br><span class="line"># kubectl apply -f api-allow.yaml</span><br><span class="line">networkpolicy &quot;api-allow&quot; created</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">创建不加label的pod，预期结果，访问被限制</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver</span><br><span class="line">wget: download timed out</span><br><span class="line">/ # exit</span><br><span class="line">创建带app=bookstore标签的pod，预期结果，访问被限制</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox --labels app=bookstore,role=frontend /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;&lt;head&gt;</span><br><span class="line">/ # exit</span><br></pre></td></tr></table></figure><h5 id="c-放通访问限制"><a href="#c-放通访问限制" class="headerlink" title="c. 放通访问限制"></a>c. 放通访问限制</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run apiserver --image=nginx --labels app=bookstore,role=api --expose --port 80</span><br></pre></td></tr></table></figure><p>应用a中的网络策略，限制所有流量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># cat web-deny-all.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-deny-all</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress: []</span><br><span class="line">  </span><br><span class="line">$ kubectl apply -f web-deny-all.yaml</span><br><span class="line">networkpolicy &quot;web-deny-all&quot; created</span><br></pre></td></tr></table></figure><p>创建放通通网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># cat web-deny-all.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-allow-all</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress:</span><br><span class="line">  - &#123;&#125;</span><br><span class="line">  </span><br><span class="line">$ kubectl apply -f web-allow-all.yaml</span><br><span class="line">networkpolicy &quot;web-allow-all&quot; created</span><br><span class="line"># 需要注意deny跟allow的细微差别就是[]与&#123;&#125;，其中&#123;&#125;代表</span><br><span class="line">- from:</span><br><span class="line">    podSelector: &#123;&#125;</span><br><span class="line">    namespaceSelector: &#123;&#125;</span><br></pre></td></tr></table></figure><h5 id="3-2-namespace限制"><a href="#3-2-namespace限制" class="headerlink" title="3.2 namespace限制"></a>3.2 namespace限制</h5><h5 id="a-禁止-namespace-中非白名单流量"><a href="#a-禁止-namespace-中非白名单流量" class="headerlink" title="a. 禁止 namespace 中非白名单流量"></a>a. 禁止 namespace 中非白名单流量</h5><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022451724392.gif" alt="img"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># cat default-deny-all.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: default-deny-all</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  podSelector: &#123;&#125;</span><br><span class="line">  ingress: []</span><br><span class="line"># kubectl apply -f default-deny-all.yaml</span><br></pre></td></tr></table></figure><p>说明:</p><ul><li><p><code>namespace: default</code> 该策略部署于default</p></li><li><p><code>podSelector</code>为<code>&#123;&#125;</code>指匹配所有pod，因而该策略对default命名空间的所有pod都有效</p></li><li><p><code>ingress</code>未指定，因而对于所有进入流量都禁止</p></li></ul><h5 id="b-禁止其他-namespace-流量"><a href="#b-禁止其他-namespace-流量" class="headerlink" title="b. 禁止其他 namespace 流量"></a>b. 禁止其他 namespace 流量</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace secondary</span><br><span class="line">kubectl run web --namespace secondary --image=nginx \</span><br><span class="line">    --labels=app=web --expose --port 80</span><br></pre></td></tr></table></figure><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022452203435.gif" alt="img"></p><p>创建网络配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: secondary</span><br><span class="line">  name: web-deny-other-namespaces</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector: &#123;&#125;</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># default命名空间访问</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.secondary</span><br><span class="line">wget: download timed out</span><br><span class="line">/ # exit</span><br><span class="line"># secondary命名空间访问</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox --namespace=secondary /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.secondary</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br></pre></td></tr></table></figure><h5 id="c-运行所有namespace流量"><a href="#c-运行所有namespace流量" class="headerlink" title="c. 运行所有namespace流量"></a>c. 运行所有namespace流量</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run web --image=nginx --labels app=web --expose --port 80</span><br></pre></td></tr></table></figure><p><img src="https://github.com/ahmetb/kubernetes-network-policy-recipes/raw/master/img/5.gif" alt="Diagram of  ALLOW traffic to an application from all namespaces policy"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># cat web-allow-all-namespaces.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: default</span><br><span class="line">  name: web-allow-all-namespaces</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector: &#123;&#125;</span><br><span class="line"># kubectl apply -f web-allow-all-namespaces.yaml</span><br><span class="line"># kubectl create namespace secondary</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>app: web</code>网络策略应用到该标签pod</li><li><code>namespaceSelector: &#123;&#125;</code>匹配所有命名空间</li></ul><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># kubectl run busybox --rm -ti --image=busybox --namespace=secondary /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.secondary</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br></pre></td></tr></table></figure><h5 id="c-指定-namespace-访问服务"><a href="#c-指定-namespace-访问服务" class="headerlink" title="c. 指定 namespace 访问服务"></a>c. 指定 namespace 访问服务</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># kubectl run web --image=nginx \</span><br><span class="line">    --labels=app=web --expose --port 80</span><br><span class="line"># kubectl create namespace dev</span><br><span class="line"># kubectl label namespace/dev purpose=testing</span><br><span class="line"># kubectl create namespace prod</span><br><span class="line"># kubectl label namespace/prod purpose=production</span><br></pre></td></tr></table></figure><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022453441751.gif" alt="img"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># cat web-allow-prod.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-allow-prod</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          purpose: production</span><br><span class="line"># kubectl apply -f web-allow-prod.yaml</span><br></pre></td></tr></table></figure><h5 id="d-允许其他namespace的指定pod的流量"><a href="#d-允许其他namespace的指定pod的流量" class="headerlink" title="d. 允许其他namespace的指定pod的流量"></a>d. 允许其他namespace的指定pod的流量</h5><p>⚠️ Kubernetes 1.11后支持<code>podSelector</code> 与<code>namespaceSelector</code>的运算符操作，同时需要网络插件支持</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># kubectl run web --image=nginx \</span><br><span class="line">    --labels=app=web --expose --port 80</span><br><span class="line"># kubectl create namespace other</span><br><span class="line"># kubectl create namespace other</span><br></pre></td></tr></table></figure><p> 创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># cat web-allow-all-ns-monitoring.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-allow-all-ns-monitoring</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress:</span><br><span class="line">    - from:</span><br><span class="line">      - namespaceSelector:     # 选择namespaces中带有team=operations标签的pod</span><br><span class="line">          matchLabels:</span><br><span class="line">            team: operations  </span><br><span class="line">        podSelector:           # 选择带有type=monitoring标签的pod</span><br><span class="line">          matchLabels:</span><br><span class="line">            type: monitoring</span><br><span class="line"># kubectl apply -f web-allow-all-ns-monitoring.yaml</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">kubectl run busybox --rm -ti --image=busybox  /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.default</span><br><span class="line">wget: download timed out</span><br><span class="line"></span><br><span class="line">(访问限制)</span><br><span class="line">/ # exit</span><br><span class="line"></span><br><span class="line"># kubectl run busybox --rm -ti --image=busybox --labels type=monitoring /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.default</span><br><span class="line">wget: download timed out</span><br><span class="line"></span><br><span class="line">(访问限制)</span><br><span class="line"></span><br><span class="line"># kubectl run busybox --rm -ti --image=busybox --namespace=other /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.default</span><br><span class="line">wget: download timed out</span><br><span class="line"></span><br><span class="line">(访问限制)</span><br><span class="line"></span><br><span class="line"># kubectl run busybox --rm -ti --image=busybox --namespace=other  --labels type=monitoring /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://web.default</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">...</span><br><span class="line">(允许访问)</span><br></pre></td></tr></table></figure><h5 id="3-3-允许外网访问服务"><a href="#3-3-允许外网访问服务" class="headerlink" title="3.3 允许外网访问服务"></a>3.3 允许外网访问服务</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl run web --image=nginx --labels=app=web --port 80</span><br><span class="line">kubectl expose pod/web --type=LoadBalancer</span><br><span class="line">kubectl get svc web</span><br><span class="line">NAME   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">web    LoadBalancer   10.233.54.206   &lt;pending&gt;     80:32548/TCP   40s</span><br><span class="line">直至EXTERNAL-IP分配IP为止</span><br></pre></td></tr></table></figure><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/concepts/images/15022454444461.gif" alt="img"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># cat web-allow-external.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: web-allow-external</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  ingress:</span><br><span class="line">  - ports:</span><br><span class="line">    - port: 80</span><br><span class="line">    from: []</span><br><span class="line"># kubectl apply -f web-allow-external.yaml</span><br></pre></td></tr></table></figure><h5 id="3-5-高级功能"><a href="#3-5-高级功能" class="headerlink" title="3.5 高级功能"></a>3.5 高级功能</h5><h5 id="a-允许应用固定端口流量"><a href="#a-允许应用固定端口流量" class="headerlink" title="a. 允许应用固定端口流量"></a>a. 允许应用固定端口流量</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># kubectl run busybox -ti --image=busybox --labels=app=apiserver /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"># nohup python3 -m http.server 8001 &amp;</span><br><span class="line"># nohup python3 -m http.server 5001 &amp;</span><br><span class="line"># exit</span><br><span class="line"># kubectl create service clusterip apiserver \</span><br><span class="line">    --tcp 8001:8000 \</span><br><span class="line">    --tcp 5001:5000</span><br></pre></td></tr></table></figure><p><img src="https://github.com/ahmetb/kubernetes-network-policy-recipes/raw/master/img/9.gif" alt="Diagram of ALLOW traffic only to a port of an application policy"></p><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># cat api-allow-5000.yml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: api-allow-5000</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: apiserver</span><br><span class="line">  ingress:</span><br><span class="line">  - ports:</span><br><span class="line">    - port: 5000</span><br><span class="line">    from:</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          role: monitoring</span><br><span class="line"># kubectl apply -f api-allow-5000.yml</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 启动pod未携带指定label时，访问受限</span><br><span class="line"># kubectl run busybox --rm -ti --image=busybox /bin/sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver:8001</span><br><span class="line">wget: download timed out</span><br><span class="line"></span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver:5001/metrics</span><br><span class="line">wget: download timed out</span><br><span class="line"></span><br><span class="line"># 启动pod携带指定label时，访问不受限</span><br><span class="line">$ kubectl run busybox --rm -ti --image=busybox --labels=role=monitoring /bin/sh</span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver:8001</span><br><span class="line">&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">/ # wget -qO- --timeout=2 http://apiserver:5001/</span><br><span class="line">&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h5 id="b-多标签限制"><a href="#b-多标签限制" class="headerlink" title="b. 多标签限制"></a>b. 多标签限制</h5><p>说明：Network Policy定义一组微服务访问某一应用,如下述示例中，一组微服务共享redis服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run db --image=redis:4 --port 6379 --expose \</span><br><span class="line">    --labels app=bookstore,role=db</span><br></pre></td></tr></table></figure><p>以下服务共享redis服务</p><table><thead><tr><th>service</th><th>labels</th></tr></thead><tbody><tr><td><code>search</code></td><td><code>app=bookstore</code> <code>role=search</code></td></tr><tr><td><code>api</code></td><td><code>app=bookstore</code> <code>role=api</code></td></tr><tr><td><code>catalog</code></td><td><code>app=inventory</code> <code>role=web</code></td></tr></tbody></table><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># cat redis-allow-services.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-allow-services</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: bookstore</span><br><span class="line">      role: db</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          app: bookstore</span><br><span class="line">          role: search</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          app: bookstore</span><br><span class="line">          role: api</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          app: inventory</span><br><span class="line">          role: web</span><br><span class="line"># kubectl apply -f redis-allow-services.yaml</span><br></pre></td></tr></table></figure><p>访问测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run busybox --rm -ti --image=curl --labels=app=inventory,role=web /bin/sh</span><br><span class="line"></span><br><span class="line">/ # nc -v -w 2 db 6379</span><br><span class="line">db (10.233.27.143:6379) open</span><br><span class="line"></span><br><span class="line">(works)</span><br><span class="line"></span><br><span class="line">$ kubectl run busybox --rm -ti --image=curl --labels=app=other /bin/sh</span><br><span class="line"></span><br><span class="line">/ # nc -v -w 2 db 6379</span><br><span class="line">nc: db (10.233.27.143:6379): Operation timed out</span><br><span class="line"></span><br><span class="line">(访问受限)</span><br></pre></td></tr></table></figure><h5 id="3-6-控制出口流量"><a href="#3-6-控制出口流量" class="headerlink" title="3.6 控制出口流量"></a>3.6 控制出口流量</h5><h5 id="a-禁止应用的出口流量"><a href="#a-禁止应用的出口流量" class="headerlink" title="a. 禁止应用的出口流量"></a>a. 禁止应用的出口流量</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run web --image=nginx --labels app=web --expose --port 80</span><br></pre></td></tr></table></figure><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># cat foo-deny-egress.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: foo-deny-egress</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: foo</span><br><span class="line">  policyTypes:</span><br><span class="line">  - Egress</span><br><span class="line">  egress: []</span><br><span class="line"># kubectl apply -f foo-deny-egress.yaml</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>policyTypes: [&quot;egress&quot;]</code> 该策略类型为出口流量</li><li><code>egress: []</code> 策略为空说明出口流量全部禁止</li></ul><h5 id="b-禁止命名空间非白名单流量"><a href="#b-禁止命名空间非白名单流量" class="headerlink" title="b. 禁止命名空间非白名单流量"></a>b. 禁止命名空间非白名单流量</h5><p>创建网络策略</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># cat default-deny-all-egress.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: default-deny-all-egress</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  policyTypes:</span><br><span class="line">  - Egress</span><br><span class="line">  podSelector: &#123;&#125;</span><br><span class="line">  egress: []</span><br><span class="line"># kubectl apply -f default-deny-all-egress.yaml</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>podSelector</code>为空，说明匹配所有pod</li><li><code>egress</code>为空数组，说明禁止所有符合<code>podSelector</code>的出口流量</li></ul><h5 id="四、NetworkPolicy-开发"><a href="#四、NetworkPolicy-开发" class="headerlink" title="四、NetworkPolicy 开发"></a>四、NetworkPolicy 开发</h5><p>​实现一个支持 Network Policy 的网络扩展需要至少包含两个组件</p><ul><li>CNI 网络插件：负责给 Pod 配置网络接口</li><li>Policy controller：监听 Network Policy 的变化，并将 Policy 应用到相应的网络接口</li></ul><p><img src="https://github.com/feiskyer/kubernetes-handbook/raw/master/plugins/images/policy-controller.jpg" alt="img"></p><h5 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h5><p>下图基于Kubernetes 1.19版本测试了以下特性：</p><p>1）MTU auto config</p><p>2） 带宽性能: Pod to Pod、Pod to Service（TCP、UDP）</p><p>3）资源消耗: Pod to Pod、Pod to Service（TCP、UDP）</p><p>4）安全特性：Network Policies、 Encryption等</p><p><img src="https://s3.ax1x.com/2021/01/12/sJzrLt.png" alt="Image for post"></p><p>calico其他详细的能力说明，可参看官网。</p><h5 id="五、未来展望"><a href="#五、未来展望" class="headerlink" title="五、未来展望"></a>五、未来展望</h5><h5 id="a-SCTP特性"><a href="#a-SCTP特性" class="headerlink" title="a. SCTP特性"></a>a. SCTP特性</h5><p><strong>支持版本：</strong> <code>Kubernetes v1.19 [beta]</code></p><p>作为一个 Beta 特性，SCTP 默认是被启用的。 要在集群层面禁用 SCTP，需要为 <code>kube-apiserver</code>关闭特性<code>--feature-gates=SCTPSupport=false,...</code> 以禁用 <code>SCTP</code> 。 启用该特性后，用户可以将 NetworkPolicy 的 <code>protocol</code> 字段设置为 <code>SCTP</code>。</p><p>⚠️ CNI插件需要支持SCTP协议</p><h5 id="b-待开发"><a href="#b-待开发" class="headerlink" title="b. 待开发"></a>b. 待开发</h5><p>截止Kubernetes v1.20 ，NetworkPolicy API 还不支持下述功能。</p><ul><li>强制集群内部流量经过某公用网关（可通过服务网格或其他代理来实现）</li><li>与 TLS 相关的场景（可使用服务网格或者 Ingress 控制器）</li><li>实现适用于所有名字空间或 Pods 的默认策略（如calico）</li><li>高级的策略查询或者策略验证相关工具（如calico）</li><li>在同一策略声明中选择目标端口范围的能力</li><li>生成网络安全事件日志的能力（例如，被阻塞或接收的连接请求）</li><li>禁止本地回路或指向宿主的网络流量（Pod 目前无法阻塞 localhost 访问， 它们也无法禁止来自所在节点的访问请求）。</li></ul><p>上述需求可以通过操作系统组件（如 SELinux、OpenVSwitch、IPTables 等） 或者七层技术（Ingress 控制器、服务网格实现）及准入控制器进行功能增强，当然有兴趣的可以参考calico及OPA项目。</p><h5 id="六、参考文档"><a href="#六、参考文档" class="headerlink" title="六、参考文档"></a>六、参考文档</h5><ul><li><a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Kubernetes network policies</a></li><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/">Declare Network Policy</a></li><li><a href="https://ahmet.im/blog/kubernetes-network-policy/">Securing Kubernetes Cluster Networking</a></li><li><a href="https://github.com/ahmetb/kubernetes-networkpolicy-tutorial">Kubernetes Network Policy Recipes</a></li><li><a href="https://github.com/feiskyer/kubernetes-handbook/blob/master/concepts/network-policy.md">fesikyer network policy</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从CNCF基金会的成立，到Kubernetes社区蓬勃发展，历经6载，17年异军突起，在mesos、swarm等项目角逐中，拔得头筹，继而一统容器编排,其成功的关键原因可概括为以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;项目领导者们的坚守与远见&lt;/li&gt;
&lt;li&gt;社区的良好的运作</summary>
      
    
    
    
    <category term="Kubernetes GO" scheme="https://zoues.com/categories/Kubernetes-GO/"/>
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes调度由浅入深：初探</title>
    <link href="https://zoues.com/posts/bafe2904/"/>
    <id>https://zoues.com/posts/bafe2904/</id>
    <published>2021-01-08T04:40:08.000Z</published>
    <updated>2024-01-20T12:01:27.435Z</updated>
    
    <content type="html"><![CDATA[<p>从CNCF基金会的成立，到Kubernetes社区蓬勃发展，历经6载，17年异军突起，在mesos、swarm等项目角逐中，拔得头筹，继而一统容器编排,其成功的关键原因可概括为以下几点：</p><ul><li>项目领导者们的坚守与远见</li><li>社区的良好的运作与社区文化</li><li>社区与企业落地的正反馈</li></ul><p>虽然针对kubernetes的介绍已经比较多了，但是云原生还是Kubernetes项目的发展都已经迈入深水区，因而今天zouyee为大家带来《kuberneter调度由浅入深》，希望通过接下来的五篇文章，让各位能够系统深入的了解kubernetes调度系统，该系列对应版本为<code>1.20.+</code>，今天带来《Kubernetes调度系统由浅入深系列：初探》</p><h4 id="一、调度简介"><a href="#一、调度简介" class="headerlink" title="一、调度简介"></a>一、调度简介</h4><p>在开始前，先来看看Kubernetes的架构示意图，其中控制平面包含以下三大组件：kube-scheduler、kube-apiserver、kube-controller-manager。kubelet及kube-proxy组件的分析我们后续单独成章进行讲解，现在我们可以简单给理解上述组件的难易程度排个序，kube-apiserver、kubelet、kube-scheduler、kube-controller-manager、kube-proxy。</p><p><img src="https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg" alt="Components of Kubernetes"></p><p>如上所述，<code>kube-scheduler</code>是K8S系统的核心组件之一，其主要负责Pod的调度，其监听kube-apiserver，查询未分配 Node的Pod（未分配、分配失败及尝试多次无法分配），根据配置的调度策略，将Pod调度到最优的工作节点上，从而高效、合理的利用集群的资源，该特性是用户选择K8S系统的关键因素之一，帮助用户提升效率、降低能耗。</p><p><code>kube-scheduler</code> 负责将Pod 调度到集群内的<em>最佳节点</em>(基于相应策略计算出的最佳值)上，它监听<code> kube-apiserver</code>，查询还未分配节点 的 Pod，然后根据调度策略为这些 Pod 分配节点，执行绑定节点的操作(更新Pod的<strong>nodeName</strong>字段)。</p><p>在上述过程中，需要考虑以下问题：</p><ul><li>如何确保节点分配的公平性</li><li>如何确保节点资源分配的高效性</li><li>如何确保Pod调度的公平性</li><li>如何确保Pod调度的高效性</li><li>如何扩展Pod调度策略</li></ul><p>为解决上述的问题，<code>kube-scheduler</code>通过汇集节点资源、节点地域、节点镜像、Pod调度等信息综合决策，确保Pod分配到最佳节点，以下为<code>kube-scheduler</code>的主要目标：</p><ul><li>公平性：在调度Pod时需要公平的决策，每个节点都有被分配的机会，调度器需要针对不同节点作出平衡决策。</li><li>资源高效：最大化提升所有可调度资源的利用率，使有限的CPU、内存等资源服务尽可能更多的Pod。</li><li>性能：能快速的完成对大规模Pod的调度工作，在集群规模扩增的情况下，依然能确保调度的性能。</li><li>灵活性：在实际生产中，用户希望Pod的调度策略是可扩展的，从而可以定制化调度算法以处理复杂的实际问题。因此平台要允许多种调度器并行工作，并支持自定义调度器。</li></ul><h4 id="二、调度流程"><a href="#二、调度流程" class="headerlink" title="二、调度流程"></a>二、调度流程</h4><p>首先我们通过下面的整体的交互图，来构建Pod调度的直观感受。</p><p><img src="https://s3.ax1x.com/2021/01/06/sZ9Aun.png"></p><p>上述以创建一个Pod为例，简要介绍调度流程：</p><ol><li><p>用户通过命令行创建Pod(选择直接创建Pod而不是其他workload，是为了省略kube-controller-manager)</p></li><li><p>kube-apiserver经过对象校验、admission、quota等准入操作，写入etcd</p></li><li><p>kube-apiserver将结果返回给用户</p></li><li><p>同时kube-scheduler一直监听节点、Pod事件等（流程1）</p></li><li><p>kube-scheduler将spec.nodeName的pod加入到调度队列中，进行调度周期（该周期即位后续介绍内容）（流程2-3）</p></li><li><p>kube-scheduler将pod与得分最高的节点进行binding操作（流程4）</p></li><li><p>kube-apiserver将binding信息写入etcd</p></li><li><p>kubelet监听分配给自己的Pod，调用CRI接口进行Pod创建（该部分内容后续出系列，进行介绍）</p></li><li><p>kubelet创建Pod后，更新Pod状态等信息，并向kube-apiserver上报</p></li><li><p>kube-apiserver写入数据</p></li></ol><h5 id="调度周期"><a href="#调度周期" class="headerlink" title="调度周期"></a>调度周期</h5><p><code>kube-scheduler</code>的工作任务是根据各种调度算法将Pod绑定（bind）到最合适的工作节点，整个调度流程分为两个阶段：过滤和评分。流程示意图如下所示。</p><p><img src="https://s3.ax1x.com/2021/01/06/sZ9lv9.png"></p><p>​注：以前称之为predicate与priorities，当前统称为过滤与评分，实际效果一致</p><ul><li><p><strong>过滤</strong>：输入是所有节点，输出是满足预选条件的节点。<code>kube-scheduler</code>根据过滤策略过滤掉不满足的节点。例如，如果某节点的资源不足或者不满足预选策略的条件如“节点的标签必须与Pod的Selector一致”时则无法通过过滤。</p></li><li><p><strong>评分：</strong>输入是通过过滤阶段的节点，评分时会根据评分算法为通过过滤的节点进行打分，选择得分最高的节点。例如，资源越充足、负载越小的节点可能具有越高的排名。</p></li></ul><p>​通俗点说，调度的过程就是在回答两个问题：1. 候选节点有哪些？2. 其中最适合的是哪一个？</p><p>​如果在过滤阶段没有节点满足条件，Pod会一直处在Pending状态直到出现满足的节点，在此期间调度器会不断的进行重试。如果有多个节点评分一致，那么<code>kube-scheduler</code>任意选择其一。</p><p>​注：Pod首先进入调度队列，失败后进入backoff，多次失败后进入unschedule，该部分内容后续介绍。</p><h5 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h5><p>当前支持两种方式配置过滤、评分算法：</p><pre><code>1. Scheduling Policies：通过文件或者configmap配置Predicate算法(过滤)和 Priorities算法(评分)的算法 2. Scheduling Profiles：当前调度系统为插拔架构，其将调度周期分为 `QueueSort`、`PreFilter`、`Filter`、`PreScore`、`Score`、`Reserve`、`Permit`、`PreBind`、`Bind`、`PostBind`等阶段，通过定制调度周期中不同阶段的插件行为来实现自定义。</code></pre><p>下面简单介绍一下通过Scheduling Policies方式配置</p><p><code>pkg/scheduler/framework/plugins/legacy_registry.go</code></p><p> <em><strong>预选(Precates)</strong></em></p><table><thead><tr><th>算法名称</th><th>算法含义</th></tr></thead><tbody><tr><td>MatchInterPodAffinity</td><td>检查pod资源对象与其他pod资源对象是否符合亲和性规则</td></tr><tr><td>CheckVolumeBinding</td><td>检查节点是否满足pod资源对象的pvc挂载需求</td></tr><tr><td>GeneralPredicates</td><td>检查节点上pod资源对象数量的上线，以及CPU 内存 GPU等资源是否符合要求</td></tr><tr><td>HostName</td><td>检查Pod指定的NodeName是否匹配当前节点</td></tr><tr><td>PodFitsHostPorts</td><td>检查Pod容器所需的HostPort是否已被节点上其它容器或服务占用。如果已被占用，则禁止Pod调度到该节点</td></tr><tr><td>MatchNodeSelector</td><td>检查Pod的节点选择器是否与节点的标签匹配</td></tr><tr><td>PodFitsResources</td><td>检查节点是否有足够空闲资源（例如CPU和内存）来满足Pod的要求</td></tr><tr><td>NoDiskConflict</td><td>检查当前pod资源对象使用的卷是否与节点上其他的pod资源对象使用的卷冲突</td></tr><tr><td>PodToleratesNodeTaints</td><td>如果当前节点被标记为taints，检查pod资源对象是否能容忍node taints</td></tr><tr><td>CheckNodeUnschedulable</td><td>检查节点是否可调度</td></tr><tr><td>CheckNodeLabelPresence</td><td>检查节点标签是否存在</td></tr><tr><td>CheckServiceAffinity</td><td>检查服务亲和性</td></tr><tr><td>MaxCSIVolumeCountPred</td><td>如果设置了featuregate （attachvolumelimit）功能，检查pod资源对象挂载的csi卷是否超出了节点上卷的最大挂载数量</td></tr><tr><td>NoVolumeZoneConflict</td><td>检查pod资源对象挂载pvc是否属于跨区域挂载，因为gce的pd存储或aws的ebs卷都不支持跨区域挂载</td></tr><tr><td>EvenPodsSpreadPred</td><td>一组 Pod 在某个 TopologyKey 上的均衡打散需求</td></tr></tbody></table><p>注：其中 MaxEBSVolumeCountPred、 MaxGCEPDVolumeCountPred  MaxAzureDiskVolumeCountPred、MaxCinderVolumeCountPred 等云厂商相关预选算法已经废弃</p><p><em><strong>优选(Priorities)</strong></em></p><table><thead><tr><th>算法名称</th><th>算法含义</th></tr></thead><tbody><tr><td>EqualPriority</td><td>节点权重相等</td></tr><tr><td>MostRequestedPriority</td><td>偏向具有最多请求资源的节点。这个策略将把计划的Pods放到整个工作负载集所需的最小节点上运行。</td></tr><tr><td>RequestedToCapacityRatioPriority</td><td>使用默认的资源评分函数模型创建基于ResourceAllocationPriority的requestedToCapacity。</td></tr><tr><td>SelectorSpreadPriority</td><td>将属于相同service rcs rss sts 的pod尽量调度在不同的节点上</td></tr><tr><td>ServiceSpreadingPriority</td><td>对于给定的服务，此策略旨在确保Service的Pods运行在不同的节点上。总的结果是，Service对单个节点故障变得更有弹性。</td></tr><tr><td>InterPodAffinityPriority</td><td>基于亲和性（affinity）和反亲和性（anti-affinity）计算分数</td></tr><tr><td>LeastRequestdPriority</td><td>偏向使用较少请求资源的节点。换句话说，放置在节点上的Pod越多，这些Pod使用的资源越多，此策略给出的排名就越低。</td></tr><tr><td>BalancedRequestdPriority</td><td>计算节点上cpu和内存的使用率，使用率最均衡的节点最优</td></tr><tr><td>NodePreferAvoidPodsPriority</td><td>基于节点上定义的注释（annotaion）记分，注释中如果定义了alpha.kubernetes.io&#x2F;preferAvoidPods则会禁用ReplicationController或者将ReplicaSet的pod资源对象调度在该节点上</td></tr><tr><td>NodeAffinityPriority</td><td>基于节点亲和性计算分数</td></tr><tr><td>TaintTolerationPriority</td><td>基于污点（taint）和容忍度（toleration）是否匹配计算分数</td></tr><tr><td>ImageLocalityPriority</td><td>基于节点上是否已经下拉了运行pod资源对象的镜像计算分数</td></tr><tr><td>EvenPodsSpreadPriority</td><td>用来指定一组符合条件的 Pod 在某个拓扑结构上的打散需求</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从CNCF基金会的成立，到Kubernetes社区蓬勃发展，历经6载，17年异军突起，在mesos、swarm等项目角逐中，拔得头筹，继而一统容器编排,其成功的关键原因可概括为以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;项目领导者们的坚守与远见&lt;/li&gt;
&lt;li&gt;社区的良好的运作</summary>
      
    
    
    
    <category term="Kubernetes GO" scheme="https://zoues.com/categories/Kubernetes-GO/"/>
    
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents三部曲:实践篇</title>
    <link href="https://zoues.com/posts/c8b5de4b/"/>
    <id>https://zoues.com/posts/c8b5de4b/</id>
    <published>2020-12-20T13:40:08.000Z</published>
    <updated>2024-01-21T02:27:48.223Z</updated>
    
    <content type="html"><![CDATA[<p>随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。<br>对于CloudEvent的介绍、规范说明及实践落地，将以三篇系列文章进行说明，本文为《CloudEvent三部曲:实践篇》</p><hr><h4 id="一、产品接入"><a href="#一、产品接入" class="headerlink" title="一、产品接入"></a>一、产品接入</h4><h5 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h5><p>Serverless是一项基于事件驱动的函数计算服务，通过使用函数计算产品，函数以弹性、免运维、高可靠的方式运行，用户可以无需采购和维护服务器等基础设施，可以更加专注于函数代码的编写。<br>目前 CloudEvents 在函数计算中已有广泛的应用，第三方服务接入函数计算服务，需要使用符合 CloudEvents 规范的消息传递数据，方便函数计算平台方对第三方服务的消息进行分发过滤，同时由于规范的通用性，第三方服务一次改造后可以无缝适配到各类符合 CloudEvents 规范的平台上。<br>此外消息类产品（例如：消息队列，消息服务，事件总线等）也可通过支持 CloudEvents 规范，统一云的事件标准，加速云原生生态集成。</p><h5 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h5><p>通常情况下，要构建一个CloudEvent，需要使用CloudEvents的软件开发工具包（SDK），利用SDK可以极大方便开发人员进行集成开发，截至 CloudEvents v1.0 规范的发布，CloudEvents 团队支持和维护以下6种SDK：</p><ul><li>CSharp</li><li>Go SDK</li><li>Java SDK</li><li>JavaScript SDK</li><li>Python SDK</li><li>Ruby SDK</li></ul><p>以下使用 Go，Python SDK构造符合CloudEvent 1.0 规范的消息接收发送，HTTP&#x2F;JSON请求转化等功能的范例。</p><p><em><strong>Golang</strong></em></p><ol><li><p>获取依赖<br><code>go get github.com/cloudevents/sdk-go/v2@v2.0.0</code></p></li><li><p>依赖引用<br><code>import cloudevents &quot;github.com/cloudevents/sdk-go/v2&quot;</code></p></li><li><p>发送事件</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line">cloudevents <span class="string">&quot;github.com/cloudevents/sdk-go/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// The default client is HTTP.</span></span><br><span class="line">c, err := cloudevents.NewDefaultClient()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to create client, %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an Event.</span></span><br><span class="line">event :=  cloudevents.NewEvent()</span><br><span class="line">event.SetSource(<span class="string">&quot;example/uri&quot;</span>)</span><br><span class="line">event.SetType(<span class="string">&quot;example.type&quot;</span>)</span><br><span class="line">event.SetData(cloudevents.ApplicationJSON, <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>&#123;<span class="string">&quot;hello&quot;</span>: <span class="string">&quot;world&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set a target.</span></span><br><span class="line">ctx := cloudevents.ContextWithTarget(context.Background(), <span class="string">&quot;http://localhost:8080/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Send that Event.</span></span><br><span class="line"><span class="keyword">if</span> result := c.Send(ctx, event); !cloudevents.IsACK(result) &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to send, %v&quot;</span>, result)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>接受事件</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line">cloudevents <span class="string">&quot;github.com/cloudevents/sdk-go/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receive</span><span class="params">(event cloudevents.Event)</span></span> &#123;</span><br><span class="line"><span class="comment">// do something with event.</span></span><br><span class="line">    fmt.Printf(<span class="string">&quot;%s&quot;</span>, event)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// The default client is HTTP.</span></span><br><span class="line">c, err := cloudevents.NewDefaultClient()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to create client, %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">log.Fatal(c.StartReceiver(context.Background(), receive));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>序列化</p></li></ol><p><em><strong>序列化为JSON</strong></em></p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">event := cloudevents.NewEvent()</span><br><span class="line">event.SetSource(&quot;example/uri&quot;)</span><br><span class="line">event.SetType(&quot;example.type&quot;)</span><br><span class="line">event.SetData(cloudevents.ApplicationJSON, map[string]string&#123;&quot;hello&quot;: &quot;world&quot;&#125;)</span><br><span class="line"></span><br><span class="line">bytes, err := json.Marshal(event)</span><br></pre></td></tr></table></figure><p><em><strong>反序列化</strong></em></p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">event :=  cloudevents.NewEvent()</span><br><span class="line">err := json.Marshal(bytes, &amp;event)</span><br></pre></td></tr></table></figure><p><em><strong>Python</strong></em></p><ol><li><p>依赖包安装<br><code>pip install cloudevents</code></p></li><li><p>事件发送者<br>通过 Python SDK 中的 CloudEvent 类型构造 CloudEvents 事件，再利用 to_binary函数将其序列化为 JSON 格式的数据，使用 requests框架发送该 JSON 请求。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cloudevents.http <span class="keyword">import</span> CloudEvent, to_binary</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建CloudEvent结构体</span></span><br><span class="line"><span class="comment"># - The CloudEvent &quot;id&quot; is generated if omitted. &quot;specversion&quot; defaults to &quot;1.0&quot;.</span></span><br><span class="line">attributes = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;com.example.sampletype1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;source&quot;</span>: <span class="string">&quot;https://example.com/event-producer&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">data = &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Hello World!&quot;</span>&#125;</span><br><span class="line">event = CloudEvent(attributes, data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用to_binary函数将其序列化为 JSON 格式的数据</span></span><br><span class="line">headers, body = to_binary(event)</span><br><span class="line"></span><br><span class="line"><span class="comment"># POST</span></span><br><span class="line">requests.post(<span class="string">&quot;&lt;some-url&gt;&quot;</span>, data=body, headers=headers)</span><br></pre></td></tr></table></figure><ol start="3"><li>接受事件处理</li></ol><p>通过 Python SDK 中的 from_http 函数解析出 CloudEvents 事件，并打印事件内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cloudevents.http <span class="keyword">import</span> from_http</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create an endpoint at http://localhost:/3000/</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/&quot;</span>, methods=[<span class="string">&quot;POST&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">home</span>():</span><br><span class="line">    <span class="comment"># create a CloudEvent</span></span><br><span class="line">    event = from_http(request.headers, request.get_data())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># you can access cloudevent fields as seen below</span></span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Found <span class="subst">&#123;event[<span class="string">&#x27;id&#x27;</span>]&#125;</span> from <span class="subst">&#123;event[<span class="string">&#x27;source&#x27;</span>]&#125;</span> with type &quot;</span></span><br><span class="line">        <span class="string">f&quot;<span class="subst">&#123;event[<span class="string">&#x27;type&#x27;</span>]&#125;</span> and specversion <span class="subst">&#123;event[<span class="string">&#x27;specversion&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>, <span class="number">204</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app.run(port=<span class="number">3000</span>)</span><br></pre></td></tr></table></figure><hr><h4 id="二、接入方式"><a href="#二、接入方式" class="headerlink" title="二、接入方式"></a>二、接入方式</h4><h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5><p>基于事件驱动服务是函数计算的核心功能之一，平台使用 Knative Eventing 的Broker&#x2F;Trigger 事件处理模型对事件进行过滤分发，此外为了确保跨平台和互操作性，将采用CNCF定义的标准数据格式CloudEvents 进行事件传输。</p><p><img src="https://s3.ax1x.com/2020/12/20/rafMi4.png" alt="图 1 产品接入架构"></p><p>如上图所示，架构分为三块内容，从左到右分别为事件源，事件接收&#x2F;转发者，事件消费者。</p><ol><li>事件源</li></ol><p>事件源是一种 Kubernetes 定制资源，它提供了一种机制，用于注册来自特定服务系统的一类事件。例如：对象存储事件源，Github事件源等等，因此不同的事件源需要的不同的自定义资源进行描述。</p><p>事件源负责获取特定服务系统的事件，并将事件转化为CloudEvents格式事件发送给 Knative Eventing 平台（即 Broker&#x2F;Trigger事件处理模型）。</p><ol start="2"><li>事件接受&#x2F;转发者</li></ol><p>引入Broker&#x2F;Trigger事件处理模型的目的，是为了搭建一些黑盒子，将具体的实现隐藏起来，用户无需关心底层实现细节。</p><ul><li>Broker如同事件桶，接收各种不同的事件，这些事件可以通过属性来过滤。</li><li>Trigger描述了一个过滤器，只有通过了过滤器选择的事件，可以被传送给事件消费者。</li></ul><p>如图1所示，用户通过 filter指定感兴趣红色小球的事件，最终只有该类事件被传送给事件消费者（这里是Knative Service，即 KSvc函数）。</p><ol start="3"><li>事件消费者</li></ol><p>事件消费者可以是某个服务或系统，这里的事件消费者是用户编写的KSvc函数（即处理事件的逻辑代码）。</p><h5 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h5><ol><li>第三方接入</li></ol><p>第三方服务接入基于knative实现的serverless平台需要提供特定的事件源，Knative社区已维护部分事件源，具体列表请查看：<a href="https://github.com/knative/eventing-contrib">https://github.com/knative/eventing-contrib</a></p><p>如果第三方服务不在社区提供的支持列表中，就需要自定义事件源，有如下常用的几种方式：</p><p><img src="https://s3.ax1x.com/2020/12/20/rafGsx.png"></p><p>ContainerSource 实现简单，是目前大部分自定义事件源的实现方式，也是KNative平台推荐的方式。</p><p>ContainerSource 是 Kubernetes 中自定义的 CRD（Custom Resource Definition）资源类型，具体定义如下</p><p><img src="https://s3.ax1x.com/2020/12/20/rafteK.png" alt="CRD"></p><p>主要看以下几个部分：</p><ol><li>sink：事件转发的目标对象，这里即图1中介绍的Borker</li><li>image：需要开发的镜像，包括了监听具体数据源的事件和转发事件到sink的实现</li><li>arg和env：开发者自定义的一些数据通过 arg 和 env 传入镜像</li></ol><p>ContainerSource 中 image 镜像部分即需要自定义实现的部分，实现方式根据获取第三方服务事件的不同分为以下两种：</p><ol><li>消息队列方式<br>如下图 2所示，如果第三方服务已适配消息队列，可以将产生的事件发往消息队列，此时 ContainerSource 可以直接从消息队列中消费第三方服务的事件。</li></ol><p><img src="https://s3.ax1x.com/2020/12/20/rafdFe.png" alt="图 2 消息队列方式"></p><ol start="2"><li>直连方式<br>如下图 3所示，如果第三方服务未适配消息队列，但服务本身提供事件订阅能力（如 Redis 的键空间特性，Keyspace Notifications future），此时 ContainerSource 可以直接订阅第三方服务的事件，监听服务变化。</li></ol><p><img src="https://s3.ax1x.com/2020/12/20/raf0Wd.png" alt="图 3 直连方式"></p><p>注意：无论采用以上哪种方式，ContainerSource 在生成 CloudEvents 事件时，都需要携带 KSVC 目标函数的唯一标识，以供平台侧分发事件时使用。例如：1. 消息队列方式，由于所有事件都从同一个消息队列中获取，此时需要在第三方服务生产事件时就携带目标函数的标识（对象存储产品接入时采用该方式）；2. 直连方式，由于 ContainerSource 与第三方服务是一对一关系，所以可以在 ContainerSource 生成 CloudEvents 事件时添加目标函数的标识。</p><p>利用 Broker&#x2F;Trigger 事件处理模型，极大简化了第三方服务接入函数计算的流程。无论使用消息队列方式还是直连方式，产品侧只需要提供适配第三方服务的 ContainerSource 镜像，以供平台侧使用。</p><ol start="2"><li>平台侧纳管</li></ol><p>平台侧的工作主要是纳管产品侧提供的 ContainerSource，并利用 Trigger 提供事件过滤的能力。</p><p>针对 ContainerSource 不同的实现方式，平台侧工作内容也有所区别：</p><p><em><strong>消息队列实现方式</strong></em></p><p>平台侧会创建如下内容：</p><ol><li>一组相同的ContainerSource（用于高可用）</li><li>一个 Broker 类型的资源，用于分发事件</li><li>多个 Trigger 类型资源，用于事件过滤</li></ol><p>平台侧会预先创建好 ContainerSource 和 Broker 资源，并提供纳管 Trigger 的增删改查接口用于事件过滤，此时 ContainerSource，Broker，Trigger 对应关系如下图所示：</p><p><img src="https://s3.ax1x.com/2020/12/20/rafsyt.png"></p><p><em><strong>直连方式</strong></em></p><p>平台侧会创建如下内容：</p><ol><li>多个 ContainerSource 订阅监听不同的服务实例</li><li>一个 Broker 类型的资源，用于分发事件</li><li>多个 Trigger 类型资源，用于事件过滤</li></ol><p>平台侧会预先提供好 Broker 资源，并提供纳管 ContainerSource 和 Trigger 的增删改查接口，此时 ContainerSource，Broker，Trigger 对应关系如下图所示：</p><p><img src="https://s3.ax1x.com/2020/12/20/rafcef.png"></p><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li><li><a href="https://cloudevents.github.io/sdk-go/">go sdk</a></li><li><a href="https://github.com/cloudevents/sdk-go">sdk-go</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。&lt;br&gt;对于CloudEvent的介绍</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents三部曲:规范篇</title>
    <link href="https://zoues.com/posts/e6aacf5d/"/>
    <id>https://zoues.com/posts/e6aacf5d/</id>
    <published>2020-12-20T13:40:08.000Z</published>
    <updated>2024-01-21T02:27:48.214Z</updated>
    
    <content type="html"><![CDATA[<p>随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。<br>对于CloudEvent的介绍、规范说明及实践落地，将以三篇系列文章进行说明，本文为《CloudEvent三部曲:规范篇》.</p><hr><h4 id="一、规范概述"><a href="#一、规范概述" class="headerlink" title="一、规范概述"></a>一、规范概述</h4><p>事件虽无处不在，但事件生产者往往会以不同的方式来描述事件。</p><p>关于事件的行业规范的缺失意味着开发人员必须重复对接事件处理流程。这增加了跨系统（多系统）发送事件的难度，降低事件处理的可移植性。</p><p>CloudEvents是一种用通用格式描述事件数据的规范，以提供跨服务、平台和系统的互操作性。事件格式指定了如何用特定的编码格式对 CloudEvents 进行序列化。支持这些编码的CloudEvents实现必须遵守相应事件格式中指定的编码规则，所有实现都必须支持JSON格式，<em>protobuf</em>的格式也在有序推进中。</p><h6 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h6><p>CloudEvents通常用于分布式系统，以允许服务在开发期间低耦合，并独立部署，便于连接以构建新应用程序。</p><p>CloudEvents的目标是定义事件系统的互操作性，该系统允许服务生成或使用事件，其中包括独立开发和部署生产者和使用者。生产者可以在消费者收听之前生成事件，并且消费者可以进行相关订阅操作。需要注意的是，此工作产生的规范集中于事件格式的互操作性以及在各种协议（例如HTTP、protobuf）上发送事件格式的显示方式。规范不关注事件产生者或事件消费者的处理模型。</p><p>CloudEvents的核心是定义了一组元数据，称为属性，以及有关在系统之间传输的事件和这些元数据应如何出现在消息中。该元数据是定义了将请求路由到适当组件并促进该组件对事件进行适当处理所需的最少数据集。尽管这可能意味着事件本身的某些应用程序数据可能会作为CloudEvents属性集的一部分，但这也是为了正确传递和处理消息而进行的必要操作。</p><p><strong><strong>非规范范畴</strong></strong></p><p>以下内容不属于规范考虑范畴：</p><ul><li>函数构建和调用过程</li><li>特定语言的运行时API</li><li>单一身份&#x2F;访问控制系统</li></ul><hr><h4 id="二、符号和术语"><a href="#二、符号和术语" class="headerlink" title="二、符号和术语"></a>二、符号和术语</h4><h5 id="符号约定"><a href="#符号约定" class="headerlink" title="符号约定"></a>符号约定</h5><p>为了清楚起见，当一个功能被标记为”可选”时，这表明消息的生产者和消费者都可以选择支持该功能。换句话说，如果生产者愿意，可以选择将该功能包含在消息中，如果消费者愿意，可以选择支持该功能。那么不支持该功能的消费者就会默默地忽略消息中的那部分内容。生产者需要为消费者忽略该功能的情况做好准备。中间人应该转发选择性属性。</p><p><em><strong>触发</strong></em></p><p>“触发”是指在软件系统运行过程中获取到的事件。这可能是由于系统引发的信号或系统观察到的信号、状态变化、计时器过期或任何其他值得注意的活动而发生。例如，设备可能因为电池电量不足而进入警报状态，或者虚拟机即将执行预定的重启。</p><p><em><strong>事件</strong></em></p><p>“事件”是表示事件发生及其上下文的数据记录。事件被从事件生产者（源）分发到感兴趣的事件消费者。可以根据事件中包含的信息进行分发，但事件不会确定具体的分发目的地。事件将包含两类信息：事件数据代表触发后的数据，而上下文元数据提供关于事件触发的上下文信息。一个事件触发可能会产生多个事件。</p><p><em><strong>生产者</strong></em></p><p>“生产者”是特定实例、过程或设备，用于创建描述CloudEvent的数据结构。</p><p><em><strong>事件源</strong></em></p><p>“来源”是指事件触发时的上下文。在一个分布式系统中，它可能由多个生产者组成。</p><p><em><strong>消费者</strong></em></p><p>“消费者”接收事件，并对其采取行动。它使用上下文和数据来执行一些逻辑，这可能导致新事件的发生。</p><p><em><strong>中介机构</strong></em></p><p>“中介机构”接收包含事件的消息（如中间件），目的是将其转发给下一个接收者，而接收者可能是另一个中间人或消费者。中间人的一个典型任务是根据上下文中的信息将事件转发到接收者。</p><p><em><strong>上下文</strong></em></p><p>上下文元数据将被封装在上下文属性中。工具和应用程序代码可以使用这些信息来识别事件与系统的各个方面或与其他事件的关系。</p><p><em><strong>数据</strong></em></p><p>事件的特定信息。这可能包括有关触发事件的信息、修改后的数据等。</p><p><em><strong>事件格式</strong></em></p><p>事件格式指定了如何将CloudEvent序列化为字节序列。独立的事件格式（如JSON、protobuf格式）可指定独立于任何协议或存储介质的序列化。</p><p><em><strong>消息</strong></em></p><p>事件通过消息从事件源传输到目的地。</p><p>“结构化报文”是指使用独立的事件格式对事件进行完全编码并存储在消息主体中。</p><p>“二进制报文”是指事件数据存储在消息体中，事件属性作为消息元数据的一部分进行存储。</p><p><em><strong>协议</strong></em></p><p>消息可以通过各种行业标准协议（例如HTTP，AMQP，MQTT，SMTP），开源协议（例如Kafka，NATS）或平台&#x2F;供应商特定协议（AWS Kinesis，Azure Event Grid）进行传递。</p><h5 id="上下文属性"><a href="#上下文属性" class="headerlink" title="上下文属性"></a>上下文属性</h5><p>符合本规范的每个CloudEvent必须包含上下文等属性。这些属性在描述事件的同时，被设计为可以独立于事件数据进行序列化。这使得它们可以在目的地被检查，而不需要对事件数据进行反序列化。</p><p><em><strong>属性命名约定</strong></em></p><p>CloudEvents规范定义了对各种协议和编码的映射，随附的CloudEvents SDK针对各种运行时和语言。其中有些将元数据元素视为大小写敏感，而另一些则不敏感，而且单个CloudEvent可能会通过多个跳转来实现，中间涉及协议、编码和运行时。因此，本规范限制了所有属性的可用字符集，以防止大小写敏感问题或与通用语言中标识符的允许字符集冲突。</p><p>CloudEvents属性名称必须由ASCII字符集中的小写字母或数字组成。属性名称应具有描述性和简洁性，长度不得超过20个字符。</p><p><em><strong>类型系统</strong></em></p><p>以下是可用于属性中的抽象数据类型。这些类型中的每个类型都可以由不同的事件格式和协议元数据字段来表示。本规范为每个类型定义了一个标准的字符串编码，所有的实现都必须支持。</p><ul><li>布尔型 - 值为<code>true</code>或<code>false</code>的布尔值。<br>字符串编码：大小写敏感的<code>true</code>或<code>false</code>值。</li><li>整型 - <code>2,147,483,648</code>到<code>+2,147,483,647</code>之间的整数。这是一个有符号的、32位的、二进制编码的范围。事件格式不一定要使用这个编码，但它们必须只<br>使用这个范围内的整数值。<br>字符串编码: 根据RFC 7159，第6节，JSON号码的整数部分。</li><li>字符串 - 允许的Unicode字符序列。以下字符不允许使用。</li></ul><ul><li>U+0000-U+001F 和 U+007F-U+009F (两个范围都包括在内)中的”控制字符”，因为大多数字符没有约定的含义，有些字符，如 U+000A (换行符)，在HTTP头等上下文中不能使用。</li><li>代码点被Unicode识别为非字符。</li><li>U+D800-U+DBFF和U+DC00-U+DFFF，这两个范围都包括在内，除非正确地成对使用。</li></ul><p>而”\uD800\uDEAD”是合法的。</p><ul><li>字节 - 字节序列。</li><li>URI–绝对统一的资源标识符。</li></ul><ul><li>字符串编码：RFC4648中定义的绝对统一资源标识符。</li></ul><ul><li>URI-reference - 统一资源标识符引用。</li><li>时间戳 -使用Gregorian Calendar的日期和时间表达式。</li></ul><p>所有的上下文属性值必须是上面列出的类型之一。属性值可以以本地类型或标准字符串的形式呈现。表示 CloudEvent 或任何扩展的强类型编程模型必须能够将常规字符串编码转换为最适合抽象类型的运行时&#x2F;语言原生类型。</p><p>例如，在给定的实现中，时间属性可以用语言的本机日期时间类型来表示，但必须提供RFC3339字符串，并且在映射到HTTP消息的报文头时，必须可转换为RFC3339字符串。</p><p>同样，CloudEvents协议绑定或事件格式实现也必须能够在编码或协议元数据字段中将标准字符串编码转换为相应的数据类型。时间戳类型的属性值确实可以作为一个字符串通过多次跳转，并且只在生产者和最终消费者那里以本地运行时&#x2F;语言类型的形式实现。时间戳也可能被路由为本地协议类型，并可能在生产者和消费者端被映射到&#x2F;从各自的语言&#x2F;运行时类型，而永远不会以字符串的形式实现。</p><p>序列化机制的选择将决定上下文属性和事件数据的序列化方式。例如，在JSON序列化的情况下，上下文属性和事件数据可能同时出现在同一个JSON对象中。</p><h5 id="必要属性"><a href="#必要属性" class="headerlink" title="必要属性"></a>必要属性</h5><p>以下属性必须在所有CloudEvents中出现。</p><p><em><strong>id</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">id</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">字符串</td></tr><tr><td align="left">描述</td><td align="left">标示事件。生产者必须确保 source + id 对于每个独立的事件都是唯一的。如果一个重复的事件被重新发送（例如，由于网络错误），它可能有相同的id。消费者可能会认为 source 和 id 相同的事件是重复的。｜</td></tr><tr><td align="left">约束</td><td align="left">1. 必须 <br>2. 必须是一个非空字符串<br>3.必须在生产者范围内是唯一的</td></tr><tr><td align="left">范例</td><td align="left">1.由生产者维护的事件计数器<br>2.UUID</td></tr></tbody></table><p><em><strong>source</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">source</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">URI-reference</td></tr><tr><td align="left">描述</td><td align="left">标示事件发生的上下文。通常包括事件源的类型、发布事件的组织或产生事件的过程等信息。URI中编码的数据背后的确切语法和语义由事件生产者定义。生产者必须确保 source + id 对于每个独立的事件都是唯一的。应用程序可以为每个独立的生产者分配一个唯一的source，这样就很容易产生唯一的ID，因为没有其他生产者会有相同的source。应用程序可以使用 UUIDs、URNs、DNS 权限或特定于应用程序的方案来创建唯一的source标识符。一个源也可以包括多个的生产者。在这种情况下，生产者必须合作，确保 source + id 对于每个独立的事件都是唯一的。</td></tr><tr><td align="left">约束</td><td align="left">1. 必须<br>2.必须为非空URI-reference<br>3.推荐使用绝对URI</td></tr><tr><td align="left">范例</td><td align="left">全网唯一的URI，具有DNS权限。<br>1.<a href="https://github.com/cloudevents">https://github.com/cloudevents</a> <br>2.mailto:<a href="mailto:&#x63;&#110;&#x63;&#102;&#x2d;&#119;&#x67;&#x2d;&#115;&#101;&#114;&#118;&#101;&#114;&#x6c;&#x65;&#x73;&#115;&#x40;&#108;&#x69;&#x73;&#x74;&#115;&#x2e;&#99;&#110;&#x63;&#102;&#x2e;&#105;&#x6f;">&#x63;&#110;&#x63;&#102;&#x2d;&#119;&#x67;&#x2d;&#115;&#101;&#114;&#118;&#101;&#114;&#x6c;&#x65;&#x73;&#115;&#x40;&#108;&#x69;&#x73;&#x74;&#115;&#x2e;&#99;&#110;&#x63;&#102;&#x2e;&#105;&#x6f;</a><br><br>通用唯一的URN与UUID<br>1.urn:uuid:6e8bc430-9c3a-11d9-9669-0800200c9a66<br><br>应用特定的标识符<br>1.&#x2F;cloudevents&#x2F;spec&#x2F;pull&#x2F;123<br>2.&#x2F;sensors&#x2F;tn-1234567&#x2F;alertsd.1-555-123-4567</td></tr></tbody></table><p><em><strong>specversion</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">specversion</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">字符串</td></tr><tr><td align="left">描述</td><td align="left">事件所使用的CloudEvents规范的版本。该版本可用于解释上下文。</td></tr><tr><td align="left">约束</td><td align="left">1. 必须<br>2.必须是一个非空字符串<br>3.必须在生产者范围内是唯一的</td></tr></tbody></table><p><em><strong>type</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">type</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">字符串</td></tr><tr><td align="left">描述</td><td align="left">该属性包含一个描述事件类型的值，描述与起源事件相关的事件类型。该属性通常用于路由、监控、策略执行等。该属性的格式是由生产者定义的。</td></tr><tr><td align="left">约束</td><td align="left">1. 必须<br>2.必须是一个非空字符串<br>3.应该以一个反转的DNS名称为前缀。前缀域决定了定义这个事件类型的语义的组织。</td></tr><tr><td align="left">范例</td><td align="left">a.com.github.pull.create<br>b.com.example.object.delete.v2</td></tr></tbody></table><h5 id="可选属性"><a href="#可选属性" class="headerlink" title="可选属性"></a>可选属性</h5><p>以下为在CloudEvents中出现的可选属性。</p><p><em><strong>datacontenttype</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">datacontenttype</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">字符串</td></tr><tr><td align="left">描述</td><td align="left">数据的内容类型。该属性使数据可以携带任何类型的内容，其格式和编码可能与所选事件格式不同。例如，使用JSON信封格式渲染的事件可能会携带一个XM的数据，这个属性被设置为”application&#x2F;xml”就会通知消费者。不同的数据内容如何渲染不同的数据内容类型值的规则在事件格式规范中定义了，对于一些二进制模式的协议绑定，该字段直接映射到各自协议的内容类型元数据属性。二进制模式和内容类型元数据映射的规范性规则可以在相应的协议中找到。在某些事件格式中，datacontententtype属性可能会被省略。例如，如果一个JSON格式的事件没有datacontententtype属性，那么就意味着数据是符合”application&#x2F;json”类型的JSON值。换句话说：一个没有datacontententtype的JSON格式事件与一个datacontenttype&#x3D;”application&#x2F;json”的事件完全等同。当将一个没有datacontenttype属性的事件消息翻译成不同的格式或协议绑定时，目标datacontenttype应该明确地设置为源的隐含datacontenttype。</td></tr><tr><td align="left">约束</td><td align="left">1. 可选<br>2.如果存在，必须遵守RFC 2046中规定的格式。</td></tr></tbody></table><p><em><strong>dataschema</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">dataschema</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">URI</td></tr><tr><td align="left">描述</td><td align="left">指明数据所遵循的 schema。对模式不兼容的更改应该通过不同的URI来反映。</td></tr><tr><td align="left">约束</td><td align="left">1. 可选 <br>2.必须是一个非空字符串</td></tr></tbody></table><p><em><strong>subject</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">subject</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">字符串</td></tr><tr><td align="left">描述</td><td align="left">描述了事件生产者（通过 source 标识）上下文中的事件主题。在发布-订阅场景中，订阅者通常会订阅由源发出的事件，但如果源上下文有内部子结构，仅有源标识符可能不足以作为任何特定事件的限定符。</td></tr><tr><td align="left">约束</td><td align="left">1.可选<br>2.必须是一个非空字符串</td></tr><tr><td align="left">范例</td><td align="left">当在blob-存储容器内创建新的blob时，订阅者可能会对此进行订阅。在这种情况下，事件 source 标识了订阅范围（存储容器），type 标识了”blob创建”事件，id唯一标识了事件实例，以区分已创建的相同名称的blob；新创建的blob的名称携带在subject中。<br>source：<a href="https://example.com/storage/tenant/container">https://example.com/storage/tenant/container</a><br>subject: mynewfile.jpg</td></tr></tbody></table><p><em><strong>time</strong></em></p><table><thead><tr><th align="left">属性名</th><th align="left">time</th></tr></thead><tbody><tr><td align="left">类型</td><td align="left">Timestamp</td></tr><tr><td align="left">描述</td><td align="left">事件发生的时间戳。如果无法确定事件发生的时间，则该属性可以由 CloudEvents 生产者设置为其他时间（如当前时间），但同一源的所有生产者在这方面必须保持一致。换句话说，它们要么都使用实际发生的时间，要么都使用相同的算法来确定所使用的值。</td></tr><tr><td align="left">约束</td><td align="left">1.必须<br>2.如果存在，必须遵守RFC 3339中规定的格式。</td></tr></tbody></table><h5 id="扩展上下文属性"><a href="#扩展上下文属性" class="headerlink" title="扩展上下文属性"></a>扩展上下文属性</h5><p>CloudEvents可包含任意数量的具有不同名称的附加上下文属性，称为”扩展属性”。扩展属性必须遵循与标准属性相同的命名惯例，并使用与标准属性相同的类型系统。扩展属性在本规范中没有定义的含义，它们允许外部系统将元数据附加到事件中，就像HTTP自定义头一样。扩展属性总是按照与标准属性一样的绑定规则进行序列化。然而，本规范并不妨碍扩展将事件属性值复制到消息的其他部分，以便与同样处理消息的非CloudEvents系统进行交互。这样做的扩展规范应该指定如果复制的值与 cloud event 序列化的值不同，接收者应该如何解释消息。</p><p>扩展的定义应该定义属性的所有方面，例如，其名称、类型、语义和可能的值。新的扩展定义应该使用一个描述性足够强的名称，以减少与其他扩展名称同名的可能性。</p><p>许多协议支持发送者附加元数据的能力，例如作为 HTTP 头文件。虽然 CloudEvents 接收方没有被强制要求传递和处理这些元数据，但建议通过某种机制来解决这些元数据，以表明它们是非CloudEvents元数据。</p><hr><h4 id="事件数据"><a href="#事件数据" class="headerlink" title="事件数据"></a>事件数据</h4><p>CloudEvents可包括与事件发生相关的特定信息。如果存在，该类信息将被封装在数据中。</p><h5 id="长度限制"><a href="#长度限制" class="headerlink" title="长度限制"></a>长度限制</h5><p>在许多场景中，CloudEvents 将通过一个或多个中间件转发，每个中间件都可能会对转发事件的大小进行限制。CloudEvents也可能会被转发到消费者，比如嵌入式设备，这些设备受存储或内存限制。</p><p>事件的”大小”是指事件的线上大小，包括事件的线上传输的每一个比特：协议帧元数据、事件元数据和事件数据，基于所选的事件格式及所选的绑定协议。</p><p>如果应用配置要求在不同的协议之间转发事件，或要求对事件进行重新编码，则应考虑应用所使用的最有效的协议和编码，以符合这些大小限制。</p><ul><li>a.中间件必须转发大小为64KByte或以下的事件。</li><li>b.消费者应接受至少64 KByte大小的事件。</li></ul><p>实际上，这些规则将允许生产者安全地发布大小不超过64KB的事件。</p><p>一般来说，CloudEvents 发布者应该通过避免在事件有效载荷中嵌入大型数据项来保持事件的紧凑性，而是使用事件有效载荷链接到这些数据项。从访问控制的角度来看，这种方法还可以让事件的分布范围更广，因为通过解析链接访问事件相关的细节，可以实现差异化的访问控制和选择性的披露，而不是直接将敏感细节嵌入事件中。</p><h5 id="隐私与安全"><a href="#隐私与安全" class="headerlink" title="隐私与安全"></a>隐私与安全</h5><p>互操作性是本规范背后的主要驱动力，要实现这样的行为，需要将一些信息公开，导致信息泄露的可能性。</p><p>请考虑以下几点，以防止不经意间的数据泄漏，特别是在利用第三方平台及通信网络时。</p><ol><li><p>上下文属性<br>敏感信息不应在上下文属性中携带或表示。<br>CloudEvents生产者、消费者和中间人可以审查并记录上下文属性。</p></li><li><p>数据<br>业务数据应进行加密，以限制受信任方的可见性。数据加密是生产者和消费者之间的协议，不属于本规范的范围。</p></li><li><p>协议绑定<br>应采用工业级的安全方案，以确保CloudEvents的可信及安全的信息交换。</p></li></ol><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。&lt;br&gt;对于CloudEvent的介绍</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents三部曲:初识篇</title>
    <link href="https://zoues.com/posts/744a240b/"/>
    <id>https://zoues.com/posts/744a240b/</id>
    <published>2020-12-20T12:40:08.000Z</published>
    <updated>2024-01-21T02:44:16.933Z</updated>
    
    <content type="html"><![CDATA[<p>随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。<br>对于CloudEvent的介绍、规范说明及实践落地，将以三篇系列文章进行说明，本文为《CloudEvent三部曲:初识篇》.</p><hr><h4 id="一、规范背景"><a href="#一、规范背景" class="headerlink" title="一、规范背景"></a>一、规范背景</h4><h5 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h5><p>事件在系统设计中已经变的无处不在，但各类事件的提供方倾向于以不同的方式来描述事件，缺乏一种对事件的统一描述，事件使用方和提供方往往要花费大量的时间沟通字段定义，设计事件属性，并在将来的使用过程中疲于新增或修改事件的属性。这也限制了类库、工具和基础设施在跨环境时发送事件数据的潜力，如SDK、事件路由器或跟踪系统等。</p><p>随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。</p><h5 id="历史背景"><a href="#历史背景" class="headerlink" title="历史背景"></a>历史背景</h5><p>CloudEvents 是一种以通用方式描述事件数据的供应商中立的规范，该事件数据定义规范旨在简化跨服务，平台及其他方面的事件声明和发送。</p><p> CloudEvents 的相关工作最初是作为云原生计算基金会（Cloud Native Computing Foundation，简称 CNCF）Serverless工作组的一部分开展的，当规范达到v0.1的里程碑之后，于2018年5月15日获得技术监督委员会（Technical Oversight Committee，简称 TOC）批准作为一个全新的独立的CNCF沙盒项目。</p><p>2019年10月24日，CloudEvents项目取得了两项重大成果。第一，CNCF的技术监督委员会批准该项目成为 “孵化器“项目（从而使其从CNCF的“沙盒”毕业）。第二，CloudEvents规范发布了1.0版本，这是该规范的第一个主要版本！</p><h6 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h6><p>目前各大第三方云提供商都在大力推广落地CloudEvents规范，例如：</p><ul><li>2018年，微软宣布将通过Event Grid服务（一项由Azure集中管理的事件服务，支持用户通过“发布-订阅”机制发送和接收事件）提供对CloudEvents的支持</li><li>2019年，阿里云开始推广 OpenMessaging 标准协议，希望让 Apache RocketMQ 兼容 Cloudevent 体系，成为 Serverless 的桥梁</li><li>2020年，字节跳动在其函数计算产品中利用CloudEvents规范统一事件源标准，极大方便之后的能力扩展。</li></ul><p>但大多数云目前缺乏CloudEvents规范的相应支持，导致各能力服务之间的联动效率较差，该问题丞待解决。</p><hr><h4 id="二、规范优势"><a href="#二、规范优势" class="headerlink" title="二、规范优势"></a>二、规范优势</h4><p>从历史上看，行业缺乏描述无服务器的事件元数据的标准，这意味着开发人员需要重新学习如何跨系统使用各种类型的事件数据，从而难以构建可移植的工具。 CloudEvents 定义了一套一致的元数据，且首次将业界的云供应商、企业软件巨头和初创企业的无服务器社区聚集在一起，实现并支持该规范。</p><p>CloudEvents 具有如下一些优势：</p><h5 id="消费优势"><a href="#消费优势" class="headerlink" title="消费优势"></a>消费优势</h5><p>生产者生产事件供消费者使用时，由于使用了 CloudEvents 规范，消费者不再需要为平台或服务的差异性编写特定的消费逻辑，改而使用通用逻辑处理事件数据，方便事件消费者提高开发效率，并降低系统复杂度。例如：阿里云的事件总线 EventBridge，微软Azure的Event Grid服务都极大方便了产品的端到端集成。</p><h5 id="路由优势"><a href="#路由优势" class="headerlink" title="路由优势"></a>路由优势</h5><p>中间件将事件从生产者路由到消费者，或者转发到其他中间件的时，CloudEvents会保留事件的身份和语义完整性。 用于事件的分类过滤或元数据的鉴别。例如：消费者利用过滤功能只关注特定用户；或者利用元数据鉴别只接收后缀为 .doc 的新建文件等。</p><p>利用 CloudEvents中间件可以在改变事件的语义含义时承担生成器的角色，在基于事件采取行动时承担消费者的角色，或在路由事件不进行语义更改时承担中间件的角色。例如： Apache RocketMQ 社区发布的OpenMessaging 标准协议兼容CloudEvents规范，从而成为 Serverless 的桥梁，更加高效广泛的进行消息路由。</p><h5 id="交互优势"><a href="#交互优势" class="headerlink" title="交互优势"></a>交互优势</h5><p>利用 CloudEvents系统框架对内解耦各模块的通信能力，提高可维护性；对外与其他事件平台基础设施的交互将更简单，并且方便为其他平台设施提供通用 API，降低交互的复杂性，提高系统平台的扩展性。</p><hr><h4 id="三、落地场景"><a href="#三、落地场景" class="headerlink" title="三、落地场景"></a>三、落地场景</h4><p>CloudEvents 在如下场景中有广泛的应用价值：</p><h5 id="跨平台和服务的事件规范化"><a href="#跨平台和服务的事件规范化" class="headerlink" title="跨平台和服务的事件规范化"></a>跨平台和服务的事件规范化</h5><p>不同的云提供商都在各自的平台上以不同的格式发布事件，此外同一云提供商上的不同服务也可能以不同的格式发布事件。这就迫使事件消费者不得不针对各类平台或各类服务编写针对性逻辑来消费事件数据。而CloudEvents 可以为处理跨平台和跨服务的事件的消费者提供统一的体验。</p><h5 id="事件追踪"><a href="#事件追踪" class="headerlink" title="事件追踪"></a>事件追踪</h5><p>从事件源发送的事件可能会导致各种中间件设备（如事件代理和网关）产生的附加事件序列。利用CloudEvents 包含事件的元数据这一特性（例如：事件经过多个代理时，代理会将自身IP追加到CloudEvents扩展属性中，最终事件消费者可以通过扩展属性中的 IP 信息，知道事件经过哪些代理），可以将这些附加的事件信息作为源事件序列的一部分进行关联，从而进行事件追踪和故障排除。</p><h5 id="提高Serverless的可移植性"><a href="#提高Serverless的可移植性" class="headerlink" title="提高Serverless的可移植性"></a>提高Serverless的可移植性</h5><p>Serverless（也称无服务器计算）是IT领域发展最快的趋势之一，它主要是由事件驱动。然而，供应商的锁定是FaaS的一个主要问题，这种锁定部分主要是由于各供应商函数内部接收事件数据的格式差异造成的。CloudEvents 对事件数据的通用描述方式解决了该问题，从而提高了FaaS的可移植性。</p><p>微软Azure的Event Grid事件服务提供了对CloudEvens的支持，用户可以将自己的CloudEvents推送到指定的Azure Grid Event主题（topic）。此后，Grid Event支持将符合CloudEvent模式的事件转换为符合特定Event Grid模式的事件，或者反之。</p><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着云原生的发展（云原生的下一个五年在哪里？），逐步进入深水区，业界需要一种统一的事件定义和描述规范，以提供跨服务、跨平台的交互能力。CloudEvents事件规范应运而生，并得到了行业的广泛关注，包括主要的云提供商和 SaaS 公司。&lt;br&gt;对于CloudEvent的介绍</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>关于Kubernetes废弃内置docker CRI功能的说明</title>
    <link href="https://zoues.com/posts/2698d6f3/"/>
    <id>https://zoues.com/posts/2698d6f3/</id>
    <published>2020-12-06T14:56:01.000Z</published>
    <updated>2024-01-20T12:01:27.474Z</updated>
    
    <content type="html"><![CDATA[<p>今天，zouyee带各位看看关于前几天Kubernetes“废弃”docker支持的申明。首先，请各位稍安勿躁，主要还是中英文的翻译差别以及标题所引发的歧义，对Kubernetes开源项目有所了解的朋友，可能知道，该项目成功的原因之一，就在于对于接口及功能的版本管理，社区有一套完整且行之有效的方案，接口的兼容性、版本的多样性管理是驱动Kubernetes社区不断前行的内因。<br>先说结论：</p><ol><li>对于使用者没有任何影响</li><li>对于开发者，若想保持原有docker使用方式只是新增一个已知组件</li></ol><p>Kubernetes 1.20前后，对于docker的支持没有变化，只是将该部分代码（dockershim）独立出来，使用者可独立配置。</p><hr><h4 id="一、改变动因"><a href="#一、改变动因" class="headerlink" title="一、改变动因"></a>一、改变动因</h4><p>维护dockershim已成为Kubernetes维护人员的一种负担。创建CRI标准就是为了减轻这种负担，并提升不同容器运行时的可移植性性。Docker本身目前没有实现CRI，但Containerd实现了CRI接口。Dockershim一直是一种临时解决方案，此外，与dockershim不兼容的特性，如cgroups v2和用户命名空间，实现CRI接口的运行时也在慢慢探索并实现上述特性。</p><p><strong>何时完全废弃dockershim</strong></p><p>考虑到此更改的影响，它在Kubernetes 1.22之前不会被删除。</p><hr><h4 id="二、架构变化"><a href="#二、架构变化" class="headerlink" title="二、架构变化"></a>二、架构变化</h4><p>在Kubernetes架构中，是由Kubelet组件负责与容器运行时交互的。Kubelet调用容器运行时的流程如下图所示。</p><p><img src="https://s3.ax1x.com/2020/12/06/DjNt8x.png"></p><p>CRI shim是实现CRI接口提供的gRPC server服务，负责连接Kubelet和Container runtime，Container runtime是容器运行时工具；具体的流程是Kubelet调用CRI shim接口，CRI shim响应请求，然后调用底层的Container runtime工具运行容器。Kubelet、CRI shim和Container runtime都部署在一个Kubernetes 业务节点上，前两者是以独立的守护进程的方式启动的，而Container runtime不是守护进程，它通常是一个命令行工具。Kubernetes在1.5版本之前没有CRI接口，当时Kubelet内部只集成了两种容器运行时(Docker和rkt)的代码。但这两种容器运行时并不能满足用户的所有使用场景（rkt早已废弃），因为用户对容器的安全隔离性及性能在不同的应用场景有着不同的需求，用户希望Kubernetes能支持更多种的容器运行时。因此，Kubernetes在1.5版本推出了CRI接口，各个容器运行时只要实现了CRI接口规范，就可以接入到Kubernetes平台。在推出CRI后，Kublet为了满足CRI接口，实现了dockershim以支持直接使用docker接口，前期Containerd为了支持CRI接口，实现了CRI-Containerd，但在Containerd 1.1发布后，CRI-Containerd被废弃，转而使用插件方式支持CRI，即CRI插件，当前Kubernetes(1.20之前)关于docker及Containerd的支持如下所示。</p><p><img src="https://s3.ax1x.com/2020/12/06/DjN8a9.png"><br>内置dockershim方式</p><p><img src="https://s3.ax1x.com/2020/12/06/DjN3VJ.png"><br>containerd CRI方式</p><p>那么Kubernetes 1.20之后(1.22 之前)关于docker及Containerd的支持如下所示。<br><img src="https://s3.ax1x.com/2020/12/06/DjNN26.png"></p><p>Kubernetes 1.20之后，若前期使用dockershim内置方式，那么只需要再部署dockershim即可，若使用containerd等runtime，则保持不变即可,当然，官方推荐配置为containerd方式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天，zouyee带各位看看关于前几天Kubernetes“废弃”docker支持的申明。首先，请各位稍安勿躁，主要还是中英文的翻译差别以及标题所引发的歧义，对Kubernetes开源项目有所了解的朋友，可能知道，该项目成功的原因之一，就在于对于接口及功能的版本管理，社区有</summary>
      
    
    
    
    
    <category term="Docker" scheme="https://zoues.com/tags/Docker/"/>
    
    <category term="Kubernetes" scheme="https://zoues.com/tags/Kubernetes/"/>
    
    <category term="Containerd" scheme="https://zoues.com/tags/Containerd/"/>
    
  </entry>
  
  <entry>
    <title>Containerd CVE-2020–15257细节说明</title>
    <link href="https://zoues.com/posts/652176ee/"/>
    <id>https://zoues.com/posts/652176ee/</id>
    <published>2020-12-06T05:01:21.000Z</published>
    <updated>2024-01-21T02:29:07.231Z</updated>
    
    <content type="html"><![CDATA[<p>  Containerd是基于OCI规范实现的一款工业级标准的容器运行时。 Containerd在宿主机中管理容器生命周期，如容器镜像的传输和存储、容器的执行和管理、存储和网络等。 containerd-shim是用作容器运行的载体，实现容器生命周期管理， 其API以抽象命名空间Unix域套接字方式暴露，该套接字可通过根网络名称空间访问。 因此，一旦普通用户获得主机网络访问权限（通过启动主机网络模式的容器），则可以访问任一容器的API，并以此提权。</p><p>  在主机网络名称空间中运行容器是不安全的：</p><ul><li>请勿使用<code>docker run --net = host</code>运行Docker容器</li><li>请勿使用<code>.spec.hostNetwork：true</code>配置运行Kubernetes Pods</li></ul><h4 id="一、Containerd-CVE-2020–15257"><a href="#一、Containerd-CVE-2020–15257" class="headerlink" title="一、Containerd CVE-2020–15257"></a>一、Containerd CVE-2020–15257</h4><ol><li>漏洞级别</li></ol><p>该漏洞社区评分为5.2 分&#x2F;10分（中等）的安全级别，需要具备一定的触发条件、攻击路径较长。</p><ol start="2"><li>提权条件</li></ol><p>如果不受信任的用户在平台上无法创建主机网络模式（hostnetwork）的容器，或者容器内的进程是以非root用户（UID 0）运行，则不会触发该漏洞，具体满足以下多个条件：</p><ul><li>容器使用主机网络<code>hostnetwork</code>部署，此时容器和主机共享网络命名空间;</li><li>容器使用root用户(即UID 0);</li><li><code>containerd</code>版本在 &lt;&#x3D;1.3.7</li></ul><ol start="3"><li>漏洞确认</li></ol><p>对于在易受攻击的系统上运行容器的用户，可以通过禁止主机网络模式，或者通过确保此类容器以非零UID&#x2F;GID运行来缓解此问题。用户可将<code>containerd</code>版本更新到最新版本。 此外，更新前创建并运行的容器仍会受到攻击，因此用户需要确保所有容器完全停止，然后在更新后重新启动。</p><p>对于不确定<code>CVE-2020-15257</code>是否会影响的用户，可以使用以下命令快速确定受影响的<code>containerd</code>版本创建的容器是否仍在运行。 如果有返回结果，则说明存在。</p><p><code>$ cat /proc/net/unix | grep &#39;containerd-shim&#39; | grep &#39;@&#39;</code></p><ol start="4"><li>特别说明</li></ol><p>即使替换了补丁版本的<code>containerd</code>，使用主机网络也是不安全的。</p><hr><h4 id="二、-安全分析"><a href="#二、-安全分析" class="headerlink" title="二、 安全分析"></a>二、 安全分析</h4><h5 id="2-1-代码定位"><a href="#2-1-代码定位" class="headerlink" title="2.1 代码定位"></a>2.1 代码定位</h5><ul><li>containerd&#x2F;containerd<ul><li>runtime&#x2F;v1&#x2F;shim&#x2F;client&#x2F;client.go: WithStart(), newCommand()</li><li>cmd&#x2F;containerd-shim&#x2F;main_unix.go: serve()</li><li>cmd&#x2F;containerd-shim&#x2F;shim_linux.go: newServer()</li></ul></li><li>containerd&#x2F;ttrpc (via vendor&#x2F;github.com&#x2F;containerd&#x2F;ttrpc&#x2F;unixcreds_linux.go)<ul><li>unixcreds_linux.go: UnixSocketRequireSameUser()</li></ul></li></ul><h5 id="2-2-漏洞细节"><a href="#2-2-漏洞细节" class="headerlink" title="2.2 漏洞细节"></a>2.2 漏洞细节</h5><p>containerd是一个容器运行时的核心组件，其管理基于runc的容器，在Kubernetes中可通过Docker（dockershim）方式或CRI方式使用。Docker架构如下图所示。<br><img src="https://s3.ax1x.com/2020/12/06/DXnbsP.png" alt="containerd架构"><br>Docker架构包含docker、containerd、 containerd-shim、runC等组件。</p><ul><li><code>containerd</code>是容器运行时，作为守护进程，<code>containerd</code>通过<code>containerd-shim</code>调用<code>runc</code>管理容器。</li><li><code>containerd</code>作为守护进程，其对外暴露用于容器生命周期管理（如容器运行管理、镜像管理等）的gRPC接口。</li><li><code>containerd</code>生成<code>containerd-shim</code>进程对容器的生命周期进行一对一的管理。</li></ul><p>为了提供自己的gRPC（实际上是ttrpc，一种裁剪版gRPC协议）API，<code>containered-shim</code>监听Unix域套接字。 这些是Linux独有的Unix域套接字，其使用以空字节开头的长度前缀键，并且可以包含任意二进制序列。 它们在抽象Unix域套接字sun_path中嵌入了结尾的空字节，其可阻止常见的Unix工具（例如socat）与其连接。</p><ul><li>@&#x2F;containerd-shim&#x2F;&#x2F;&#x2F;shim.sock\0</li><li>@&#x2F;containerd-shim&#x2F;.sock\0</li></ul><p><code>containered-shim</code>不仅具有绑定和侦听此类套接字的能力，它还支持从其父进程接收任意套接字文件描述符。 <code>containerd</code>通过此方法，先创建抽象的Unix套接字并对其进行监听，在<code>containerd-shim</code>进程启动后，可以使用该句柄进行初始化，接下来<code>containerd-shim</code>启动<code>ttrpc</code>服务。 <code>containerd-shim</code>使用标准的Unix域套接字功能来验证传入的连接是否具有与其相同的UID和EUID（通常为UID：0和EUID：0）。</p><p><code>containerd-shim</code>所使用的抽象的Unix域套接字，是绑定在主机的网络命名空间上的。当一个恶意容器同样处于主机的网络命名空间中，该容器内的<code>root</code>用户，可以通过譬如<code>netstat -xl</code>或者<code>/proc/net/unix</code>来扫描，找到<code>containerd-shim</code>的套接字，然后链接<code>containerd-shim</code>的API以执行命令。</p><p><code>containerd-shim</code>暴露了许多危险的API，可用于逃避容器和执行特权命令。在使用的<code>containerd（-shim）</code>的两个主要版本1.2.x和1.3.x中，暴露以下能力：</p><ul><li>任意文件读取</li><li>任意文件追加</li><li>任意文件写入</li><li>containerd-shim中的任意命令执行</li><li>从runc config.json文件创建容器</li><li>启动创建的容器</li></ul><p>大多数用户实际上不受此CVE的影响。如果在未指定–user的情况下运行<code>docker run --net = host</code>，则会受到影响。如果Kubernetes用户使用<code>containerd</code>作为CRI运行时并使用<code>.spec.hostNetwork：true</code>配置运行pod且未设置<code>.spec.securityContext.runAsUser</code>，则受到影响。</p><p><img src="https://s3.ax1x.com/2020/12/06/DXk01K.png" alt="prefix"></p><p>该CVE修复了<code>containerd</code>的v1.4.3&#x2F;v1.3.9版本，其将抽象套接字修改为<code>/run/containerd</code>下基于文件的普通UNIX套接字。</p><p><img src="https://s3.ax1x.com/2020/12/06/DXEAaj.png" alt="fix"></p><h5 id="2-3-问题容器"><a href="#2-3-问题容器" class="headerlink" title="2.3 问题容器"></a>2.3 问题容器</h5><p>Docker执行以下命令：</p><p><code>$ docker ps -a --filter &#39;network=host&#39;</code></p><p>Kubernetes执行以下命令：</p><p><code>$ kubectl get pods -A -o json |    jq -c &#39;.items[] | select(.spec.hostNetwork==true) |[.metadata.namespace, .metadata.name]&#39;</code></p><h5 id="2-4-是否不使用network就一劳永逸"><a href="#2-4-是否不使用network就一劳永逸" class="headerlink" title="2.4 是否不使用network就一劳永逸"></a>2.4 是否不使用network就一劳永逸</h5><p>并不是的。 因为除了容器外，还有很多程序使用了抽象套接字。 这些程序包括：</p><ul><li>dbus</li><li>ibus</li><li>irqbalance</li><li>iscsid</li><li>iscsiuio</li><li>LXD</li><li>multipathd</li><li>X Window System</li><li>[historical] systemd before v212</li><li>[historical] Unity (desktop environment)</li><li>[historical] upstart</li></ul><p>等等</p><p>要查看主机上是否使用了抽象套接字，可运行<code>grep -ao &#39;@.*&#39; /proc/net/unix</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep -ao <span class="string">&#x27;@.*&#x27;</span> /proc/net/unix ⏎</span></span><br><span class="line">@/org/kernel/linux/storage/multipathd</span><br><span class="line">@/tmp/dbus-ihrEYFlKyT</span><br><span class="line">@/containerd-shim/moby/d0f4f5dd326d505f79e20ca891ad35516656353bc7974378237826b3456bff86/shim.sock</span><br><span class="line">@ISCSIADM_ABSTRACT_NAMESPACE</span><br><span class="line">@/containerd-shim/moby/d0f4f5dd326d505f79e20ca891ad35516656353bc7974378237826b3456bff86/shim.sock</span><br></pre></td></tr></table></figure><p>实际上，其实关于<code>containerd</code>的CVE-2020-15257漏洞，一些开发人员和用户早已知晓，但其一直未被视作安全漏洞，因为使用主机网络名称空间并不安全，无论是否存在<code>containerd</code>套接字。 虽然<code>containerd</code>项目考虑到攻击的影响范围而更改了漏洞策略，但上述的软件应该不会将抽象套接字视作漏洞。</p><hr><h4 id="三、安全建议"><a href="#三、安全建议" class="headerlink" title="三、安全建议"></a>三、安全建议</h4><p>在需要使用主机网络时，需要考虑以下安全策略</p><ul><li>以非root用户运行容器</li><li>AppArmor</li><li>SELinux等</li></ul><p><strong>Docker</strong></p><p>可以使用端口映射方式: <code>docker run -p</code><br>通信时执行以下命令：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect -f <span class="string">&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27;</span> nginx ⏎</span></span><br><span class="line">172.17.0.2</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.17.0.2</span></span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br></pre></td></tr></table></figure><p>或者修改docker proxy</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; /etc/docker/daemon.json ⏎</span></span></span><br><span class="line">&#123;&quot;userland-proxy&quot;: false&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">systemctl restart docker</span></span> </span><br></pre></td></tr></table></figure><p>以及其他方案，如</p><ul><li>AppArmor</li><li>SELinux等</li></ul><p><strong>Kubernetes</strong></p><p>对于使用Kubernetes的用户，可以使用以下方式或特性</p><ul><li><code>kubectl get pods -o wide</code>获取IP进行访问</li><li>内部DNS（CoreDNS）</li><li>kubectl port-forward</li><li>AppArmor</li><li>SELinux等</li></ul><h5 id="3-1-以非root用户运行容器"><a href="#3-1-以非root用户运行容器" class="headerlink" title="3.1 以非root用户运行容器"></a>3.1 以非root用户运行容器</h5><p>对于Docker，运行<code>docker run --net=host --user 12345 --security-opt no-new-privileges</code>。 确保选择与主机上现有用户帐户没有冲突的UID号。<br>无需指定<code>no-new-privileges</code>，但是建议禁止使用sudo之类的特权。</p><p>对于Kubernetes,指定Pod相关字段<code>.spec.[]containers.securityContext</code>:</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hostNetwork: true</span><br><span class="line">containers:</span><br><span class="line">- name: foo</span><br><span class="line">  securityContext:</span><br><span class="line">    runAsUser: 12345</span><br><span class="line">    allowPrivilegeEscalation: false</span><br></pre></td></tr></table></figure><p>对于普通用户使用1024以内端口，需要如下配置：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&#x27;net.ipv4.ip_unprivileged_port_start=0&#x27;</span> &gt; /etc/sysctl.d/99-user.conf ⏎</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sysctl --system</span></span><br></pre></td></tr></table></figure><h5 id="3-2-使用AppArmor"><a href="#3-2-使用AppArmor" class="headerlink" title="3.2 使用AppArmor"></a>3.2 使用AppArmor</h5><p>AppArmor是Linux安全模块，供多个发行版使用，包括Ubuntu，Debian，SUSE和Google COS。<br>以下AppArmor配置文件可用于禁止容器使用抽象套接字：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">include &lt;tunables/global&gt;</span></span><br><span class="line">profile docker-no-abstract-socket flags=(attach_disconnected,mediate_deleted) &#123;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">include &lt;abstractions/base&gt;</span></span><br><span class="line">  network,</span><br><span class="line">  capability,</span><br><span class="line">  file,</span><br><span class="line">  umount,</span><br><span class="line">  signal (receive) peer=unconfined,</span><br><span class="line">  signal (send,receive) peer=docker-no-abstract-socket,</span><br><span class="line">  deny @&#123;PROC&#125;/* w,</span><br><span class="line">  deny @&#123;PROC&#125;/&#123;[^1-9],[^1-9][^0-9],[^1-9s][^0-9y][^0-9s],[^1-9][^0-9][^0-9][^0-9]*&#125;/** w,</span><br><span class="line">  deny @&#123;PROC&#125;/sys/[^k]** w,</span><br><span class="line">  deny @&#123;PROC&#125;/sys/kernel/&#123;?,??,[^s][^h][^m]**&#125; w,</span><br><span class="line">  deny @&#123;PROC&#125;/sysrq-trigger rwklx,</span><br><span class="line">  deny @&#123;PROC&#125;/kcore rwklx,</span><br><span class="line">  deny mount,</span><br><span class="line">  deny /sys/[^f]*/** wklx,</span><br><span class="line">  deny /sys/f[^s]*/** wklx,</span><br><span class="line">  deny /sys/fs/[^c]*/** wklx,</span><br><span class="line">  deny /sys/fs/c[^g]*/** wklx,</span><br><span class="line">  deny /sys/fs/cg[^r]*/** wklx,</span><br><span class="line">  deny /sys/firmware/** rwklx,</span><br><span class="line">  deny /sys/kernel/security/** rwklx,</span><br><span class="line">  ptrace (trace,read,tracedby,readby) peer=docker-no-abstract-socket,</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Only the following line is related to abstract sockets.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Other lines are from <span class="string">&quot;docker-default&quot;</span> profile</span> </span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">(https://github.com/moby/moby/pull/39923)</span></span><br><span class="line">  deny unix addr=@**,</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">To load the profile, run `sudo apparmor_parser -r docker-no-abstract-socket`</span></span><br></pre></td></tr></table></figure><p>可以按如下所示将此配置文件应用于Docker容器：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo apparmor_parser -r docker-no-abstract-socket</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --net=host --security-opt apparmor=docker-no-abstract-socket ...</span></span><br></pre></td></tr></table></figure><p>关于在Kubernetes中如何使用<a href="https://kubernetes.io/docs/tutorials/clusters/apparmor/">AppArmor特性</a></p><h5 id="3-3-使用SELinux"><a href="#3-3-使用SELinux" class="headerlink" title="3.3 使用SELinux"></a>3.3 使用SELinux</h5><p>RHEL&#x2F;CentOS和Fedora的SELinux策略，用于保护主机上的抽象套接字：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">getenforce</span></span><br><span class="line">Enforcing</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">socat abstract-listen:foo,fork stdio &amp;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo podman run -it --net=host alpine</span></span><br><span class="line">/ # cat /proc/self/attr/current</span><br><span class="line">system_u:system_r:container_t:s0:c83,c1019</span><br><span class="line">/ # apk add -q socat</span><br><span class="line">/ # echo test | socat stdio abstract-connect:foo</span><br><span class="line">2020/11/27 15:42:08 socat[7] E connect(5, AF=1 &quot;\0foo&quot;, 6): Permission denied</span><br></pre></td></tr></table></figure><p>默认情况下，SELinux已启用Podman和OpenShift。 要为Docker启用SELinux，请按以下方式配置<code>/etc/docker/daemon.json</code>：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; /etc/docker/daemon.json</span></span></span><br><span class="line">&#123;&quot;selinux-enabled&quot;: true&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">systemctl restart docker</span></span></span><br></pre></td></tr></table></figure><hr><h4 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h4><ul><li><a href="https://research.nccgroup.com/2020/11/30/technical-advisory-containerd-containerd-shim-api-exposed-to-host-network-containers-cve-2020-15257/">technical advisory</a></li><li><a href="https://medium.com/nttlabs/dont-use-host-network-namespace-f548aeeef575">dont-use-host-network-namespace</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;  Containerd是基于OCI规范实现的一款工业级标准的容器运行时。 Containerd在宿主机中管理容器生命周期，如容器镜像的传输和存储、容器的执行和管理、存储和网络等。 containerd-shim是用作容器运行的载体，实现容器生命周期管理， 其API以抽象命</summary>
      
    
    
    
    <category term="containerd" scheme="https://zoues.com/categories/containerd/"/>
    
    
    <category term="CloudNative" scheme="https://zoues.com/tags/CloudNative/"/>
    
    <category term="containerd" scheme="https://zoues.com/tags/containerd/"/>
    
    <category term="kubernetes" scheme="https://zoues.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents初识规范</title>
    <link href="https://zoues.com/posts/442a67fc/"/>
    <id>https://zoues.com/posts/442a67fc/</id>
    <published>2020-07-09T12:40:08.000Z</published>
    <updated>2024-01-21T02:28:02.690Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s1.ax1x.com/2020/05/16/Yc4JUK.jpg"></p><p>事件无处不在。然而，事件生产者倾向于以不同的方式来描述事件。</p><p>缺乏通用的描述事件的方式意味着开发人员必须不断地重新学习如何消费事件。这也限制了类库、工具和基础设施在跨环境时发送事件数据的潜力，如SDK、事件路由器或跟踪系统等。我们从事件数据中实现的可移植性和生产力总体上受到了阻碍。CloudEvents是一个用通用格式描述事件数据的规范，以提供跨服务、跨平台和跨系统的互操作性。CloudEvents得到了大量的行业关注，从主要的云提供商到流行的SaaS公司都有。CloudEvents由云原生计算基金会（CNCF）主办，于2018年5月15日获批为云原生沙盒级项目。</p><hr><h4 id="一、需求背景"><a href="#一、需求背景" class="headerlink" title="一、需求背景"></a>一、需求背景</h4><h5 id="历史背景"><a href="#历史背景" class="headerlink" title="历史背景"></a>历史背景</h5><p>CNCF无服务器工作组最初是由CNCF技术监督委员会设立的，目的是调查无服务器技术，并为CNCF在这一领域的一些相关活动提出一些可能的下一步建议。其中一项建议是调查创建一种通用的事件格式，以帮助云提供商之间的函数可移植性和事件流处理的互操作性。因此，CloudEvents 规范应运而生。虽然最初CloudEvents的工作是作为无服务器工作组的一部分完成的，但在规范达到v0.1的里程碑之后，TOC批准了CloudEvents工作，将其作为一个新的独立的CNCF沙盒项目。</p><h5 id="需求目标"><a href="#需求目标" class="headerlink" title="需求目标"></a>需求目标</h5><p>CloudEvents通常用于分布式系统中，允许服务在开发过程中松散耦合，独立部署，稍后可以连接起来创建新的应用。CloudEvents规范的目标是定义事件系统的互操作性，允许服务产生或消费事件，其中生产者和消费者可以独立开发和部署。生产者可以在消费者监听之前产生事件，而消费者可以对尚未产生的事件或事件类表达兴趣。请注意，这项工作所产生的规范侧重于事件格式的互操作性，以及事件在HTTP等各种协议上发送时如何呈现。该规范将不关注事件生产者或事件消费者的处理模型。</p><p>CloudEvents 的核心是定义了一组关于系统间传输事件的元数据（被称为属性），以及这些元数据应该如何出现在该消息中。这些元数据是将请求路由到适当的组件并促进该组件对事件进行适当处理所需的最低限度的信息集。因此，虽然这可能意味着事件本身的一些应用数据可能会和作为 CloudEvent 属性集的一部分重复，但这只是为了正确传递和处理消息的目的。不用于此目的的数据应放在事件（数据）本身中。此外，假定协议层向目标系统传递消息所需的元数据完全由协议处理，因此不包含在 CloudEvents 属性中。有关详细信息，请参阅 “非目标 “部分。在定义这些属性的同时，还将对如何以不同格式（如 JSON）和协议（如 HTTP、AMQP、Kafka）序列化事件进行规范。一些协议原生支持将多个事件批量化为一个API调用。为了帮助实现互操作性，是否需要批处理和如何实现批处理由协议决定。详情可在协议绑定或协议规范中找到。</p><p>CloudEvents 的批处理没有语义，也没有顺序。中间人可以添加或删除批处理，也可以将事件分配给不同的批次。</p><hr><h4 id="二、CloudEvents相关概念"><a href="#二、CloudEvents相关概念" class="headerlink" title="二、CloudEvents相关概念"></a>二、CloudEvents相关概念</h4><p>事件（Event）包含和发生（Occurrence）相关的上下文和数据。每一个发生（Occurrence）都由事件的数据唯一标识。</p><blockquote><p>事件代表事实，因此不包括目的地，而消息则传达意图，将数据从源头传送到特定的目的地。</p></blockquote><h5 id="Eventing"><a href="#Eventing" class="headerlink" title="Eventing"></a>Eventing</h5><p>在服务器端代码中，事件通常用于连接不同的系统，其中一个系统的状态变化会导致另一个系统的代码执行。例如，当源接收到外部信号（如 HTTP 或 RPC）或观察到一个变化的值（如 IoT 传感器或非活动期）时，可能会产生一个事件。</p><p>为了说明系统如何使用 CloudEvents，下面的简化图显示了来自源的事件如何触发一个动作。</p><p>源(Source)生成消息(Message)，其中事件(Event)被封装在协议中。事件到达目的地，触发一个由事件数据提供的动作(Action)。源是源类型的一个特定实例，它允许staging和测试实例。一个特定源类型的开放源软件可以由多个公司或供应商部署。</p><ul><li><p>事件可以通过各种行业标准协议（如HTTP、AMQP、MQTT、SMTP）、开源协议（如Kafka、NATS）或平台&#x2F;供应商特定的协议（AWS Kinesis、Azure Event Grid）来递送。</p></li><li><p>动作处理定义了由特定源的特定事件触发的行为或效果的事件。虽然不在本规范的范围内，但生成事件的目的通常是为了让其他系统能够轻松地对它们无法控制的源中的变化做出反应。源和动作通常是由不同的开发人员建立的。通常情况下，源是一个托管服务，而动作是无服务器函数（如AWS Lambda或Google Cloud Functions）中的自定义代码。</p></li></ul><h5 id="规范之外"><a href="#规范之外" class="headerlink" title="规范之外"></a>规范之外</h5><p>以下内容被认为超出了本规范的范围。</p><ul><li>函数的建立和调用过程</li><li>特定语言的运行时API</li><li>选择单一身份&#x2F;访问控制系统</li><li>包含协议级的路由信息</li><li>事件持久化过程</li></ul><p>CloudEvents 规范将不包括协议级的路由信息（例如，发送事件的目标 URL）。这是对CloudEvents概念的新手提出的一个常见建议。经过多次讨论后，工作组得出结论：规范中没有必要包含路由信息：任何协议（如 HTTP、MQTT、XMPP 或 Pub&#x2F;Sub 总线）都已经定义了路由的语义。例如，CloudEvents HTTP 绑定规定了头和请求正文内容。CloudEvents 不需要在规范中包含目标 URL 才能兼容 HTTP；HTTP 规范已经在 Request-Line 中包含了一个目标 URL。</p><p>路由信息不仅是多余的，而且会分散注意力。CloudEvents 应该增加互操作性，并将事件的生产者和消费者解耦。禁止事件格式中的路由信息，可以让CloudEvents重新传递给新的Action，或者通过包含多个通道的复杂中继器传递。例如，如果 Webhook 地址不可用，则原定用于 Webhook 的 CloudEvent 应可投递给死信队列。该死信队列应该能够将事件送入原始事件发出者从未想过的新的Action。</p><p>在系统内和跨系统产生和消费的CloudEvents会触发行为，从而产生价值。因此，归档和&#x2F;或重放事件对于调试或复制来说是非常有价值的。然而，持久化事件会删除传输过程中可用的上下文信息，如生产者的身份和权利、保真验证机制或保密保护。此外，持久化会增加复杂性和挑战，以满足用户的需求。例如，重复使用私钥进行加密或签名，会增加攻击者可用的信息，从而降低安全性。预计可能会定义出有助于满足持久性要求的属性，但预计这些属性将随着行业最佳实践和进步而不断发展。</p><hr><h4 id="三、架构"><a href="#三、架构" class="headerlink" title="三、架构"></a>三、架构</h4><p>CloudEvents 规范集定义了四种不同类型的协议元素，它们构成了一个分层架构模型。</p><ol><li><p>基本规范 定义了由属性（键值对）和相关规则组成的抽象信息模型，这些属性和相关规则构成了CloudEvents。</p></li><li><p>扩展 添加了特定的、可能重叠的扩展属性和相关规则集，例如，支持不同的跟踪标准。</p></li><li><p>事件格式编码（如 JSON）定义了基本规范的信息模型和所选扩展的编码方式，以将其映射到应用协议的头和有效载荷元素。</p></li><li><p>协议绑定，例如 HTTP，定义了 CloudEvent 如何与应用协议的传输帧绑定，在 HTTP 的下是绑定 HTTP 消息。协议绑定并不约束传输帧的使用方式，这意味<br>着HTTP绑定可以与任何HTTP方法以及请求和响应消息一起使用。</p></li></ol><p>如果需要确保更广泛的互操作性，CloudEvents 规范集为使用特定应用协议的事件传递提供了特定的约束。HTTP Webhook 规范并不是 CloudEvents 所特有的，它可以用于将任何类型的单向事件和通知发布到符合的 HTTP 端点。然而，由于其他地方缺乏这样的规范，因此CloudEvents有必要定义它。</p><p><em><strong>协议错误处理</strong></em></p><p>大多数情况下，CloudEvents 规范并没有规定与创建或处理 CloudEvents 相关的处理模型。因此，如果在处理 CloudEvents 过程中出现错误，鼓励遇到错误的软件使用常规的协议级错误报告来报告错误。</p><p><em><strong>属性的版本化</strong></em></p><p>对于某些 CloudEvents 属性，其值所引用的实体或数据模型可能会随着时间的推移而变化。例如，dataschema 可能会引用模式文档的一个特定版本。通常情况下，这些属性值将通过在其值中包含某些特定于版本的字符串作为其值的一部分来区分每个变体。例如，可能会使用版本号（v1、v2）或日期（2018-01-01-01）。CloudEvents 规范并没有规定要使用任何特定的模式，甚至根本不要求使用版本字符串。此决定权在每个事件制生产者手中。但是，当包含特定版本字符串时，应注意其值的变化，因为事件的消费者可能会依赖现有的值，因此变化可能会被解释为 “破坏性变化”。应该在生产者和消费者之间建立某种形式的沟通，以确保事件消费者知道可能使用的值。一般来说，所有 CloudEvents 属性也是如此。</p><h5 id="CloudEvent属性"><a href="#CloudEvent属性" class="headerlink" title="CloudEvent属性"></a>CloudEvent属性</h5><p>本节提供了与CloudEvent的一些属性相关的其他背景和设计要点。</p><p><em><strong>id</strong></em></p><p>id 属性是指在与一个事件源相关的所有事件中都是唯一的值（每个事件源都是由其 CloudEvents 的 source 属性值唯一标识的）。虽然所使用的确切值由生产者定义，但可以保证来自单一事件源的 CloudEvents 接收者不会有两个事件共享相同的 id 值。唯一的例外情况是，如果支持事件的某些重播，在这种情况下，可以使用 id 来检测。由于一个事件的发生可能会产生一个以上的事件，所以在所有这些事件都来自同一个事件源的情况下，每个 CloudEvent 构造的事件都有一个唯一的 id。以创建 DB 条目为例，这一次发生可能会产生一个创建类型为 create 的 CloudEvent 和一个写类型为 write 的 CloudEvent。这些CloudEvents中的每一个都有一个唯一的id。如果希望这两个 CloudEvents 之间有一定的相关性，以表明它们都与同一事件相关，那么 CloudEvent 中的一些附加数据将用于此目的。在这方面，虽然事件生成者选择的确切值可能是一些随机字符串，或在其他语境中具有某种语义意义的字符串，但对于本CloudEvent属性的目的来说，这些意义并不相关，因此，将id用于唯一性检查之外的其他目的不在本规范的范围内，也不建议使用。</p><h5 id="CloudEvent-属性扩展"><a href="#CloudEvent-属性扩展" class="headerlink" title="CloudEvent 属性扩展"></a>CloudEvent 属性扩展</h5><p>为了实现既定目标，规范作者将试图限制他们在 CloudEvents 中定义的元数据属性的数量。为此，本项目所定义的属性将分为三类。</p><ul><li>required (必须的)</li><li>optional (可选的)</li><li>extensions (可扩展）</li></ul><p>正如类别名称所暗示的那样，”必需 “属性将是该组认为在所有用例中对所有事件至关重要的属性，而 “可选 “属性将在大多数情况下使用。这两种情况下的属性都将在规范本身中定义。</p><p>当小组确定一个属性不够通用，不能归入这两类，但仍然可以从定义良好的互操作性中受益，那么它们将被归入 “扩展 “类别，并被归入文档化的扩展。该规范定义了这些扩展属性在 CloudEvent 中的出现方式。</p><p>在确定提议的属性属于哪个类别时，甚至在确定是否将其包含在其中时，小组会使用用例和用户故事来解释其理由和需求。CloudEvent 规范的扩展属性是指需要包含的额外元数据，以帮助确保 CloudEvent 的正确路由和处理。与事件本身相关且在传输或处理 CloudEvent 中不需要的其他目的的附加元数据，应放在事件（数据）本身的适当扩展点中。扩展属性应保持最小化，以确保 CloudEvent 能够正确地序列化和传输。例如，事件制作者应考虑向 CloudEvent 添加扩展时可能会遇到的技术限制。例如，HTTP二进制模式使用HTTP头来传输元数据；大多数HTTP服务器会拒绝HTTP header数据过多的请求，限制低至8kb。因此，应该尽量减少扩展属性的总大小和数量。如果一个扩展变得流行，那么规范作者可能会考虑将其作为核心属性移到规范中。这意味着在正式加入规范之前，扩展机制&#x2F;进程可以作为一种方式来审核新属性，然后再正式加入到规范中。</p><p><em><strong>JSON扩展</strong></em></p><p>正如在CloudEvents规范的JSON事件格式中的Attributes部分提到的那样，CloudEvent扩展属性被序列化为规范定义的属性的兄弟姐妹–也就是说，在JSON对象的顶层。该规范的作者花了很长时间考虑了所有选项，并决定这是最好的选择。以下是其中的一些道理。由于规范遵循 semver（语义化版本），这意味着新的属性可以被未来版本的核心规范所定义，而不需要重大的版本号改变–只要这些属性是可选的。在这种情况下，考虑一下现有的消费者会如何处理一个新的（未知）顶层属性。虽然它可以自由地忽略它，因为它是可选的，但在大多数情况下，相信这些属性仍然希望暴露在接收这些事件的应用程序中。这将允许这些应用程序支持这些属性，即使基础设施不支持这些属性。这意味着，未知的顶层属性（不管是谁定义的–不管是未来版本的规范还是事件生产者）很可能不会被忽略。因此，虽然其他一些规范定义了一个特定的属性来放置扩展属性（例如顶层扩展属性），但作者决定，在一个传入的事件中，为未知的属性设置两个不同的位置，可能会导致互操作性问题，也会给开发者带来混乱。</p><p>通常情况下，在规范正式采用之前，扩展通常是用来测试规范的新的潜在属性。如果有一个扩展类型的属性，在这个新属性中，这个新属性被序列化了，那么，如果这个属性曾经被核心规范采用，那么它将从扩展属性中晋升（从序列化的角度来看）为顶层属性。如果我们假设这个新属性将是可选的，那么随着它被核心规范采用，它将只是一个小的版本增量，所有现有的消费者仍然应该继续工作。然而，消费者将不知道这个属性将出现在哪里–在扩展属性中或作为顶层属性。这意味着他们可能需要在这两个地方都要找。如果这个属性同时出现在两个地方，但价值不同怎么办？生产者是否需要将其放在两个地方，因为他们可能会有新老消费者？虽然可能有可能定义明确的规则来解决每一个可能出现的问题，但作者决定最好是一开始就简单地避免所有问题，在序列化中只为未知的、甚至是新的属性提供一个位置。此外，还有人指出，现在的HTTP规范也遵循了类似的模式，不再建议在HTTP扩展头中用X-作为前缀。</p><h5 id="创建CloudEvents"><a href="#创建CloudEvents" class="headerlink" title="创建CloudEvents"></a>创建CloudEvents</h5><p>CloudEvents 规范特意避免过强的规定如何创建 CloudEvents。例如，它不假定原始事件源是为该事件的发生构造相关的 CloudEvents 的同一个实体。这样就可以有多种实现选择。但是，对于规范的实现者来说，了解规范作者的期望值是很有用的，因为这可能有助于确保互操作性和一致性。</p><p>如上所述，生成初始事件的实体是否是创建相应的 CloudEvent 的实体是一个实现选择。然而，当构造&#x2F;填充 CloudEvents 属性的实体代表事件源行事时，这些属性的值是为了描述事件或事件源，而不是计算 CloudEvent 属性值的实体。换句话说，当事件源和 CloudEvents 生产者之间的分工对事件消费者没有实质性的意义时，规范定义的属性通常不会包含任何值来表示这种责任的分工。</p><p>这并不是说 CloudEvents 生产者不能为 CloudEvents 添加一些额外的属性，但这些属性不属于规范中互操作性定义的属性范围。这就类似于 HTTP 代理通常会尽量减少对传入消息中定义好的 HTTP 标头的更改，但它可能会添加一些包含代理特定元数据的附加标头。还值得注意的是，原始事件源和 CloudEvents 生产者之间的这种分离可以是小的或大的。这意味着，即使CloudEvents 生产者不属于原始事件源的生态系统的一部分，但如果它是代表事件源行事，并且它在事件流中的存在对事件消费者来说没有意义，那么上述指导仍然适用。当一个实体同时充当CloudEvents的接收方和发送方，以转发或转换入站事件为目的时，出站CloudEvent与入站CloudEvent的匹配程度将根据该实体的处理语义而有所不同。如果它作为代理，只是将 CloudEvents 转发到另一个事件消费者，那么出站 CloudEvent 通常与入站 CloudEvent 在规范定义的属性方面看起来与入站 CloudEvent 完全相同。但是，如果这个实体正在对CloudEvent进行某种类型的语义处理，通常会导致数据属性的值发生变化，那么它可能需要被视为一个与原始事件源不同的 “事件源”。因此，预计与事件生产者相关的CloudEvents属性（如源和id）将从传入的CloudEvent中更改。</p><hr><h4 id="四、协议与编码"><a href="#四、协议与编码" class="headerlink" title="四、协议与编码"></a>四、协议与编码</h4><p>正如规范中所表达的那样，CloudEvents工作的明确目标是 “以通用的方式描述事件数据”，并 “定义事件系统的互操作性，使服务能够产生或消费事件，生产者和消费者可以独立开发和部署”。</p><p>这种互操作性的基础是开放的数据格式和开放的协议，CloudEvents旨在提供这种开放的数据格式，并将其数据格式投射到常用的协议和常用的编码上。尽管每个软件或服务产品和项目显然可以选择自己喜欢的通信形式，但毫无疑问，对这种产品或项目私有的专有协议并不能促进事件生产者和消费者之间的广泛互操作性的目标。特别是在消息传递和事件处理领域，过去十年来，业界在开发一个强大的、广泛支持的协议基础上取得了重大进展，比如HTTP 1.1和HTTP&#x2F;2以及WebSockets或事件网络上的WebSockets或事件，或者是面向连接的消息传递和遥测传输的MQTT和AMQP。一些被广泛使用的协议已经成为事实上的标准，有些协议是由三家或更多公司组成的顶级联盟组成的强大的生态系统中产生的，有些则是由一家公司发布的强大的项目生态系统中产生的，无论在哪种情况下，都是与前面提到的标准栈的演进同步进行的。</p><p>CloudEvents不应成为一种载体，甚至不应成为暗中认可或推广项目或产品专有协议的工具，因为这将会对 CloudEvents 的最初目标产生反作用。要使协议或编码符合 CloudEvents 核心事件格式或协议绑定的资格，它必须属于以下任一类别。</p><ul><li>该协议具有作为标准的正式地位，具有广泛认可的多厂商协议标准化机构（如 W3C、IETF、OASIS、ISO）的标准地位</li><li>该协议在其生态系统类别中具有 “非事实标准 “的地位，这意味着它被广泛使用，以至于被认为是特定应用的标准。实际上，我们希望看到至少有一家厂商中立的<br>开源组织（如Apache、Eclipse、CNCF、.NET基金会）旗下至少有一个开源实现，并且至少有十几家独立的厂商在其产品&#x2F;服务中使用该协议。</li></ul><p>除了正式地位之外，协议或编码是否符合核心 CloudEvents 事件格式或协议绑定的关键标准是，该组是否同意该规范将为与协议或编码产生的产品或项目无关的任何一方带来持续的实际利益。这方面的一个基本要求是，协议或编码的定义方式必须允许独立于产品或项目的代码之外的替代实现。</p><hr><h4 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h4><p>本节介绍了一些解释CloudEvents价值的用例。</p><ul><li>跨服务和平台的事件规范化</li></ul><p>主要的事件发布商（如AWS、微软、谷歌等）都在各自的平台上以不同的格式发布事件。甚至有少数情况下，同一提供商上的服务以不同的格式发布事件（如AWS）。这就迫使事件消费者不得不实施自定义逻辑，以实现跨平台、偶尔跨服务在单一平台上读取或合并事件数据。CloudEvents 可以为处理跨平台和跨服务的事件的消费者提供单一体验。</p><ul><li>促进跨服务和平台的集成</li></ul><p>事件数据跨环境传输的情况越来越普遍。然而，如果没有一种通用的描述事件的方式，事件的跨环境传输就会受到阻碍。没有单一的方法来确定事件的来源和可能的去向。这就阻碍了促进事件成功交付的工具化，也阻碍了消费者知道如何处理事件数据。CloudEvents 提供了有用的元数据，中间件和消费者可以依赖这些元数据来促进事件的路由、记录、传递和接收。</p><ul><li>提高FaaS的可移植性</li></ul><p>FaaS（也称无服务器计算）是IT领域发展最快的趋势之一，它主要是由事件驱动的。然而，FaaS的一个主要问题是供应商的锁定问题。这种锁定部分是由各供应商之间的函数API和签名的差异造成的，但这种锁定也是由函数内部接收事件数据的格式差异造成的。CloudEvents 对事件数据的通用描述方式提高了FaaS的可移植性。</p><ul><li>改进事件驱动&#x2F;无服务器架构的开发和测试工作</li></ul><p>由于缺乏通用的事件格式，使得事件驱动和无服务器架构的开发和测试变得复杂化。没有简单的方法可以准确地模拟事件用于开发和测试，并帮助在开发环境中模拟事件驱动的工作流程。CloudEvents可以使开发人员有更好的工具来构建、测试和处理事件驱动和无服务器架构的端到端生命周期。</p><ul><li>事件数据演变</li></ul><p>大多数平台和服务对其事件的数据模型进行了不同的版本（如果他们根本不这么做的话）。这为发布和消费事件的数据模型创造了不一致的体验，因为这些数据模型在不断发展。CloudEvents 可以提供一种通用的方式来版本化和演进事件数据。这将帮助事件发布者根据最佳实践安全地对其数据模型进行版本化，这将帮助事件消费者在事件数据演进过程中安全地使用事件数据。</p><ul><li>规范化Webhooks</li></ul><p>Webhooks是一种没有使用通用格式的事件发布方式。Webhooks 的消费者没有一致的方式来开发、测试、识别、验证和整体处理通过 Webhooks 传递的事件数据。CloudEvents 可以为 webhook 发布和消费提供一致性。</p><ul><li>政策执行</li></ul><p>处于安全和策略的考虑，系统之间的事件的传送可能需要过滤、转换或阻止。例如，为了防止事件的进入或流出，如事件数据包含敏感信息或希望禁止发送方和接收方之间的信息流。</p><p>一个通用的事件格式将使人们更容易推理正在流转的数据，并允许对数据进行更好的反省。</p><ul><li>事件追踪</li></ul><p>从源发送的事件可能会导致从各种中间件设备（如事件代理和网关）发送的附加事件序列。CloudEvents 包含事件中的元数据，可将这些事件作为事件序列的一部分进行关联，以进行事件追踪和故障排除。</p><ul><li>IoT &#x2F; 物联网</li></ul><p>物联网设备会发送和接收与其函数相关的事件。例如，一个连接的恒温器将发送关于当前温度的遥测数据，并可以接收改变温度的事件。这些设备通常有一个受限制的操作环境（CPU、内存），需要一个定义良好的事件消息格式。在很多情况下，这些消息是二进制编码的，而不是文本的。无论是直接来自设备还是通过网关转换，CloudEvents 都可以更好地描述消息的来源和消息中包含的数据格式。</p><ul><li>事件的关联性</li></ul><p>一个无服务器的应用程序&#x2F;工作流可以与来自不同事件源&#x2F;生产者的多个事件相关联。例如，一个防盗侦测应用&#x2F;工作流可能同时涉及一个运动事件和一个门窗打开事件。一个无服务器平台可以接收到许多不同类型事件的实例，例如，它可以接收来自不同房屋的运动事件和门窗打开事件。无服务器平台需要将一种类型的事件实例与其他类型的事件实例正确关联，并将接收到的事件实例映射到正确的应用&#x2F;工作流实例。CloudEvents 将为任何事件消费者（如无服务器平台）提供一种标准的方法，以便在事件数据中找到事件关联信息&#x2F;标记，并将接收到的事件实例映射到正确的应用&#x2F;工作流实例。</p><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s1.ax1x.com/2020/05/16/Yc4JUK.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;事件无处不在。然而，事件生产者倾向于以不同的方式来描述事件。&lt;/p&gt;
&lt;p&gt;缺乏通用的描述事件的方式意味着开发人员必须不断地重新学习如何消费事件。这也限</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents知多少</title>
    <link href="https://zoues.com/posts/78a79c49/"/>
    <id>https://zoues.com/posts/78a79c49/</id>
    <published>2020-06-30T13:40:08.000Z</published>
    <updated>2024-01-21T02:28:54.172Z</updated>
    
    <content type="html"><![CDATA[<p>CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents最初由CNCF Severless 工作组提出。</p><hr><h4 id="一、需求背景"><a href="#一、需求背景" class="headerlink" title="一、需求背景"></a>一、需求背景</h4><p>事件无处不在，然而事件发布者对事件的描述却往往不尽相同。</p><ul><li>一致性：缺乏通用的事件描述方式，意味着开发人员必须为每个事件源编写新的事件处理逻辑。</li><li>无障碍环境：没有通用的事件格式意味着没有通用的库、工具和基础设施来跨环境投递事件数据。CloudEvents提供了Go、JavaScript、Java、C#、Ruby和<br>Python的SDK，可用于构建事件路由器、跟踪系统和其他工具。</li><li>可移植性：整体上阻碍了我们从事件数据中实现的可移植性和生产力。</li></ul><h5 id="何为CloudEvents"><a href="#何为CloudEvents" class="headerlink" title="何为CloudEvents"></a>何为CloudEvents</h5><p>CloudEvents 是一个以通用方式描述事件数据的规范。CloudEvents旨在大幅简化跨服务、跨平台的事件声明和投递。</p><p>CloudEvents是一项新的工作，目前仍在积极开发中。然而，它的工作小组已经收到了令人惊讶的行业兴趣，从主要的云提供商到流行的SaaS公司都有。该规范现在由云原生计算基金会（Cloud Native Computing Foundation&#x2F;CNCF）负责。</p><p>CloudEvents是通过CNCF的Serverless工作组组织的。</p><hr><h4 id="二、CloudEvents-1-0"><a href="#二、CloudEvents-1-0" class="headerlink" title="二、CloudEvents 1.0"></a>二、CloudEvents 1.0</h4><h5 id="历史发展"><a href="#历史发展" class="headerlink" title="历史发展"></a>历史发展</h5><p>CNCF Severless 工作组最初是由 CNCF 技术监督委员会创立的，旨在调查 Serverless 技术和指导 CNCF 在本领域下一步可能展开的相关工作的建议。其中一项建议是创建一个通用的 Event Format，以在不同云供应商提供的Function 之间实现可移植性和事件流处理的互操作性。CloudEvents 规范因此被创建出来。</p><h5 id="版本确立"><a href="#版本确立" class="headerlink" title="版本确立"></a>版本确立</h5><p>尽管 CloudEvents 的工作最初是作为 Serverless 工作组的一部分开展的，当规范到达 v0.1 里程碑之后，TOC 批准了 CloudEvents 成为一个独立的 CNCF 沙盒项目。2019年10月24日，CloudEvents项目取得了两项重大成果。第一，CNCF的技术监督委员会批准该项目成为 “孵化器 “项目（从而使其从CNCF的 “沙盒”毕业）。第二，CloudEvents规范发布了1.0版本!这是该规范的第一个主要版本，代表了整个serverless社区中一个真正伟大的团队两年来的努力工作。我们已经有几乎所有主要的云提供商参与其中，还有一些 “终端用户 “公司以及许多个人参与者，他们都在努力工作以制作出一个规范，希望在这一里程碑式的发展过程中，能够继续得到更多的采用。除了核心的CloudEvents规范外，还有Primer和协议及格式规范，所有这些都可以在GitHub repo中找到。此外，还有六种不同的SDK-Go、JavaScript、Java、C#、Ruby和Python，帮助生产和消费CloudEvents。CNCF Serverless工作组将决定下一步的工作重点（例如，额外的CloudEvents相关活动，或者解决社区正在经历的其他互操作性痛点）。</p><h5 id="集成现状"><a href="#集成现状" class="headerlink" title="集成现状"></a>集成现状</h5><p><img src="https://s1.ax1x.com/2020/06/04/tB4PzD.md.png"></p><hr><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">cloudevent</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents最初由CNCF Severless 工作组提出。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;一、需求背景&quot;&gt;&lt;a href=&quot;#一、</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents核心规范之三</title>
    <link href="https://zoues.com/posts/34952747/"/>
    <id>https://zoues.com/posts/34952747/</id>
    <published>2020-06-17T13:40:08.000Z</published>
    <updated>2024-01-21T02:28:28.382Z</updated>
    
    <content type="html"><![CDATA[<p>CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents　最初由　CNCF<br>Severless 工作组提出。本文档的目的是描述针对CloudEvents的新软件开发工具包（SDK）的最低要求。这些SDK的设计和实施是为了增强和加快CloudEvents<br>的集成。作为社区工作的一部分，CloudEvents团队承诺支持和维护以下SDK。</p><hr><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>本文档旨在为 SDK 作者提供指导和要求。本文档旨在与 CloudEvents 规范保持同步更新。当前提供以下语言的SDK:</p><ul><li>CSharp</li><li>Go SDK</li><li>Java SDK</li><li>JavaScript SDK</li><li>Python SDK</li><li>Ruby SDK</li></ul><h3 id="技术需求"><a href="#技术需求" class="headerlink" title="技术需求"></a>技术需求</h3><p>每个SDK必须满足这些要求。</p><ul><li>支持CloudEvents 的里程碑版本和正在进行的开发版本。<ul><li>将Canonical Event编码为特定于传输的编码消息。</li><li>将特定于传输的编码消息解码为Canonical事件。</li></ul></li><li>熟练使用编程语言。<ul><li>使用当前的语言版本。</li></ul></li><li>支持结构化和二进制编码的HTTP传输渲染。</li></ul><h3 id="对象模型结构准则"><a href="#对象模型结构准则" class="headerlink" title="对象模型结构准则"></a>对象模型结构准则</h3><p>每个SDK将提供一个通用的CloudEvents类&#x2F;对象&#x2F;结构，该类&#x2F;对象&#x2F;结构表示事件的典型形式。</p><p>该 SDK 应使用户能够绕过 CloudEvents Event 对象的特定传输编码和解码。对象的一般流程应该是：</p><p>Event (-&gt; Message) -&gt; Transport</p><p>和</p><p>Transport (-&gt; Message) -&gt; Event</p><p>不需要SDK来实现传输的包装器，重点应该是允许编程模型与高层次的Event对象一起工作，并提供工具将Event转化成可以与所选的实现传输一起使用的东西。</p><p>在高层次上，SDK需要能够帮助完成以下任务。</p><ul><li>组合事件。</li><li>编码事件，给定传输和编码（如果适当的话，将其编码为传输消息）。</li><li>解码特定于传输的消息、请求或响应（如果适当的话，到一个传输消息）为事件。</li></ul><p><em><strong>组合事件</strong></em></p><p>提供一种方便的方法，既可以组成单一消息，也可以组成许多消息。实现者将需要一种方法来快速建立事件数据并将其转换为CloudEvents编码的事件。在实践中，事</p><p>件的组成往往有两个方面。</p><ol><li>事件创建</li></ol><p>“我有一个格式不是CloudEvent的数据，我想让它成为CloudEvent。”</p><ol start="2"><li>事件变化</li></ol><p>“我有一个CloudEvents格式化的事件，我需要将它变成不同的事件。” “我有一个CloudEvents格式化的事件，我需要修改事件。”</p><p>对于SDK语言来说，事件的创建是非常习以为常的。</p><p>事件变化往往用访问器模式来解决，比如getters和setter。但是可以利用直接的 key 访问，也可以利用命名的 key 访问器函数。</p><p>无论是哪种情况，都必须有一个方法根据参数设置来验证生成的Event对象，最重要的是CloudEvents规范版本。</p><p><em><strong>对事件进行编码&#x2F;解码</strong></em></p><p>每个SDK都支持对事件进行编码和解码。结构化编码是最容易支持的，因为它只是json，但二进制编码对于每个传输方式来说是相当定制的。</p><p><em><strong>数据</strong></em></p><p>从事件中访问数据有一些考虑，事件可以被编码成base64形式，作为结构化数据，或者像json这样的线上格式。一个SDK必须提供一种方法来将这些格式的数据解压成<br>原生格式。</p><p><em><strong>扩展</strong></em></p><p>支持CloudEventss的扩展又是成语，但镜像数据访问的方法似乎是可行的。</p><p><em><strong>验证</strong></em></p><p>验证必须在单个事件上进行。验证必须考虑到规格版本，以及每个版本的规格所提出的所有要求。</p><hr><h2 id="二、Golang示例"><a href="#二、Golang示例" class="headerlink" title="二、Golang示例"></a>二、Golang示例</h2><h3 id="处理依赖"><a href="#处理依赖" class="headerlink" title="处理依赖"></a>处理依赖</h3><p><em><strong>获取依赖</strong></em></p><p><code>go get github.com/cloudevents/sdk-go/v2@v2.0.0</code></p><p><em><strong>依赖引用</strong></em></p><p><code>import cloudevents &quot;github.com/cloudevents/sdk-go/v2&quot;</code></p><h3 id="发送事件"><a href="#发送事件" class="headerlink" title="发送事件"></a>发送事件</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line">cloudevents <span class="string">&quot;github.com/cloudevents/sdk-go/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// The default client is HTTP.</span></span><br><span class="line">c, err := cloudevents.NewDefaultClient()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to create client, %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an Event.</span></span><br><span class="line">event :=  cloudevents.NewEvent()</span><br><span class="line">event.SetSource(<span class="string">&quot;example/uri&quot;</span>)</span><br><span class="line">event.SetType(<span class="string">&quot;example.type&quot;</span>)</span><br><span class="line">event.SetData(cloudevents.ApplicationJSON, <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>&#123;<span class="string">&quot;hello&quot;</span>: <span class="string">&quot;world&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set a target.</span></span><br><span class="line">ctx := cloudevents.ContextWithTarget(context.Background(), <span class="string">&quot;http://localhost:8080/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Send that Event.</span></span><br><span class="line"><span class="keyword">if</span> result := c.Send(ctx, event); !cloudevents.IsACK(result) &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to send, %v&quot;</span>, result)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="接受事件"><a href="#接受事件" class="headerlink" title="接受事件"></a>接受事件</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line">cloudevents <span class="string">&quot;github.com/cloudevents/sdk-go/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receive</span><span class="params">(event cloudevents.Event)</span></span> &#123;</span><br><span class="line"><span class="comment">// do something with event.</span></span><br><span class="line">    fmt.Printf(<span class="string">&quot;%s&quot;</span>, event)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// The default client is HTTP.</span></span><br><span class="line">c, err := cloudevents.NewDefaultClient()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to create client, %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">log.Fatal(c.StartReceiver(context.Background(), receive));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p><em><strong>序列化为JSON</strong></em></p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">event := cloudevents.NewEvent()</span><br><span class="line">event.SetSource(&quot;example/uri&quot;)</span><br><span class="line">event.SetType(&quot;example.type&quot;)</span><br><span class="line">event.SetData(cloudevents.ApplicationJSON, map[string]string&#123;&quot;hello&quot;: &quot;world&quot;&#125;)</span><br><span class="line"></span><br><span class="line">bytes, err := json.Marshal(event)</span><br></pre></td></tr></table></figure><p><em><strong>反序列化</strong></em></p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">event :=  cloudevents.NewEvent()</span><br><span class="line"></span><br><span class="line">err := json.Marshal(bytes, &amp;event)</span><br></pre></td></tr></table></figure><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li><li><a href="https://cloudevents.github.io/sdk-go/">go sdk</a></li><li><a href="https://github.com/cloudevents/sdk-go">sdk-go</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents　最初由　CNCF&lt;br&gt;Severless 工作组提出。本文档的目的是描述针对CloudEvents的新软件开发工具包（S</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>CloudEvents核心规范之二</title>
    <link href="https://zoues.com/posts/76c9b14a/"/>
    <id>https://zoues.com/posts/76c9b14a/</id>
    <published>2020-06-16T13:40:08.000Z</published>
    <updated>2024-01-21T02:28:39.994Z</updated>
    
    <content type="html"><![CDATA[<p>CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents　最初由　CNCF<br>Severless 工作组提出。CloudEvents 的 HTTP 协议绑定定义了如何将事件映射到 HTTP 1.1 请求和响应消息。</p><hr><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>CloudEvents是事件的结构和元数据描述的标准化且与协议无关的定义。该规范定义了如何在HTTP 1.1请求和响应消息中使用CloudEvents规范中定义的元素。</p><h3 id="与HTTP的关系"><a href="#与HTTP的关系" class="headerlink" title="与HTTP的关系"></a>与HTTP的关系</h3><p>本规范没有规定约束特定HTTP方法的使用或处理规则，也没有约束用于传输或请求事件的HTTP目标资源。</p><p>事件可以通过所有支持有效载荷体传输的标准或应用程序定义的HTTP请求方法来传输。事件也可以在HTTP响应中以及与允许有效载荷体传输的所有HTTP状态码一起传输。</p><p>这里所有显示HTTP方法、HTTP目标URI和HTTP状态码的例子都是非规范性的说明。</p><p>本规范也同样适用于与 HTTP 1.1语义兼容的 HTTP&#x2F;2（RFC7540）。</p><blockquote><p>也适用于HTTP&#x2F;2</p></blockquote><h3 id="内容模式"><a href="#内容模式" class="headerlink" title="内容模式"></a>内容模式</h3><p>本规范定义了传输事件的三种内容模式：二进制（binary）、结构化（structured）和批量（batched）。每个符合规范的实现都应该支持二进制（binary）和结</p><p>构化（structured）模式。</p><ul><li>在二进制内容模式下，事件 data 的值被放置到HTTP请求或响应的主体（body）中，并在HTTP Content-Type header中以 datacontenttype属性的值声明其</li></ul><p>媒体类型；所有其他事件属性都被映射到HTTP头。</p><ul><li><p>在结构化内容模式下，事件元数据属性和事件数据被放置到HTTP请求或响应body中，使用事件格式。</p></li><li><p>在批量内容模式中，多个事件使用支持批量的事件格式，分批放入单个HTTP请求或响应body中。</p></li></ul><h3 id="事件格式"><a href="#事件格式" class="headerlink" title="事件格式"></a>事件格式</h3><p>与结构化内容模式一起使用的事件格式，定义了事件如何以特定的数据格式表达。本规范的所有实现必须支持非批处理的JSON事件格式，但也可以支持任何其他格式，包括专有格式。</p><p>事件格式可以额外定义事件批处理的表达方式。这些格式可以与批处理内容模式一起使用。</p><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>本规范没有为HTTP引入任何新的安全特性，也没有规定要使用特定的现有特性。本规范同样适用于TLS上的HTTP。</p><hr><h2 id="二、CloudEvents-属性的使用"><a href="#二、CloudEvents-属性的使用" class="headerlink" title="二、CloudEvents 属性的使用"></a>二、CloudEvents 属性的使用</h2><p>本规范没有进一步定义任何核心 CloudEvents 事件属性。</p><p>此映射是为了防止变化（包括事件属性的添加和删除），并适应供应商对事件元数据的扩展。</p><h3 id="datacontententtype-属性"><a href="#datacontententtype-属性" class="headerlink" title="datacontententtype 属性"></a>datacontententtype 属性</h3><p>datacontententtype属性被认为包含一个符合RFC2046的媒体类型表达式。</p><h3 id="data"><a href="#data" class="headerlink" title="data"></a>data</h3><p>data 被假定为包含由 datacontenttype 属性声明的不透明的应用数据。</p><p>应用程序可以自由地以其选择的任何内存中的表示方式来保存信息，但是由于该值是按照本规范中的定义被转接到HTTP中的，因此假设 data 的值是以字节序列的形式</p><p>提供的。</p><p>例如，如果声明的 datacontenttype 为 application&#x2F;json;charset&#x3D;utf-8，则期望 data 值以 UTF-8 编码的JSON文本形式提供给HTTP。</p><hr><h2 id="三、HTTP消息映射"><a href="#三、HTTP消息映射" class="headerlink" title="三、HTTP消息映射"></a>三、HTTP消息映射</h2><p>HTTP请求和响应消息的事件绑定是相同的。</p><p>内容模式是由事件的发送方选择的，发送方可以是请求方或响应方。可能允许使用特定模式请求事件的手势可能是由应用程序定义的，但这里没有定义。除非被邀约，</p><p>否则不能使用批量模式，而且手势应该允许接收方选择最大的批处理量。</p><p>事件的接收方可以通过检查 Content-Type header 的值来区分这三种模式。如果该值前缀为 CloudEvents 媒体类型 application&#x2F;cloudevents，表示使</p><p>用已知的事件格式，则接收方使用结构化模式。如果该值前缀为 application&#x2F;cloudevents-batch，则接收器使用批处理模式。否则，则默认为二进制模式。</p><blockquote><p>默认是使用二进制模式</p></blockquote><p>如果接收器检测到 CloudEvents 媒体类型，但它无法处理的事件格式（例如 application&#x2F;cloudevents+avro），它仍然可以将事件作为二进制模式处理，并</p><p>将其转发到另一方。</p><h3 id="二进制内容模式"><a href="#二进制内容模式" class="headerlink" title="二进制内容模式"></a>二进制内容模式</h3><p>二进制的内容模式可以容纳任何形状的事件数据，并允许高效传输，无需转码。</p><p><em><strong>HTTP Content Type</strong></em></p><p>对于二进制模式，HTTP Content-Type header值对应于（必须从 CloudEvents datacontenttype 属性中填充或写入）CloudEvents datacontenttype </p><p>属性。请注意 ce-datacontenttype HTTP 标头不能也存在于消息中。</p><p><em><strong>事件数据编码</strong></em></p><p>data 字节序列作为HTTP报文Body。</p><p><em><strong>Metadata headers</strong></em></p><p>所有其他 CloudEvents 属性（包括扩展）必须单独映射到不同的 HTTP 消息头，并从不同的 HTTP 消息头中映射。</p><p>定义了自己属性的 CloudEvents 扩展可以为这些属性定义二级映射到 HTTP 头，特别是当特定属性需要与 HTTP 特性或其他有明确 HTTP 头绑定的规范保持一致</p><p>时。请注意，这些属性还必须作为带有 ce 前缀的 HTTP 标头出现在 HTTP 报文中，如 HTTP 标头名称中所述。</p><p><em><strong>HTTP Header Names</strong></em></p><p>除注明的情况外，所有 CloudEvents 上下文属性（包括扩展）都必须映射到与属性名称相同但前缀为 ce 的 HTTP header中。</p><p>示例:</p><ul><li><code>time</code> maps to <code>ce-time</code></li><li><code>id</code> maps to <code>ce-id</code></li><li><code>specversion</code> maps to <code>ce-specversion</code></li></ul><blockquote><p>根据HTTP规范，header name是不区分大小写的</p></blockquote><p><em><strong>HTTP header值</strong></em></p><p>每个 HTTP header的值由相应属性类型的标准字符串表示法构建。</p><p>某些 CloudEvents 元数据属性可包含任意 UTF-8 字符串内容，HTTP 标头必须仅使用 US-ASCII 字符集中的可打印字符，并由 CRLF 序列终止，标头值周围</p><p>有可选的空白。中描述的 header 编码规则之前，必须按照RFC3986，第2.4节中描述的百分比编码，对字符串值进行百分比编码。</p><p>将 HTTP 报文解码为 CloudEvent 时，必须反向应用这些规则 – RFC7230 第 3.2.6 节对 ASCII 字符串进行解码，然后按照 RFC3986 第 2.4 节中的描</p><p>述进行单轮百分比解码，以生成有效的 UTF-8 字符串。(注意，应用百分比解码的次数不正确可能导致报文损坏或安全问题)。</p><p><em><strong>Examples</strong></em></p><p>这个例子显示了带有HTTP POST请求的事件与的二进制模式映射：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST /someresource HTTP/1.1</span><br><span class="line">Host: webhook.example.com</span><br><span class="line">ce-specversion: 1.0</span><br><span class="line">ce-type: com.example.someevent</span><br><span class="line">ce-time: 2018-04-05T03:56:24Z</span><br><span class="line">ce-id: 1234-1234-1234</span><br><span class="line">ce-source: /mycontext/subcontext</span><br><span class="line">    .... further attributes ...</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    ... application data ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子显示了包含事件的响应：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">ce-specversion: 1.0</span><br><span class="line">ce-type: com.example.someevent</span><br><span class="line">ce-time: 2018-04-05T03:56:24Z</span><br><span class="line">ce-id: 1234-1234-1234</span><br><span class="line">ce-source: /mycontext/subcontext</span><br><span class="line">    .... further attributes ...</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    ... application data ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em><strong>结构化内容模式</strong></em><br>结构化的内容模式将事件元数据和数据保持在有效载荷中，使得同一事件可以在多个路由跳转、多协议之间简单转发。</p><h3 id="HTTP内容类型"><a href="#HTTP内容类型" class="headerlink" title="HTTP内容类型"></a>HTTP内容类型</h3><p>HTTP内容类型头必须设置为事件格式的媒体类型。</p><blockquote><p>JSON 格式的示例。</p></blockquote><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: application/cloudevents+json; charset=UTF-8</span><br></pre></td></tr></table></figure><h3 id="事件数据编码"><a href="#事件数据编码" class="headerlink" title="事件数据编码"></a>事件数据编码</h3><p>所选择的事件格式定义了所有属性和数据的表示方式。</p><p>然后按照事件格式规范对事件元数据和数据进行渲染，最后得到的数据成为HTTP报文body。</p><h3 id="metadata-header"><a href="#metadata-header" class="headerlink" title="metadata header"></a>metadata header</h3><p>实现可以包含与二进制模式定义的相同的 HTTP 标头。</p><p>所有 CloudEvents 元数据属性都必须映射到有效载荷（Payload）中，即使它们也已经映射到 HTTP header中了。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>这个例子显示了一个JSON事件格式编码的事件，用PUT请求发送：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT /myresource HTTP/1.1</span><br><span class="line">Host: webhook.example.com</span><br><span class="line">Content-Type: application/cloudevents+json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">    &quot;type&quot; : &quot;com.example.someevent&quot;,</span><br><span class="line"></span><br><span class="line">    ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">    &quot;data&quot; : &#123;</span><br><span class="line">        ... application data ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子显示了一个响应中返回的JSON编码的事件：</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: application/cloudevents+json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">    &quot;type&quot; : &quot;com.example.someevent&quot;,</span><br><span class="line"></span><br><span class="line">    ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">    &quot;data&quot; : &#123;</span><br><span class="line">        ... application data ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="批量内容模式"><a href="#批量内容模式" class="headerlink" title="批量内容模式"></a>批量内容模式</h3><p>在批量内容模式下，多个事件被批量到一个HTTP请求或响应体中。选择的事件格式必须定义如何表示一个批次。基于JSON格式（任何兼容的实现都必须支持JSON格式），</p><p>JSON Batch格式是一种支持批处理的事件格式。</p><p><em><strong>HTTP 内容类型</strong></em></p><p>HTTP Content-Type头必须设置为事件格式的媒体类型。</p><p>JSON Batch 格式的示例。</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: application/cloudevents-batch+json; charset=UTF-8</span><br></pre></td></tr></table></figure><p><em><strong>事件数据编码</strong></em></p><p>所选的事件格式定义了一批事件和所有事件属性和数据的表示方式。</p><p>然后根据事件格式规范对事件批进行渲染，结果数据将成为HTTP消息主体。</p><p>该批事件可以是空的。所有批处理的 CloudEvents 必须具有相同的 specversion 属性。其他属性可能不同，包括 datacontententtype 属性。</p><p><em><strong>示例</strong></em></p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PUT /myresource HTTP/1.1</span><br><span class="line">Host: webhook.example.com</span><br><span class="line">Content-Type: application/cloudevents-batch+json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">        &quot;type&quot; : &quot;com.example.someevent&quot;,</span><br><span class="line"></span><br><span class="line">        ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">        &quot;data&quot; : &#123;</span><br><span class="line">            ... application data ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">        &quot;type&quot; : &quot;com.example.someotherevent&quot;,</span><br><span class="line"></span><br><span class="line">        ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">        &quot;data&quot; : &#123;</span><br><span class="line">            ... application data ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>返回</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: application/cloudevents-batch+json; charset=utf-8</span><br><span class="line">Content-Length: nnnn</span><br><span class="line"></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">        &quot;type&quot; : &quot;com.example.someevent&quot;,</span><br><span class="line"></span><br><span class="line">        ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">        &quot;data&quot; : &#123;</span><br><span class="line">            ... application data ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;specversion&quot; : &quot;1.0&quot;,</span><br><span class="line">        &quot;type&quot; : &quot;com.example.someotherevent&quot;,</span><br><span class="line"></span><br><span class="line">        ... further attributes omitted ...</span><br><span class="line"></span><br><span class="line">        &quot;data&quot; : &#123;</span><br><span class="line">            ... application data ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><hr><h2 id="四、json事件格式"><a href="#四、json事件格式" class="headerlink" title="四、json事件格式"></a>四、json事件格式</h2><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p>本节定义了 CloudEvents 属性如何映射到 JSON。本规范没有明确映射每个属性，但提供了一个通用映射模型，该模型适用于所有当前和未来的 CloudEvents </p><p>属性（包括扩展）。</p><p>为明确起见，扩展属性使用与规范定义的属性相同的规则进行序列化。这包括其语法和在 JSON 对象中的位置。特别是，扩展作为顶层 JSON 属性放置。扩展必须被</p><p>序列化为顶层JSON属性。</p><p><em><strong>Type System Mapping</strong></em></p><p>扩展规范可以为其定义的属性值定义二次映射规则，但必须包括之前定义的主映射。</p><p>例如，属性值可能是在 CloudEvents 以外的标准中定义的数据结构，具有正式的 JSON 映射，如果不保留原始格式，可能会有翻译错误或信息丢失的风险。</p><p>定义了 JSON 次要映射规则的扩展规范，以及对该规范的任何修订，都必须为提交或修订时属于 CloudEvents 核心的所有其他事件格式定义明确的映射规则。</p><p>如果需要，例如在解码地图时，CloudEvents 类型可以通过使用映射表中的规则进行推理来确定，其中唯一潜在的模糊 JSON 数据类型是字符串。当满足映射规则时，</p><p>该值与相应的 CloudEvents 类型兼容。</p><h3 id="Envelope"><a href="#Envelope" class="headerlink" title="Envelope"></a>Envelope</h3><p>每个 CloudEvents 事件可以完全表示为一个 JSON 对象。</p><p>这种表示方式必须使用媒体类型 application&#x2F;cloudevents+json。</p><p>给定事件中的所有 REQUIRED 和所有未省略的 OPTIONAL 属性必须成为 JSON 对象的成员，相应的 JSON 对象成员名称与属性名称相匹配，并且成员的类型和值</p><p>使用类型系统映射。</p><p><em><strong>对 “data”的处理</strong></em></p><p>在采取行动之前，JSON序列化器必须首先确定数据内容的运行时数据类型。</p><p>如果实现确定数据类型为二进制，则必须将值表示为包含Base64编码的二进制值的JSON字符串表达式，并使用成员名data_base64将其存储在JSON对象中。</p><p>对于任何其他类型，实现必须将数据值转换为JSON值，并使用成员名data_base64来存储在JSON对象中。</p><p>由此可见，在 JSON 序列化的 CloudEvent 中，数据和 data_base64 成员的使用是相互排斥的。</p><p>当从 JSON 中解串化 CloudEvents 时，data_base64 成员的存在清楚地表明该值是 Base64 编码的二进制数据，序列化器必须将其解码为二进制的运行时数据</p><p>类型。当数据成员存在时，它将使用默认的JSON类型映射来解码，用于使用的运行时。</p><p>与属性不同的是，根据类型系统映射，值类型被限制为字符串，而产生的数据成员JSON值是不受限制的，可以包含任何有效的JSON。</p><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.bookstack.cn/read/serverless-handbook/core-function-code.md">function</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CloudEvents是一种以通用方式描述事件数据的规范。CloudEvents旨在简化跨服务，平台及其他方面的事件声明和发送。CloudEvents　最初由　CNCF&lt;br&gt;Severless 工作组提出。CloudEvents 的 HTTP 协议绑定定义了如何将事件映射</summary>
      
    
    
    
    <category term="serverless" scheme="https://zoues.com/categories/serverless/"/>
    
    
    <category term="serverless" scheme="https://zoues.com/tags/serverless/"/>
    
    <category term="cloudnative" scheme="https://zoues.com/tags/cloudnative/"/>
    
  </entry>
  
</feed>
